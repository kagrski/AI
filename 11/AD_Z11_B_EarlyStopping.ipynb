{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "QaY1womeWj-p",
    "outputId": "751da686-39c4-469c-9fd2-7cd1272301c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNNfo5kGWj-y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "9f39RViyXKD-",
    "outputId": "ae267cc2-2a5a-436b-8f09-0c715bc1241c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive # import drive from google colab\n",
    "\n",
    "ROOT = \"/content/drive\"     # default location for the drive\n",
    "print(ROOT)                 # print content of ROOT (Optional)\n",
    "\n",
    "drive.mount(ROOT)           # we mount the google drive at /content/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "VcP-X56WXRCl",
    "outputId": "3a5f6269-9ee8-46a1-f9e8-f50d8e0e3d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'drive'\n",
      "/content/drive\n",
      "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "61kwTzumXXy4",
    "outputId": "b0d24efc-5f05-4b69-d965-60241a7fba67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "%cd My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "7EZ1l_VqWj-8",
    "outputId": "d51fe2f4-b9b8-4643-f69c-7721321d52a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  ... hours_per_week  native_country wage_class\n",
       "0   39         State-gov   77516  ...             40   United-States      <=50K\n",
       "1   50  Self-emp-not-inc   83311  ...             13   United-States      <=50K\n",
       "2   38           Private  215646  ...             40   United-States      <=50K\n",
       "3   53           Private  234721  ...             40   United-States      <=50K\n",
       "4   28           Private  338409  ...             40            Cuba      <=50K\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02LPb701Wj_D"
   },
   "source": [
    "# Zad.\n",
    "Zróbmy szybki preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wbCIz5HWj_E"
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlXWXQqsWj_L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "4ZDHZNOTWj_R",
    "outputId": "f0f67d92-9779-40f9-dc29-b4b3aed7df51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwSHDLrIWj_Y"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6yPnoFaWj_f"
   },
   "source": [
    "# Zad\n",
    "nauczmy model z EarlyStopping\n",
    "\n",
    "Musimy podać:\n",
    "* miarę, która ma zostać użyta do zatrzymania modelu\n",
    "* jak długo ma model ma czekać na otrzymanie lepszego parametru zanim się zatrzyma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "Kd78j1CqWj_f",
    "outputId": "7dcf68d9-a2d2-415a-945c-f7d2b9b7dfa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 0s 247us/step - loss: 0.2544 - accuracy: 0.8868 - val_loss: 0.5177 - val_accuracy: 0.7447\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2534 - accuracy: 0.8868 - val_loss: 0.5148 - val_accuracy: 0.7447\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2536 - accuracy: 0.9057 - val_loss: 0.5134 - val_accuracy: 0.7660\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 156us/step - loss: 0.2525 - accuracy: 0.9057 - val_loss: 0.5147 - val_accuracy: 0.7447\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 157us/step - loss: 0.2527 - accuracy: 0.9057 - val_loss: 0.5159 - val_accuracy: 0.7447\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.2527 - accuracy: 0.8868 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1, min_delta=0.0005)\n",
    "history = model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "NoWaPhz1Wj_l",
    "outputId": "bc2ca6ff-6d59-46bb-ae3a-cb4a789b22cd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "kJCVyPzpWj_s",
    "outputId": "f02c5747-ec30-4fa1-8e98-dd7752d656da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15060/15060 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3714007297835027, 0.8096281290054321]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6sg5qqZ7Wj_x",
    "outputId": "444f7d11-62d2-4f8c-9f78-94735afda35f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8096281540504648"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "metrics.accuracy_score(y_true= y_test, y_pred= model.predict_classes(X_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sYAahubWj_3"
   },
   "source": [
    "# Zad.\n",
    "Na poniższych danych naucz\n",
    "\n",
    "* model bez EarlyStopping z 1000 epok\n",
    "* model z wykorzystaniem EarlyStopping \n",
    "    dobierz paametr\n",
    "    ```python\n",
    "    patience=\n",
    "    ```\n",
    "\n",
    "Zwizualizuj wyniki:\n",
    "\n",
    "* porównaj krzywe uczenia\n",
    "* narysuj granice decyzyjne (dane są w 2D)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "8Iehbi_9Wj_5",
    "outputId": "1ad0e879-be4e-4749-f736-c2dae2140ad1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "CO14ODkSaBoW",
    "outputId": "3da7c45c-cb32-4281-fe8e-4bc356a35d21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 5,871\n",
      "Trainable params: 5,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XA3Jo0DNjnzI",
    "outputId": "1e33a55a-85b9-48ea-9d3f-c3629aee775c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 5,871\n",
      "Trainable params: 5,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.4528 - val_loss: 0.6887 - val_accuracy: 0.5532\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 165us/step - loss: 0.7094 - accuracy: 0.4528 - val_loss: 0.6893 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.7014 - accuracy: 0.4528 - val_loss: 0.6908 - val_accuracy: 0.5532\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.6965 - accuracy: 0.4528 - val_loss: 0.6929 - val_accuracy: 0.5532\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6952 - accuracy: 0.4340 - val_loss: 0.6957 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.6926 - accuracy: 0.5472 - val_loss: 0.6986 - val_accuracy: 0.4468\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.6902 - accuracy: 0.5472 - val_loss: 0.7013 - val_accuracy: 0.4468\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.6912 - accuracy: 0.5472 - val_loss: 0.7038 - val_accuracy: 0.4468\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.6888 - accuracy: 0.5472 - val_loss: 0.7053 - val_accuracy: 0.4468\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.6884 - accuracy: 0.5472 - val_loss: 0.7065 - val_accuracy: 0.4468\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.6883 - accuracy: 0.5472 - val_loss: 0.7075 - val_accuracy: 0.4468\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.6880 - accuracy: 0.5472 - val_loss: 0.7080 - val_accuracy: 0.4468\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 154us/step - loss: 0.6878 - accuracy: 0.5472 - val_loss: 0.7082 - val_accuracy: 0.4468\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.6873 - accuracy: 0.5472 - val_loss: 0.7079 - val_accuracy: 0.4468\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.6871 - accuracy: 0.5472 - val_loss: 0.7075 - val_accuracy: 0.4468\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.6868 - accuracy: 0.5472 - val_loss: 0.7069 - val_accuracy: 0.4468\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.6864 - accuracy: 0.5472 - val_loss: 0.7062 - val_accuracy: 0.4468\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.6862 - accuracy: 0.5472 - val_loss: 0.7055 - val_accuracy: 0.4468\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 303us/step - loss: 0.6858 - accuracy: 0.5472 - val_loss: 0.7048 - val_accuracy: 0.4468\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.6855 - accuracy: 0.5472 - val_loss: 0.7040 - val_accuracy: 0.4468\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.6851 - accuracy: 0.5472 - val_loss: 0.7030 - val_accuracy: 0.4468\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.6849 - accuracy: 0.5472 - val_loss: 0.7018 - val_accuracy: 0.4468\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.6845 - accuracy: 0.5472 - val_loss: 0.7008 - val_accuracy: 0.4468\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.6853 - accuracy: 0.5472 - val_loss: 0.6997 - val_accuracy: 0.4468\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 235us/step - loss: 0.6840 - accuracy: 0.5472 - val_loss: 0.6997 - val_accuracy: 0.4468\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.6836 - accuracy: 0.5472 - val_loss: 0.6995 - val_accuracy: 0.4468\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.6832 - accuracy: 0.5472 - val_loss: 0.6994 - val_accuracy: 0.4468\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.6828 - accuracy: 0.5472 - val_loss: 0.6993 - val_accuracy: 0.4468\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.6824 - accuracy: 0.5472 - val_loss: 0.6992 - val_accuracy: 0.4468\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.6820 - accuracy: 0.5472 - val_loss: 0.6989 - val_accuracy: 0.4468\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.6816 - accuracy: 0.5472 - val_loss: 0.6986 - val_accuracy: 0.4468\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.6811 - accuracy: 0.5472 - val_loss: 0.6985 - val_accuracy: 0.4468\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.6814 - accuracy: 0.5472 - val_loss: 0.6984 - val_accuracy: 0.4468\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.6801 - accuracy: 0.5472 - val_loss: 0.6974 - val_accuracy: 0.4468\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.6797 - accuracy: 0.5472 - val_loss: 0.6962 - val_accuracy: 0.4468\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.6792 - accuracy: 0.5472 - val_loss: 0.6953 - val_accuracy: 0.4468\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.6787 - accuracy: 0.5472 - val_loss: 0.6940 - val_accuracy: 0.4468\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.6780 - accuracy: 0.5472 - val_loss: 0.6931 - val_accuracy: 0.4468\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6774 - accuracy: 0.5472 - val_loss: 0.6921 - val_accuracy: 0.4468\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.6768 - accuracy: 0.5472 - val_loss: 0.6910 - val_accuracy: 0.4468\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.6763 - accuracy: 0.5472 - val_loss: 0.6899 - val_accuracy: 0.4468\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.6756 - accuracy: 0.5472 - val_loss: 0.6890 - val_accuracy: 0.4468\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 256us/step - loss: 0.6748 - accuracy: 0.5472 - val_loss: 0.6885 - val_accuracy: 0.4468\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 148us/step - loss: 0.6740 - accuracy: 0.5472 - val_loss: 0.6879 - val_accuracy: 0.4468\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.6735 - accuracy: 0.5472 - val_loss: 0.6880 - val_accuracy: 0.4468\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.6722 - accuracy: 0.5472 - val_loss: 0.6874 - val_accuracy: 0.4468\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.6713 - accuracy: 0.5472 - val_loss: 0.6868 - val_accuracy: 0.4468\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.6702 - accuracy: 0.5472 - val_loss: 0.6860 - val_accuracy: 0.4468\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.6693 - accuracy: 0.5472 - val_loss: 0.6853 - val_accuracy: 0.4468\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.6683 - accuracy: 0.5472 - val_loss: 0.6839 - val_accuracy: 0.4468\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.6670 - accuracy: 0.5472 - val_loss: 0.6829 - val_accuracy: 0.4468\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 157us/step - loss: 0.6656 - accuracy: 0.5472 - val_loss: 0.6821 - val_accuracy: 0.4468\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 149us/step - loss: 0.6644 - accuracy: 0.5472 - val_loss: 0.6813 - val_accuracy: 0.4468\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 152us/step - loss: 0.6632 - accuracy: 0.5472 - val_loss: 0.6801 - val_accuracy: 0.4468\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.6615 - accuracy: 0.5472 - val_loss: 0.6793 - val_accuracy: 0.4468\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.6602 - accuracy: 0.5472 - val_loss: 0.6780 - val_accuracy: 0.4681\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.6585 - accuracy: 0.5472 - val_loss: 0.6773 - val_accuracy: 0.4681\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6570 - accuracy: 0.5660 - val_loss: 0.6757 - val_accuracy: 0.5106\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.6553 - accuracy: 0.5660 - val_loss: 0.6741 - val_accuracy: 0.5319\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.6534 - accuracy: 0.5849 - val_loss: 0.6716 - val_accuracy: 0.5532\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 159us/step - loss: 0.6513 - accuracy: 0.6415 - val_loss: 0.6688 - val_accuracy: 0.6170\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.6489 - accuracy: 0.6792 - val_loss: 0.6663 - val_accuracy: 0.7234\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.6465 - accuracy: 0.6981 - val_loss: 0.6638 - val_accuracy: 0.7660\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.6442 - accuracy: 0.7170 - val_loss: 0.6606 - val_accuracy: 0.7447\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.6420 - accuracy: 0.7925 - val_loss: 0.6571 - val_accuracy: 0.7447\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.6390 - accuracy: 0.7925 - val_loss: 0.6545 - val_accuracy: 0.7234\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 165us/step - loss: 0.6360 - accuracy: 0.7925 - val_loss: 0.6513 - val_accuracy: 0.7234\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.6337 - accuracy: 0.7736 - val_loss: 0.6477 - val_accuracy: 0.7660\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.6303 - accuracy: 0.8113 - val_loss: 0.6448 - val_accuracy: 0.7872\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.6270 - accuracy: 0.8302 - val_loss: 0.6420 - val_accuracy: 0.7872\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.6236 - accuracy: 0.8302 - val_loss: 0.6392 - val_accuracy: 0.7872\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.6202 - accuracy: 0.8302 - val_loss: 0.6366 - val_accuracy: 0.7872\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.6165 - accuracy: 0.8302 - val_loss: 0.6335 - val_accuracy: 0.7872\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.6126 - accuracy: 0.8302 - val_loss: 0.6310 - val_accuracy: 0.7872\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.6085 - accuracy: 0.8302 - val_loss: 0.6279 - val_accuracy: 0.7872\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 156us/step - loss: 0.6045 - accuracy: 0.8302 - val_loss: 0.6243 - val_accuracy: 0.7872\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.6001 - accuracy: 0.8302 - val_loss: 0.6203 - val_accuracy: 0.7872\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 166us/step - loss: 0.5958 - accuracy: 0.8302 - val_loss: 0.6162 - val_accuracy: 0.7447\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 187us/step - loss: 0.5909 - accuracy: 0.8302 - val_loss: 0.6115 - val_accuracy: 0.7447\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.5866 - accuracy: 0.8302 - val_loss: 0.6064 - val_accuracy: 0.7447\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.5814 - accuracy: 0.8302 - val_loss: 0.6019 - val_accuracy: 0.7234\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.5763 - accuracy: 0.8113 - val_loss: 0.5977 - val_accuracy: 0.7234\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.5711 - accuracy: 0.8113 - val_loss: 0.5934 - val_accuracy: 0.7234\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.5660 - accuracy: 0.8113 - val_loss: 0.5892 - val_accuracy: 0.7234\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.5602 - accuracy: 0.8113 - val_loss: 0.5851 - val_accuracy: 0.7234\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.5546 - accuracy: 0.8113 - val_loss: 0.5809 - val_accuracy: 0.7234\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.5493 - accuracy: 0.8113 - val_loss: 0.5767 - val_accuracy: 0.7234\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.5435 - accuracy: 0.8113 - val_loss: 0.5724 - val_accuracy: 0.7234\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.5383 - accuracy: 0.8113 - val_loss: 0.5680 - val_accuracy: 0.7234\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 187us/step - loss: 0.5321 - accuracy: 0.8113 - val_loss: 0.5638 - val_accuracy: 0.7234\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.5262 - accuracy: 0.8113 - val_loss: 0.5595 - val_accuracy: 0.7234\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.5207 - accuracy: 0.8113 - val_loss: 0.5553 - val_accuracy: 0.7234\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.5152 - accuracy: 0.8113 - val_loss: 0.5512 - val_accuracy: 0.7234\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.5095 - accuracy: 0.8113 - val_loss: 0.5473 - val_accuracy: 0.7447\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.5035 - accuracy: 0.8302 - val_loss: 0.5436 - val_accuracy: 0.7447\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.4993 - accuracy: 0.8302 - val_loss: 0.5404 - val_accuracy: 0.7447\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.4941 - accuracy: 0.8491 - val_loss: 0.5369 - val_accuracy: 0.7447\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.4883 - accuracy: 0.8302 - val_loss: 0.5340 - val_accuracy: 0.7447\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.4827 - accuracy: 0.8302 - val_loss: 0.5309 - val_accuracy: 0.7447\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.4786 - accuracy: 0.8302 - val_loss: 0.5279 - val_accuracy: 0.7447\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.4737 - accuracy: 0.8302 - val_loss: 0.5253 - val_accuracy: 0.7447\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4691 - accuracy: 0.8302 - val_loss: 0.5228 - val_accuracy: 0.7447\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 331us/step - loss: 0.4650 - accuracy: 0.8302 - val_loss: 0.5204 - val_accuracy: 0.7447\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 227us/step - loss: 0.4604 - accuracy: 0.8302 - val_loss: 0.5182 - val_accuracy: 0.7447\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.4570 - accuracy: 0.8302 - val_loss: 0.5165 - val_accuracy: 0.7447\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.4527 - accuracy: 0.8491 - val_loss: 0.5145 - val_accuracy: 0.7447\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.4487 - accuracy: 0.8491 - val_loss: 0.5124 - val_accuracy: 0.7447\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.4451 - accuracy: 0.8491 - val_loss: 0.5101 - val_accuracy: 0.7447\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 227us/step - loss: 0.4422 - accuracy: 0.8302 - val_loss: 0.5083 - val_accuracy: 0.7447\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.4385 - accuracy: 0.8302 - val_loss: 0.5070 - val_accuracy: 0.7447\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.4351 - accuracy: 0.8491 - val_loss: 0.5066 - val_accuracy: 0.7447\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 275us/step - loss: 0.4320 - accuracy: 0.8491 - val_loss: 0.5063 - val_accuracy: 0.7447\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4288 - accuracy: 0.8491 - val_loss: 0.5054 - val_accuracy: 0.7447\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 149us/step - loss: 0.4265 - accuracy: 0.8491 - val_loss: 0.5050 - val_accuracy: 0.7447\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.4234 - accuracy: 0.8491 - val_loss: 0.5033 - val_accuracy: 0.7447\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 250us/step - loss: 0.4201 - accuracy: 0.8491 - val_loss: 0.5019 - val_accuracy: 0.7447\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.4175 - accuracy: 0.8491 - val_loss: 0.5013 - val_accuracy: 0.7447\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.4152 - accuracy: 0.8491 - val_loss: 0.5000 - val_accuracy: 0.7447\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 154us/step - loss: 0.4127 - accuracy: 0.8491 - val_loss: 0.4992 - val_accuracy: 0.7447\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 156us/step - loss: 0.4101 - accuracy: 0.8491 - val_loss: 0.4992 - val_accuracy: 0.7447\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 155us/step - loss: 0.4080 - accuracy: 0.8491 - val_loss: 0.4995 - val_accuracy: 0.7447\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.4061 - accuracy: 0.8491 - val_loss: 0.4985 - val_accuracy: 0.7447\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.4037 - accuracy: 0.8491 - val_loss: 0.4988 - val_accuracy: 0.7447\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.4012 - accuracy: 0.8491 - val_loss: 0.4983 - val_accuracy: 0.7447\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.3995 - accuracy: 0.8491 - val_loss: 0.4977 - val_accuracy: 0.7447\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.3971 - accuracy: 0.8491 - val_loss: 0.4961 - val_accuracy: 0.7447\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.3956 - accuracy: 0.8491 - val_loss: 0.4949 - val_accuracy: 0.7447\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.3931 - accuracy: 0.8491 - val_loss: 0.4928 - val_accuracy: 0.7447\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.3927 - accuracy: 0.8491 - val_loss: 0.4907 - val_accuracy: 0.7447\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.3903 - accuracy: 0.8491 - val_loss: 0.4905 - val_accuracy: 0.7447\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 252us/step - loss: 0.3884 - accuracy: 0.8491 - val_loss: 0.4899 - val_accuracy: 0.7447\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.3863 - accuracy: 0.8491 - val_loss: 0.4902 - val_accuracy: 0.7447\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.3846 - accuracy: 0.8491 - val_loss: 0.4911 - val_accuracy: 0.7447\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.3827 - accuracy: 0.8491 - val_loss: 0.4920 - val_accuracy: 0.7447\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.3810 - accuracy: 0.8491 - val_loss: 0.4930 - val_accuracy: 0.7660\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.3796 - accuracy: 0.8491 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.3783 - accuracy: 0.8679 - val_loss: 0.4940 - val_accuracy: 0.7660\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.3765 - accuracy: 0.8679 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3748 - accuracy: 0.8679 - val_loss: 0.4954 - val_accuracy: 0.7660\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 145us/step - loss: 0.3736 - accuracy: 0.8679 - val_loss: 0.4954 - val_accuracy: 0.7660\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 241us/step - loss: 0.3728 - accuracy: 0.8679 - val_loss: 0.4962 - val_accuracy: 0.7872\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 166us/step - loss: 0.3706 - accuracy: 0.8679 - val_loss: 0.4948 - val_accuracy: 0.7660\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 158us/step - loss: 0.3692 - accuracy: 0.8679 - val_loss: 0.4919 - val_accuracy: 0.7660\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.3677 - accuracy: 0.8679 - val_loss: 0.4895 - val_accuracy: 0.7660\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.3657 - accuracy: 0.8679 - val_loss: 0.4886 - val_accuracy: 0.7660\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.3643 - accuracy: 0.8679 - val_loss: 0.4875 - val_accuracy: 0.7660\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.3632 - accuracy: 0.8679 - val_loss: 0.4862 - val_accuracy: 0.7660\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 157us/step - loss: 0.3622 - accuracy: 0.8679 - val_loss: 0.4866 - val_accuracy: 0.7660\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 139us/step - loss: 0.3611 - accuracy: 0.8679 - val_loss: 0.4860 - val_accuracy: 0.7660\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.3590 - accuracy: 0.8679 - val_loss: 0.4831 - val_accuracy: 0.7660\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.3577 - accuracy: 0.8679 - val_loss: 0.4817 - val_accuracy: 0.7660\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.3567 - accuracy: 0.8491 - val_loss: 0.4804 - val_accuracy: 0.7660\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.3555 - accuracy: 0.8491 - val_loss: 0.4801 - val_accuracy: 0.7660\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.3543 - accuracy: 0.8679 - val_loss: 0.4815 - val_accuracy: 0.7660\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3527 - accuracy: 0.8679 - val_loss: 0.4829 - val_accuracy: 0.7872\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 154us/step - loss: 0.3516 - accuracy: 0.8679 - val_loss: 0.4846 - val_accuracy: 0.7872\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.3509 - accuracy: 0.8679 - val_loss: 0.4859 - val_accuracy: 0.7872\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.3488 - accuracy: 0.8679 - val_loss: 0.4850 - val_accuracy: 0.7872\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 187us/step - loss: 0.3477 - accuracy: 0.8679 - val_loss: 0.4842 - val_accuracy: 0.7872\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 154us/step - loss: 0.3465 - accuracy: 0.8679 - val_loss: 0.4833 - val_accuracy: 0.7872\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.3455 - accuracy: 0.8679 - val_loss: 0.4826 - val_accuracy: 0.7872\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.3444 - accuracy: 0.8679 - val_loss: 0.4812 - val_accuracy: 0.7872\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.3432 - accuracy: 0.8679 - val_loss: 0.4813 - val_accuracy: 0.7872\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.3421 - accuracy: 0.8679 - val_loss: 0.4816 - val_accuracy: 0.7872\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.3410 - accuracy: 0.8679 - val_loss: 0.4822 - val_accuracy: 0.7872\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.3397 - accuracy: 0.8679 - val_loss: 0.4825 - val_accuracy: 0.7872\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.3389 - accuracy: 0.8679 - val_loss: 0.4830 - val_accuracy: 0.7872\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.3375 - accuracy: 0.8679 - val_loss: 0.4848 - val_accuracy: 0.7660\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 233us/step - loss: 0.3366 - accuracy: 0.8679 - val_loss: 0.4870 - val_accuracy: 0.7660\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.3359 - accuracy: 0.8679 - val_loss: 0.4874 - val_accuracy: 0.7660\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.3349 - accuracy: 0.8679 - val_loss: 0.4894 - val_accuracy: 0.7660\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 335us/step - loss: 0.3337 - accuracy: 0.8679 - val_loss: 0.4889 - val_accuracy: 0.7660\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.3328 - accuracy: 0.8679 - val_loss: 0.4873 - val_accuracy: 0.7660\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 273us/step - loss: 0.3314 - accuracy: 0.8679 - val_loss: 0.4858 - val_accuracy: 0.7660\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.3304 - accuracy: 0.8679 - val_loss: 0.4845 - val_accuracy: 0.7660\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.3293 - accuracy: 0.8679 - val_loss: 0.4823 - val_accuracy: 0.7660\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.3286 - accuracy: 0.8679 - val_loss: 0.4805 - val_accuracy: 0.7660\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.3274 - accuracy: 0.8868 - val_loss: 0.4808 - val_accuracy: 0.7660\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 273us/step - loss: 0.3264 - accuracy: 0.8868 - val_loss: 0.4807 - val_accuracy: 0.7660\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.3259 - accuracy: 0.8868 - val_loss: 0.4807 - val_accuracy: 0.7660\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.3245 - accuracy: 0.8868 - val_loss: 0.4790 - val_accuracy: 0.7660\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.3250 - accuracy: 0.8868 - val_loss: 0.4758 - val_accuracy: 0.7660\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 155us/step - loss: 0.3233 - accuracy: 0.8868 - val_loss: 0.4774 - val_accuracy: 0.7660\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.3219 - accuracy: 0.8868 - val_loss: 0.4782 - val_accuracy: 0.7660\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.3211 - accuracy: 0.8868 - val_loss: 0.4795 - val_accuracy: 0.7660\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.3202 - accuracy: 0.8868 - val_loss: 0.4814 - val_accuracy: 0.7660\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.3193 - accuracy: 0.8868 - val_loss: 0.4826 - val_accuracy: 0.7660\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.3185 - accuracy: 0.8868 - val_loss: 0.4845 - val_accuracy: 0.7660\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.3178 - accuracy: 0.8868 - val_loss: 0.4852 - val_accuracy: 0.7660\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.3169 - accuracy: 0.8868 - val_loss: 0.4884 - val_accuracy: 0.7660\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.3160 - accuracy: 0.8868 - val_loss: 0.4899 - val_accuracy: 0.7660\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 227us/step - loss: 0.3157 - accuracy: 0.8868 - val_loss: 0.4910 - val_accuracy: 0.7660\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.3156 - accuracy: 0.8868 - val_loss: 0.4901 - val_accuracy: 0.7660\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.3134 - accuracy: 0.8868 - val_loss: 0.4851 - val_accuracy: 0.7660\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.3125 - accuracy: 0.8868 - val_loss: 0.4792 - val_accuracy: 0.7872\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 222us/step - loss: 0.3154 - accuracy: 0.8868 - val_loss: 0.4733 - val_accuracy: 0.7872\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.3129 - accuracy: 0.8868 - val_loss: 0.4741 - val_accuracy: 0.7872\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 255us/step - loss: 0.3124 - accuracy: 0.8868 - val_loss: 0.4758 - val_accuracy: 0.7872\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.3118 - accuracy: 0.8868 - val_loss: 0.4821 - val_accuracy: 0.7872\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.3097 - accuracy: 0.8868 - val_loss: 0.4865 - val_accuracy: 0.7872\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 269us/step - loss: 0.3100 - accuracy: 0.8868 - val_loss: 0.4931 - val_accuracy: 0.7660\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 257us/step - loss: 0.3087 - accuracy: 0.8868 - val_loss: 0.4961 - val_accuracy: 0.7660\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.3089 - accuracy: 0.8868 - val_loss: 0.4962 - val_accuracy: 0.7660\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.3080 - accuracy: 0.9057 - val_loss: 0.4979 - val_accuracy: 0.7660\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.3071 - accuracy: 0.9057 - val_loss: 0.5019 - val_accuracy: 0.7660\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3072 - accuracy: 0.9057 - val_loss: 0.5037 - val_accuracy: 0.7660\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 233us/step - loss: 0.3067 - accuracy: 0.9057 - val_loss: 0.5024 - val_accuracy: 0.7660\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.3057 - accuracy: 0.9057 - val_loss: 0.4968 - val_accuracy: 0.7872\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.3046 - accuracy: 0.9057 - val_loss: 0.4921 - val_accuracy: 0.7872\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.3046 - accuracy: 0.8868 - val_loss: 0.4881 - val_accuracy: 0.7872\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.3037 - accuracy: 0.8868 - val_loss: 0.4879 - val_accuracy: 0.7872\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.3032 - accuracy: 0.8868 - val_loss: 0.4875 - val_accuracy: 0.7872\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.3028 - accuracy: 0.8868 - val_loss: 0.4876 - val_accuracy: 0.7872\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.3032 - accuracy: 0.8868 - val_loss: 0.4900 - val_accuracy: 0.7872\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 252us/step - loss: 0.3019 - accuracy: 0.8868 - val_loss: 0.4899 - val_accuracy: 0.7872\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.3015 - accuracy: 0.8868 - val_loss: 0.4917 - val_accuracy: 0.7872\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 271us/step - loss: 0.3008 - accuracy: 0.8868 - val_loss: 0.4928 - val_accuracy: 0.7872\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.3003 - accuracy: 0.8868 - val_loss: 0.4944 - val_accuracy: 0.7872\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2999 - accuracy: 0.8868 - val_loss: 0.4976 - val_accuracy: 0.7872\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2994 - accuracy: 0.9057 - val_loss: 0.5004 - val_accuracy: 0.7872\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2992 - accuracy: 0.9057 - val_loss: 0.5023 - val_accuracy: 0.7872\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.2985 - accuracy: 0.9057 - val_loss: 0.5018 - val_accuracy: 0.7872\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2983 - accuracy: 0.9057 - val_loss: 0.5015 - val_accuracy: 0.7872\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2978 - accuracy: 0.9057 - val_loss: 0.4989 - val_accuracy: 0.7872\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2974 - accuracy: 0.9057 - val_loss: 0.4975 - val_accuracy: 0.7872\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 255us/step - loss: 0.2976 - accuracy: 0.8868 - val_loss: 0.4963 - val_accuracy: 0.7872\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2973 - accuracy: 0.8868 - val_loss: 0.4990 - val_accuracy: 0.7872\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.2964 - accuracy: 0.9057 - val_loss: 0.4999 - val_accuracy: 0.7872\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2963 - accuracy: 0.9057 - val_loss: 0.5015 - val_accuracy: 0.7872\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 307us/step - loss: 0.2956 - accuracy: 0.9057 - val_loss: 0.5011 - val_accuracy: 0.7872\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 235us/step - loss: 0.2959 - accuracy: 0.9057 - val_loss: 0.5012 - val_accuracy: 0.7872\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 272us/step - loss: 0.2950 - accuracy: 0.9057 - val_loss: 0.5050 - val_accuracy: 0.7660\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.2960 - accuracy: 0.9057 - val_loss: 0.5089 - val_accuracy: 0.7660\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.2943 - accuracy: 0.9057 - val_loss: 0.5078 - val_accuracy: 0.7660\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 259us/step - loss: 0.2939 - accuracy: 0.9057 - val_loss: 0.5073 - val_accuracy: 0.7660\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.2936 - accuracy: 0.9057 - val_loss: 0.5081 - val_accuracy: 0.7660\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.2936 - accuracy: 0.9057 - val_loss: 0.5086 - val_accuracy: 0.7660\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2930 - accuracy: 0.9057 - val_loss: 0.5064 - val_accuracy: 0.7660\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 144us/step - loss: 0.2927 - accuracy: 0.9057 - val_loss: 0.5059 - val_accuracy: 0.7660\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.2926 - accuracy: 0.9057 - val_loss: 0.5054 - val_accuracy: 0.7660\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2922 - accuracy: 0.9057 - val_loss: 0.5066 - val_accuracy: 0.7660\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2923 - accuracy: 0.9057 - val_loss: 0.5079 - val_accuracy: 0.7660\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2915 - accuracy: 0.9057 - val_loss: 0.5120 - val_accuracy: 0.7660\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2912 - accuracy: 0.9057 - val_loss: 0.5170 - val_accuracy: 0.7660\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.2920 - accuracy: 0.9057 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2927 - accuracy: 0.9057 - val_loss: 0.5276 - val_accuracy: 0.7660\n",
      "Epoch 00246: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = History()\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model2.add(Dense(50,activation=\"sigmoid\"))\n",
    "model2.add(Dense(10,activation=\"sigmoid\"))\n",
    "model2.add(Dense(1,activation=\"sigmoid\"))\n",
    "model2.summary()\n",
    "model2.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, mode='min', verbose=1, min_delta=0.00005)\n",
    "history2 = model2.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=1000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcyPRsUJWkAA"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AtKhhkWUWkAF",
    "outputId": "6bf09a33-7ec6-45b2-d5a4-e466093d5202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.5472 - val_loss: 0.7459 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.6988 - accuracy: 0.5472 - val_loss: 0.7332 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 165us/step - loss: 0.6942 - accuracy: 0.5472 - val_loss: 0.7233 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.6906 - accuracy: 0.5472 - val_loss: 0.7160 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.6884 - accuracy: 0.5472 - val_loss: 0.7103 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 150us/step - loss: 0.6880 - accuracy: 0.5472 - val_loss: 0.7056 - val_accuracy: 0.4468\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.6872 - accuracy: 0.5472 - val_loss: 0.7025 - val_accuracy: 0.4468\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.6870 - accuracy: 0.5472 - val_loss: 0.7003 - val_accuracy: 0.4468\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.6877 - accuracy: 0.5472 - val_loss: 0.6986 - val_accuracy: 0.4468\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.6869 - accuracy: 0.5472 - val_loss: 0.6987 - val_accuracy: 0.4468\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.6863 - accuracy: 0.5472 - val_loss: 0.6983 - val_accuracy: 0.4468\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.6857 - accuracy: 0.5472 - val_loss: 0.6988 - val_accuracy: 0.4468\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.6851 - accuracy: 0.5472 - val_loss: 0.6992 - val_accuracy: 0.4468\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 165us/step - loss: 0.6844 - accuracy: 0.5472 - val_loss: 0.7001 - val_accuracy: 0.4468\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6839 - accuracy: 0.5472 - val_loss: 0.7016 - val_accuracy: 0.4468\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6831 - accuracy: 0.5472 - val_loss: 0.7027 - val_accuracy: 0.4468\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.6826 - accuracy: 0.5472 - val_loss: 0.7036 - val_accuracy: 0.4468\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.6820 - accuracy: 0.5472 - val_loss: 0.7046 - val_accuracy: 0.4468\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 265us/step - loss: 0.6820 - accuracy: 0.5472 - val_loss: 0.7058 - val_accuracy: 0.4468\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.6812 - accuracy: 0.5472 - val_loss: 0.7057 - val_accuracy: 0.4468\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.6807 - accuracy: 0.5472 - val_loss: 0.7055 - val_accuracy: 0.4468\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 227us/step - loss: 0.6802 - accuracy: 0.5472 - val_loss: 0.7052 - val_accuracy: 0.4468\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.6795 - accuracy: 0.5472 - val_loss: 0.7051 - val_accuracy: 0.4468\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.6789 - accuracy: 0.5472 - val_loss: 0.7050 - val_accuracy: 0.4468\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 149us/step - loss: 0.6783 - accuracy: 0.5472 - val_loss: 0.7044 - val_accuracy: 0.4468\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.6778 - accuracy: 0.5472 - val_loss: 0.7032 - val_accuracy: 0.4468\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.6767 - accuracy: 0.5472 - val_loss: 0.7025 - val_accuracy: 0.4468\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 239us/step - loss: 0.6759 - accuracy: 0.5472 - val_loss: 0.7015 - val_accuracy: 0.4468\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.6752 - accuracy: 0.5472 - val_loss: 0.7000 - val_accuracy: 0.4468\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.6746 - accuracy: 0.5472 - val_loss: 0.6993 - val_accuracy: 0.4468\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.6732 - accuracy: 0.5472 - val_loss: 0.6969 - val_accuracy: 0.4468\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.6722 - accuracy: 0.5472 - val_loss: 0.6948 - val_accuracy: 0.4468\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.6716 - accuracy: 0.5472 - val_loss: 0.6928 - val_accuracy: 0.4468\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6700 - accuracy: 0.5472 - val_loss: 0.6917 - val_accuracy: 0.4468\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.6691 - accuracy: 0.5472 - val_loss: 0.6905 - val_accuracy: 0.4468\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.6684 - accuracy: 0.5472 - val_loss: 0.6898 - val_accuracy: 0.4468\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.6668 - accuracy: 0.5472 - val_loss: 0.6882 - val_accuracy: 0.4468\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.6657 - accuracy: 0.5472 - val_loss: 0.6861 - val_accuracy: 0.4468\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.6649 - accuracy: 0.5472 - val_loss: 0.6842 - val_accuracy: 0.4468\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.6632 - accuracy: 0.5472 - val_loss: 0.6834 - val_accuracy: 0.4468\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.6618 - accuracy: 0.5472 - val_loss: 0.6827 - val_accuracy: 0.4468\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.6612 - accuracy: 0.5472 - val_loss: 0.6825 - val_accuracy: 0.4468\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.6590 - accuracy: 0.5472 - val_loss: 0.6810 - val_accuracy: 0.4468\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.6573 - accuracy: 0.5472 - val_loss: 0.6800 - val_accuracy: 0.4468\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.6559 - accuracy: 0.5472 - val_loss: 0.6792 - val_accuracy: 0.4468\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.6542 - accuracy: 0.5472 - val_loss: 0.6779 - val_accuracy: 0.4468\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.6526 - accuracy: 0.5472 - val_loss: 0.6760 - val_accuracy: 0.4468\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.6507 - accuracy: 0.5472 - val_loss: 0.6746 - val_accuracy: 0.4468\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.6487 - accuracy: 0.5472 - val_loss: 0.6739 - val_accuracy: 0.4468\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.6467 - accuracy: 0.5472 - val_loss: 0.6729 - val_accuracy: 0.4681\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.6448 - accuracy: 0.5660 - val_loss: 0.6711 - val_accuracy: 0.4894\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.6427 - accuracy: 0.5660 - val_loss: 0.6699 - val_accuracy: 0.4894\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.6405 - accuracy: 0.5660 - val_loss: 0.6683 - val_accuracy: 0.5319\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.6380 - accuracy: 0.5660 - val_loss: 0.6659 - val_accuracy: 0.5532\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.6354 - accuracy: 0.6038 - val_loss: 0.6628 - val_accuracy: 0.5532\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.6331 - accuracy: 0.6792 - val_loss: 0.6593 - val_accuracy: 0.6809\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.6303 - accuracy: 0.7170 - val_loss: 0.6564 - val_accuracy: 0.7447\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.6274 - accuracy: 0.7170 - val_loss: 0.6540 - val_accuracy: 0.7447\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 345us/step - loss: 0.6245 - accuracy: 0.7170 - val_loss: 0.6516 - val_accuracy: 0.7660\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 222us/step - loss: 0.6217 - accuracy: 0.7170 - val_loss: 0.6497 - val_accuracy: 0.7660\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.6181 - accuracy: 0.7170 - val_loss: 0.6472 - val_accuracy: 0.7660\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.6152 - accuracy: 0.7547 - val_loss: 0.6442 - val_accuracy: 0.7447\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.6113 - accuracy: 0.7925 - val_loss: 0.6419 - val_accuracy: 0.7447\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.6081 - accuracy: 0.7925 - val_loss: 0.6395 - val_accuracy: 0.7447\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 250us/step - loss: 0.6042 - accuracy: 0.7925 - val_loss: 0.6364 - val_accuracy: 0.7447\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.6003 - accuracy: 0.7925 - val_loss: 0.6327 - val_accuracy: 0.7234\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.5965 - accuracy: 0.7925 - val_loss: 0.6295 - val_accuracy: 0.7447\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.5923 - accuracy: 0.7925 - val_loss: 0.6253 - val_accuracy: 0.7234\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 329us/step - loss: 0.5878 - accuracy: 0.7925 - val_loss: 0.6213 - val_accuracy: 0.7234\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.5836 - accuracy: 0.7736 - val_loss: 0.6173 - val_accuracy: 0.7234\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.5790 - accuracy: 0.7925 - val_loss: 0.6132 - val_accuracy: 0.7234\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.5743 - accuracy: 0.8113 - val_loss: 0.6093 - val_accuracy: 0.7447\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.5693 - accuracy: 0.8113 - val_loss: 0.6055 - val_accuracy: 0.7660\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 247us/step - loss: 0.5653 - accuracy: 0.8113 - val_loss: 0.6021 - val_accuracy: 0.7660\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.5594 - accuracy: 0.8113 - val_loss: 0.5979 - val_accuracy: 0.7660\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.5548 - accuracy: 0.8113 - val_loss: 0.5937 - val_accuracy: 0.7872\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.5497 - accuracy: 0.8302 - val_loss: 0.5899 - val_accuracy: 0.7872\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.5440 - accuracy: 0.8302 - val_loss: 0.5858 - val_accuracy: 0.7660\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.5393 - accuracy: 0.8302 - val_loss: 0.5815 - val_accuracy: 0.7447\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.5338 - accuracy: 0.8302 - val_loss: 0.5775 - val_accuracy: 0.7447\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 258us/step - loss: 0.5296 - accuracy: 0.8302 - val_loss: 0.5738 - val_accuracy: 0.7447\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.5231 - accuracy: 0.8302 - val_loss: 0.5708 - val_accuracy: 0.7447\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.5197 - accuracy: 0.8302 - val_loss: 0.5684 - val_accuracy: 0.7872\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.5145 - accuracy: 0.8302 - val_loss: 0.5651 - val_accuracy: 0.7872\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 266us/step - loss: 0.5096 - accuracy: 0.8302 - val_loss: 0.5612 - val_accuracy: 0.7447\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 225us/step - loss: 0.5054 - accuracy: 0.8302 - val_loss: 0.5575 - val_accuracy: 0.7447\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 248us/step - loss: 0.4994 - accuracy: 0.8302 - val_loss: 0.5535 - val_accuracy: 0.7447\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.4953 - accuracy: 0.8302 - val_loss: 0.5497 - val_accuracy: 0.7447\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.4904 - accuracy: 0.8302 - val_loss: 0.5465 - val_accuracy: 0.7447\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.4867 - accuracy: 0.8113 - val_loss: 0.5435 - val_accuracy: 0.7234\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 261us/step - loss: 0.4812 - accuracy: 0.8113 - val_loss: 0.5406 - val_accuracy: 0.7234\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 247us/step - loss: 0.4769 - accuracy: 0.8113 - val_loss: 0.5378 - val_accuracy: 0.7447\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.4727 - accuracy: 0.8302 - val_loss: 0.5352 - val_accuracy: 0.7447\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.4688 - accuracy: 0.8302 - val_loss: 0.5326 - val_accuracy: 0.7447\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.4651 - accuracy: 0.8302 - val_loss: 0.5301 - val_accuracy: 0.7447\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.4611 - accuracy: 0.8302 - val_loss: 0.5276 - val_accuracy: 0.7447\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.4575 - accuracy: 0.8302 - val_loss: 0.5253 - val_accuracy: 0.7447\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.4536 - accuracy: 0.8302 - val_loss: 0.5230 - val_accuracy: 0.7447\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.4500 - accuracy: 0.8113 - val_loss: 0.5208 - val_accuracy: 0.7234\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.4470 - accuracy: 0.8113 - val_loss: 0.5191 - val_accuracy: 0.7234\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.4427 - accuracy: 0.8302 - val_loss: 0.5173 - val_accuracy: 0.7447\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 261us/step - loss: 0.4398 - accuracy: 0.8302 - val_loss: 0.5158 - val_accuracy: 0.7447\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.4361 - accuracy: 0.8302 - val_loss: 0.5141 - val_accuracy: 0.7447\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.4336 - accuracy: 0.8302 - val_loss: 0.5124 - val_accuracy: 0.7447\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.4300 - accuracy: 0.8302 - val_loss: 0.5105 - val_accuracy: 0.7447\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 154us/step - loss: 0.4273 - accuracy: 0.8302 - val_loss: 0.5086 - val_accuracy: 0.7447\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.4245 - accuracy: 0.8302 - val_loss: 0.5071 - val_accuracy: 0.7447\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.4222 - accuracy: 0.8302 - val_loss: 0.5055 - val_accuracy: 0.7447\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.4191 - accuracy: 0.8302 - val_loss: 0.5043 - val_accuracy: 0.7447\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.4166 - accuracy: 0.8491 - val_loss: 0.5032 - val_accuracy: 0.7447\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.4140 - accuracy: 0.8491 - val_loss: 0.5020 - val_accuracy: 0.7447\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.4111 - accuracy: 0.8491 - val_loss: 0.5007 - val_accuracy: 0.7447\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.4094 - accuracy: 0.8491 - val_loss: 0.4996 - val_accuracy: 0.7447\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.4065 - accuracy: 0.8491 - val_loss: 0.4988 - val_accuracy: 0.7447\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.4046 - accuracy: 0.8491 - val_loss: 0.4985 - val_accuracy: 0.7447\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 158us/step - loss: 0.4020 - accuracy: 0.8491 - val_loss: 0.4978 - val_accuracy: 0.7447\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 153us/step - loss: 0.4004 - accuracy: 0.8491 - val_loss: 0.4975 - val_accuracy: 0.7447\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.3980 - accuracy: 0.8491 - val_loss: 0.4966 - val_accuracy: 0.7447\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.3957 - accuracy: 0.8491 - val_loss: 0.4951 - val_accuracy: 0.7447\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.3936 - accuracy: 0.8491 - val_loss: 0.4935 - val_accuracy: 0.7447\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 225us/step - loss: 0.3921 - accuracy: 0.8491 - val_loss: 0.4921 - val_accuracy: 0.7447\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.3899 - accuracy: 0.8491 - val_loss: 0.4912 - val_accuracy: 0.7447\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.3879 - accuracy: 0.8491 - val_loss: 0.4903 - val_accuracy: 0.7447\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.3860 - accuracy: 0.8491 - val_loss: 0.4896 - val_accuracy: 0.7447\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.3844 - accuracy: 0.8491 - val_loss: 0.4891 - val_accuracy: 0.7447\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.3830 - accuracy: 0.8491 - val_loss: 0.4885 - val_accuracy: 0.7447\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.3807 - accuracy: 0.8491 - val_loss: 0.4875 - val_accuracy: 0.7447\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.3792 - accuracy: 0.8491 - val_loss: 0.4865 - val_accuracy: 0.7447\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.3773 - accuracy: 0.8491 - val_loss: 0.4860 - val_accuracy: 0.7447\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.3756 - accuracy: 0.8491 - val_loss: 0.4859 - val_accuracy: 0.7660\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.3740 - accuracy: 0.8679 - val_loss: 0.4856 - val_accuracy: 0.7660\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.3723 - accuracy: 0.8679 - val_loss: 0.4857 - val_accuracy: 0.7660\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.3705 - accuracy: 0.8679 - val_loss: 0.4863 - val_accuracy: 0.7660\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.3697 - accuracy: 0.8679 - val_loss: 0.4870 - val_accuracy: 0.7872\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.3680 - accuracy: 0.8679 - val_loss: 0.4866 - val_accuracy: 0.7872\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 368us/step - loss: 0.3667 - accuracy: 0.8679 - val_loss: 0.4859 - val_accuracy: 0.7872\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.3652 - accuracy: 0.8679 - val_loss: 0.4843 - val_accuracy: 0.7872\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 154us/step - loss: 0.3635 - accuracy: 0.8679 - val_loss: 0.4830 - val_accuracy: 0.7872\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.3618 - accuracy: 0.8679 - val_loss: 0.4822 - val_accuracy: 0.7872\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.3600 - accuracy: 0.8679 - val_loss: 0.4808 - val_accuracy: 0.7872\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.3605 - accuracy: 0.8679 - val_loss: 0.4799 - val_accuracy: 0.7872\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 261us/step - loss: 0.3572 - accuracy: 0.8679 - val_loss: 0.4775 - val_accuracy: 0.7660\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.3561 - accuracy: 0.8679 - val_loss: 0.4758 - val_accuracy: 0.7660\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 242us/step - loss: 0.3572 - accuracy: 0.8679 - val_loss: 0.4743 - val_accuracy: 0.7660\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.3549 - accuracy: 0.8679 - val_loss: 0.4746 - val_accuracy: 0.7660\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3527 - accuracy: 0.8679 - val_loss: 0.4748 - val_accuracy: 0.7872\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 255us/step - loss: 0.3513 - accuracy: 0.8679 - val_loss: 0.4756 - val_accuracy: 0.7872\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 252us/step - loss: 0.3497 - accuracy: 0.8679 - val_loss: 0.4761 - val_accuracy: 0.7872\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.3488 - accuracy: 0.8679 - val_loss: 0.4778 - val_accuracy: 0.7872\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.3471 - accuracy: 0.8679 - val_loss: 0.4783 - val_accuracy: 0.7872\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 241us/step - loss: 0.3457 - accuracy: 0.8679 - val_loss: 0.4796 - val_accuracy: 0.7872\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.3449 - accuracy: 0.8679 - val_loss: 0.4800 - val_accuracy: 0.7872\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.3436 - accuracy: 0.8491 - val_loss: 0.4804 - val_accuracy: 0.7872\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 158us/step - loss: 0.3426 - accuracy: 0.8491 - val_loss: 0.4800 - val_accuracy: 0.7872\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.3415 - accuracy: 0.8491 - val_loss: 0.4792 - val_accuracy: 0.7872\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 237us/step - loss: 0.3405 - accuracy: 0.8491 - val_loss: 0.4769 - val_accuracy: 0.7872\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.3386 - accuracy: 0.8679 - val_loss: 0.4755 - val_accuracy: 0.7872\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.3370 - accuracy: 0.8679 - val_loss: 0.4734 - val_accuracy: 0.7872\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.3363 - accuracy: 0.8679 - val_loss: 0.4709 - val_accuracy: 0.7872\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 159us/step - loss: 0.3355 - accuracy: 0.8679 - val_loss: 0.4695 - val_accuracy: 0.7872\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.3342 - accuracy: 0.8679 - val_loss: 0.4692 - val_accuracy: 0.7872\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.3330 - accuracy: 0.8679 - val_loss: 0.4698 - val_accuracy: 0.7872\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.3318 - accuracy: 0.8679 - val_loss: 0.4707 - val_accuracy: 0.7660\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.3308 - accuracy: 0.8679 - val_loss: 0.4731 - val_accuracy: 0.7660\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.3297 - accuracy: 0.8679 - val_loss: 0.4748 - val_accuracy: 0.7660\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.3283 - accuracy: 0.8679 - val_loss: 0.4751 - val_accuracy: 0.7660\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.3273 - accuracy: 0.8679 - val_loss: 0.4753 - val_accuracy: 0.7660\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.3265 - accuracy: 0.8679 - val_loss: 0.4747 - val_accuracy: 0.7660\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.3261 - accuracy: 0.8679 - val_loss: 0.4744 - val_accuracy: 0.7660\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.3252 - accuracy: 0.8679 - val_loss: 0.4763 - val_accuracy: 0.7660\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 150us/step - loss: 0.3232 - accuracy: 0.8679 - val_loss: 0.4755 - val_accuracy: 0.7660\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.3221 - accuracy: 0.8679 - val_loss: 0.4746 - val_accuracy: 0.7660\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.3212 - accuracy: 0.8679 - val_loss: 0.4738 - val_accuracy: 0.7660\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.3197 - accuracy: 0.8679 - val_loss: 0.4719 - val_accuracy: 0.7660\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.3190 - accuracy: 0.8679 - val_loss: 0.4698 - val_accuracy: 0.7660\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.3179 - accuracy: 0.8679 - val_loss: 0.4690 - val_accuracy: 0.7660\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.3171 - accuracy: 0.8679 - val_loss: 0.4683 - val_accuracy: 0.7660\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.3165 - accuracy: 0.8679 - val_loss: 0.4686 - val_accuracy: 0.7660\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.3161 - accuracy: 0.8679 - val_loss: 0.4688 - val_accuracy: 0.7660\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.3145 - accuracy: 0.8679 - val_loss: 0.4678 - val_accuracy: 0.7660\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.3135 - accuracy: 0.8679 - val_loss: 0.4665 - val_accuracy: 0.7660\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.3130 - accuracy: 0.8679 - val_loss: 0.4655 - val_accuracy: 0.7660\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.3123 - accuracy: 0.8679 - val_loss: 0.4657 - val_accuracy: 0.7660\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.3123 - accuracy: 0.8679 - val_loss: 0.4660 - val_accuracy: 0.7660\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 158us/step - loss: 0.3114 - accuracy: 0.8679 - val_loss: 0.4695 - val_accuracy: 0.7660\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.3091 - accuracy: 0.8679 - val_loss: 0.4717 - val_accuracy: 0.7660\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.3087 - accuracy: 0.8679 - val_loss: 0.4734 - val_accuracy: 0.7660\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.3075 - accuracy: 0.8868 - val_loss: 0.4770 - val_accuracy: 0.7660\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 165us/step - loss: 0.3069 - accuracy: 0.8868 - val_loss: 0.4792 - val_accuracy: 0.7660\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.3071 - accuracy: 0.8868 - val_loss: 0.4801 - val_accuracy: 0.7660\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.3062 - accuracy: 0.8679 - val_loss: 0.4824 - val_accuracy: 0.7660\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 145us/step - loss: 0.3058 - accuracy: 0.8679 - val_loss: 0.4821 - val_accuracy: 0.7660\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.3052 - accuracy: 0.8679 - val_loss: 0.4816 - val_accuracy: 0.7660\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.3044 - accuracy: 0.8679 - val_loss: 0.4819 - val_accuracy: 0.7660\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.3031 - accuracy: 0.8679 - val_loss: 0.4796 - val_accuracy: 0.7660\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.3021 - accuracy: 0.8868 - val_loss: 0.4765 - val_accuracy: 0.7660\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.3010 - accuracy: 0.8868 - val_loss: 0.4738 - val_accuracy: 0.7660\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 158us/step - loss: 0.3012 - accuracy: 0.9057 - val_loss: 0.4704 - val_accuracy: 0.7660\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.3001 - accuracy: 0.8868 - val_loss: 0.4694 - val_accuracy: 0.7660\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.3000 - accuracy: 0.8868 - val_loss: 0.4688 - val_accuracy: 0.7660\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.3007 - accuracy: 0.8868 - val_loss: 0.4703 - val_accuracy: 0.7660\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2985 - accuracy: 0.9057 - val_loss: 0.4700 - val_accuracy: 0.7660\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2985 - accuracy: 0.8868 - val_loss: 0.4701 - val_accuracy: 0.7660\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2982 - accuracy: 0.9057 - val_loss: 0.4727 - val_accuracy: 0.7660\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2970 - accuracy: 0.9057 - val_loss: 0.4742 - val_accuracy: 0.7660\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2960 - accuracy: 0.9057 - val_loss: 0.4751 - val_accuracy: 0.7660\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2955 - accuracy: 0.9057 - val_loss: 0.4756 - val_accuracy: 0.7660\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2954 - accuracy: 0.9057 - val_loss: 0.4763 - val_accuracy: 0.7660\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2955 - accuracy: 0.9057 - val_loss: 0.4749 - val_accuracy: 0.7660\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2940 - accuracy: 0.9057 - val_loss: 0.4759 - val_accuracy: 0.7660\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.2940 - accuracy: 0.9057 - val_loss: 0.4780 - val_accuracy: 0.7660\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 156us/step - loss: 0.2930 - accuracy: 0.9057 - val_loss: 0.4785 - val_accuracy: 0.7660\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2929 - accuracy: 0.8868 - val_loss: 0.4796 - val_accuracy: 0.7447\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2921 - accuracy: 0.9057 - val_loss: 0.4790 - val_accuracy: 0.7447\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 165us/step - loss: 0.2918 - accuracy: 0.9057 - val_loss: 0.4782 - val_accuracy: 0.7447\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.2912 - accuracy: 0.9057 - val_loss: 0.4784 - val_accuracy: 0.7447\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2913 - accuracy: 0.9057 - val_loss: 0.4779 - val_accuracy: 0.7447\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 352us/step - loss: 0.2905 - accuracy: 0.9057 - val_loss: 0.4795 - val_accuracy: 0.7447\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2913 - accuracy: 0.9057 - val_loss: 0.4797 - val_accuracy: 0.7447\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2903 - accuracy: 0.9057 - val_loss: 0.4834 - val_accuracy: 0.7447\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2894 - accuracy: 0.9057 - val_loss: 0.4844 - val_accuracy: 0.7447\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.2901 - accuracy: 0.9057 - val_loss: 0.4869 - val_accuracy: 0.7447\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2894 - accuracy: 0.8868 - val_loss: 0.4856 - val_accuracy: 0.7447\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2883 - accuracy: 0.9057 - val_loss: 0.4853 - val_accuracy: 0.7447\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2877 - accuracy: 0.9057 - val_loss: 0.4855 - val_accuracy: 0.7447\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2875 - accuracy: 0.9057 - val_loss: 0.4853 - val_accuracy: 0.7447\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2871 - accuracy: 0.9057 - val_loss: 0.4849 - val_accuracy: 0.7447\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2872 - accuracy: 0.9057 - val_loss: 0.4829 - val_accuracy: 0.7447\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2866 - accuracy: 0.9057 - val_loss: 0.4825 - val_accuracy: 0.7660\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 235us/step - loss: 0.2861 - accuracy: 0.9057 - val_loss: 0.4832 - val_accuracy: 0.7660\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 256us/step - loss: 0.2863 - accuracy: 0.9057 - val_loss: 0.4849 - val_accuracy: 0.7447\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.2857 - accuracy: 0.9057 - val_loss: 0.4852 - val_accuracy: 0.7447\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 325us/step - loss: 0.2851 - accuracy: 0.9057 - val_loss: 0.4840 - val_accuracy: 0.7660\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.2849 - accuracy: 0.9057 - val_loss: 0.4824 - val_accuracy: 0.7660\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.2853 - accuracy: 0.9057 - val_loss: 0.4816 - val_accuracy: 0.7660\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2850 - accuracy: 0.9057 - val_loss: 0.4835 - val_accuracy: 0.7660\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2841 - accuracy: 0.9057 - val_loss: 0.4842 - val_accuracy: 0.7660\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2839 - accuracy: 0.9057 - val_loss: 0.4853 - val_accuracy: 0.7660\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2836 - accuracy: 0.9057 - val_loss: 0.4860 - val_accuracy: 0.7660\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.2832 - accuracy: 0.9057 - val_loss: 0.4875 - val_accuracy: 0.7660\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.2838 - accuracy: 0.9057 - val_loss: 0.4892 - val_accuracy: 0.7660\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2829 - accuracy: 0.9057 - val_loss: 0.4886 - val_accuracy: 0.7660\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.2827 - accuracy: 0.9057 - val_loss: 0.4871 - val_accuracy: 0.7660\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.2823 - accuracy: 0.9057 - val_loss: 0.4866 - val_accuracy: 0.7660\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2841 - accuracy: 0.9057 - val_loss: 0.4855 - val_accuracy: 0.7660\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2819 - accuracy: 0.9057 - val_loss: 0.4881 - val_accuracy: 0.7660\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.2819 - accuracy: 0.9057 - val_loss: 0.4917 - val_accuracy: 0.7660\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2819 - accuracy: 0.9057 - val_loss: 0.4943 - val_accuracy: 0.7660\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2817 - accuracy: 0.9057 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.2812 - accuracy: 0.9057 - val_loss: 0.4950 - val_accuracy: 0.7660\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 151us/step - loss: 0.2818 - accuracy: 0.9057 - val_loss: 0.4962 - val_accuracy: 0.7447\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2809 - accuracy: 0.9057 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2810 - accuracy: 0.9057 - val_loss: 0.4925 - val_accuracy: 0.7660\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2808 - accuracy: 0.9057 - val_loss: 0.4917 - val_accuracy: 0.7660\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2802 - accuracy: 0.9057 - val_loss: 0.4932 - val_accuracy: 0.7660\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.2798 - accuracy: 0.9057 - val_loss: 0.4935 - val_accuracy: 0.7660\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2797 - accuracy: 0.9057 - val_loss: 0.4945 - val_accuracy: 0.7660\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.2800 - accuracy: 0.9057 - val_loss: 0.4945 - val_accuracy: 0.7660\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2811 - accuracy: 0.9057 - val_loss: 0.4974 - val_accuracy: 0.7660\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2827 - accuracy: 0.9057 - val_loss: 0.4954 - val_accuracy: 0.7660\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2800 - accuracy: 0.9057 - val_loss: 0.4987 - val_accuracy: 0.7660\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2789 - accuracy: 0.9057 - val_loss: 0.4991 - val_accuracy: 0.7660\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.2790 - accuracy: 0.9057 - val_loss: 0.4987 - val_accuracy: 0.7660\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2786 - accuracy: 0.9057 - val_loss: 0.4992 - val_accuracy: 0.7660\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.2788 - accuracy: 0.9057 - val_loss: 0.5002 - val_accuracy: 0.7660\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2783 - accuracy: 0.9057 - val_loss: 0.4991 - val_accuracy: 0.7660\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 155us/step - loss: 0.2781 - accuracy: 0.9057 - val_loss: 0.4977 - val_accuracy: 0.7660\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.2788 - accuracy: 0.9057 - val_loss: 0.4952 - val_accuracy: 0.7660\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2778 - accuracy: 0.9057 - val_loss: 0.4954 - val_accuracy: 0.7660\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.2777 - accuracy: 0.9057 - val_loss: 0.4960 - val_accuracy: 0.7660\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2776 - accuracy: 0.9057 - val_loss: 0.4967 - val_accuracy: 0.7660\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2777 - accuracy: 0.9057 - val_loss: 0.4987 - val_accuracy: 0.7660\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2777 - accuracy: 0.9057 - val_loss: 0.4998 - val_accuracy: 0.7660\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.2775 - accuracy: 0.9057 - val_loss: 0.4986 - val_accuracy: 0.7660\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2770 - accuracy: 0.9057 - val_loss: 0.4991 - val_accuracy: 0.7660\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 159us/step - loss: 0.2769 - accuracy: 0.9057 - val_loss: 0.4992 - val_accuracy: 0.7660\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2767 - accuracy: 0.9057 - val_loss: 0.4993 - val_accuracy: 0.7660\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2766 - accuracy: 0.9057 - val_loss: 0.4994 - val_accuracy: 0.7660\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 314us/step - loss: 0.2765 - accuracy: 0.9057 - val_loss: 0.5003 - val_accuracy: 0.7660\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2763 - accuracy: 0.9057 - val_loss: 0.5007 - val_accuracy: 0.7660\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2762 - accuracy: 0.9057 - val_loss: 0.5013 - val_accuracy: 0.7660\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2764 - accuracy: 0.9057 - val_loss: 0.5013 - val_accuracy: 0.7660\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 224us/step - loss: 0.2764 - accuracy: 0.9057 - val_loss: 0.5034 - val_accuracy: 0.7660\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 154us/step - loss: 0.2767 - accuracy: 0.9057 - val_loss: 0.5044 - val_accuracy: 0.7660\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2759 - accuracy: 0.9057 - val_loss: 0.5032 - val_accuracy: 0.7660\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2755 - accuracy: 0.9057 - val_loss: 0.5009 - val_accuracy: 0.7660\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2757 - accuracy: 0.9057 - val_loss: 0.4990 - val_accuracy: 0.7660\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2755 - accuracy: 0.9057 - val_loss: 0.4967 - val_accuracy: 0.7660\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2772 - accuracy: 0.9057 - val_loss: 0.4958 - val_accuracy: 0.7660\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2760 - accuracy: 0.9057 - val_loss: 0.4933 - val_accuracy: 0.7660\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2770 - accuracy: 0.9057 - val_loss: 0.4906 - val_accuracy: 0.7660\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.2774 - accuracy: 0.9057 - val_loss: 0.4911 - val_accuracy: 0.7660\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2773 - accuracy: 0.9057 - val_loss: 0.4933 - val_accuracy: 0.7660\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2775 - accuracy: 0.9057 - val_loss: 0.4957 - val_accuracy: 0.7660\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2759 - accuracy: 0.9057 - val_loss: 0.5030 - val_accuracy: 0.7660\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2744 - accuracy: 0.9057 - val_loss: 0.5092 - val_accuracy: 0.7660\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 378us/step - loss: 0.2742 - accuracy: 0.8868 - val_loss: 0.5140 - val_accuracy: 0.7660\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.2748 - accuracy: 0.8868 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 254us/step - loss: 0.2769 - accuracy: 0.8679 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 289us/step - loss: 0.2769 - accuracy: 0.8491 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2759 - accuracy: 0.8491 - val_loss: 0.5177 - val_accuracy: 0.7660\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2743 - accuracy: 0.8868 - val_loss: 0.5119 - val_accuracy: 0.7660\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2733 - accuracy: 0.8868 - val_loss: 0.5046 - val_accuracy: 0.7660\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2738 - accuracy: 0.9057 - val_loss: 0.4982 - val_accuracy: 0.7660\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2759 - accuracy: 0.9057 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 222us/step - loss: 0.2763 - accuracy: 0.9057 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 254us/step - loss: 0.2766 - accuracy: 0.9057 - val_loss: 0.4951 - val_accuracy: 0.7660\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 156us/step - loss: 0.2757 - accuracy: 0.9057 - val_loss: 0.4994 - val_accuracy: 0.7660\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2752 - accuracy: 0.9057 - val_loss: 0.5037 - val_accuracy: 0.7660\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2739 - accuracy: 0.9057 - val_loss: 0.5126 - val_accuracy: 0.7660\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2727 - accuracy: 0.9057 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2736 - accuracy: 0.8868 - val_loss: 0.5256 - val_accuracy: 0.7660\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2767 - accuracy: 0.8491 - val_loss: 0.5304 - val_accuracy: 0.7660\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2773 - accuracy: 0.8491 - val_loss: 0.5290 - val_accuracy: 0.7660\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.2762 - accuracy: 0.8491 - val_loss: 0.5274 - val_accuracy: 0.7660\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2756 - accuracy: 0.8491 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2737 - accuracy: 0.8868 - val_loss: 0.5174 - val_accuracy: 0.7660\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2740 - accuracy: 0.8868 - val_loss: 0.5112 - val_accuracy: 0.7660\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2754 - accuracy: 0.9057 - val_loss: 0.5069 - val_accuracy: 0.7660\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 157us/step - loss: 0.2734 - accuracy: 0.9057 - val_loss: 0.5068 - val_accuracy: 0.7660\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.2737 - accuracy: 0.9057 - val_loss: 0.5088 - val_accuracy: 0.7660\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 285us/step - loss: 0.2731 - accuracy: 0.9057 - val_loss: 0.5091 - val_accuracy: 0.7660\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.2735 - accuracy: 0.9057 - val_loss: 0.5103 - val_accuracy: 0.7660\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2730 - accuracy: 0.9057 - val_loss: 0.5145 - val_accuracy: 0.7660\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2736 - accuracy: 0.8868 - val_loss: 0.5176 - val_accuracy: 0.7660\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 252us/step - loss: 0.2728 - accuracy: 0.8868 - val_loss: 0.5175 - val_accuracy: 0.7660\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2738 - accuracy: 0.8868 - val_loss: 0.5185 - val_accuracy: 0.7660\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 260us/step - loss: 0.2727 - accuracy: 0.8868 - val_loss: 0.5157 - val_accuracy: 0.7660\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2723 - accuracy: 0.8868 - val_loss: 0.5139 - val_accuracy: 0.7660\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2724 - accuracy: 0.9057 - val_loss: 0.5124 - val_accuracy: 0.7660\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2751 - accuracy: 0.9057 - val_loss: 0.5106 - val_accuracy: 0.7660\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2723 - accuracy: 0.9057 - val_loss: 0.5138 - val_accuracy: 0.7660\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2726 - accuracy: 0.9057 - val_loss: 0.5161 - val_accuracy: 0.7660\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2717 - accuracy: 0.8868 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2720 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7872\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2732 - accuracy: 0.8679 - val_loss: 0.5279 - val_accuracy: 0.7660\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2752 - accuracy: 0.8679 - val_loss: 0.5268 - val_accuracy: 0.7660\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2730 - accuracy: 0.8679 - val_loss: 0.5284 - val_accuracy: 0.7660\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.2737 - accuracy: 0.8679 - val_loss: 0.5283 - val_accuracy: 0.7660\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.2741 - accuracy: 0.8679 - val_loss: 0.5237 - val_accuracy: 0.7872\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2727 - accuracy: 0.8868 - val_loss: 0.5206 - val_accuracy: 0.7660\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 187us/step - loss: 0.2717 - accuracy: 0.8868 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 247us/step - loss: 0.2717 - accuracy: 0.8868 - val_loss: 0.5174 - val_accuracy: 0.7660\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2715 - accuracy: 0.8868 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2714 - accuracy: 0.9057 - val_loss: 0.5130 - val_accuracy: 0.7660\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 156us/step - loss: 0.2714 - accuracy: 0.9057 - val_loss: 0.5097 - val_accuracy: 0.7660\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 230us/step - loss: 0.2728 - accuracy: 0.9057 - val_loss: 0.5073 - val_accuracy: 0.7660\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2726 - accuracy: 0.9057 - val_loss: 0.5080 - val_accuracy: 0.7660\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.2721 - accuracy: 0.9057 - val_loss: 0.5111 - val_accuracy: 0.7660\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2722 - accuracy: 0.9057 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2714 - accuracy: 0.9057 - val_loss: 0.5174 - val_accuracy: 0.7660\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2714 - accuracy: 0.8868 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2719 - accuracy: 0.8868 - val_loss: 0.5250 - val_accuracy: 0.7872\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2717 - accuracy: 0.8868 - val_loss: 0.5254 - val_accuracy: 0.7872\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2728 - accuracy: 0.8868 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2734 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2709 - accuracy: 0.8868 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2724 - accuracy: 0.8868 - val_loss: 0.5158 - val_accuracy: 0.7660\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2712 - accuracy: 0.9057 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2709 - accuracy: 0.9057 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 250us/step - loss: 0.2711 - accuracy: 0.8868 - val_loss: 0.5189 - val_accuracy: 0.7660\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2706 - accuracy: 0.8868 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.2717 - accuracy: 0.8868 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2710 - accuracy: 0.8868 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2704 - accuracy: 0.8868 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2706 - accuracy: 0.8868 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2701 - accuracy: 0.8868 - val_loss: 0.5141 - val_accuracy: 0.7660\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 291us/step - loss: 0.2708 - accuracy: 0.9057 - val_loss: 0.5108 - val_accuracy: 0.7660\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2713 - accuracy: 0.9057 - val_loss: 0.5096 - val_accuracy: 0.7660\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 159us/step - loss: 0.2725 - accuracy: 0.9057 - val_loss: 0.5096 - val_accuracy: 0.7660\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2720 - accuracy: 0.9057 - val_loss: 0.5083 - val_accuracy: 0.7660\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.2722 - accuracy: 0.9057 - val_loss: 0.5097 - val_accuracy: 0.7660\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 237us/step - loss: 0.2712 - accuracy: 0.9057 - val_loss: 0.5140 - val_accuracy: 0.7660\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2701 - accuracy: 0.9057 - val_loss: 0.5189 - val_accuracy: 0.7660\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2696 - accuracy: 0.8868 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 166us/step - loss: 0.2704 - accuracy: 0.8868 - val_loss: 0.5308 - val_accuracy: 0.7872\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.2713 - accuracy: 0.8679 - val_loss: 0.5341 - val_accuracy: 0.7872\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 151us/step - loss: 0.2712 - accuracy: 0.8679 - val_loss: 0.5336 - val_accuracy: 0.7872\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 251us/step - loss: 0.2718 - accuracy: 0.8679 - val_loss: 0.5316 - val_accuracy: 0.7872\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2707 - accuracy: 0.8868 - val_loss: 0.5309 - val_accuracy: 0.7872\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2705 - accuracy: 0.8868 - val_loss: 0.5290 - val_accuracy: 0.7872\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2709 - accuracy: 0.8868 - val_loss: 0.5260 - val_accuracy: 0.7660\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.2700 - accuracy: 0.8868 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2710 - accuracy: 0.8868 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2700 - accuracy: 0.8868 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.2697 - accuracy: 0.8868 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2704 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2696 - accuracy: 0.8868 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2696 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.2696 - accuracy: 0.8868 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2699 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2694 - accuracy: 0.8868 - val_loss: 0.5234 - val_accuracy: 0.7660\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.2693 - accuracy: 0.8868 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2693 - accuracy: 0.8868 - val_loss: 0.5204 - val_accuracy: 0.7660\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2694 - accuracy: 0.8868 - val_loss: 0.5197 - val_accuracy: 0.7660\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2695 - accuracy: 0.8868 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 242us/step - loss: 0.2707 - accuracy: 0.9057 - val_loss: 0.5174 - val_accuracy: 0.7660\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 306us/step - loss: 0.2695 - accuracy: 0.8868 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.2710 - accuracy: 0.8868 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 248us/step - loss: 0.2707 - accuracy: 0.8868 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2692 - accuracy: 0.8868 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 187us/step - loss: 0.2692 - accuracy: 0.8868 - val_loss: 0.5188 - val_accuracy: 0.7660\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.2715 - accuracy: 0.8868 - val_loss: 0.5163 - val_accuracy: 0.7660\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2695 - accuracy: 0.9057 - val_loss: 0.5183 - val_accuracy: 0.7660\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2692 - accuracy: 0.8868 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.2692 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2688 - accuracy: 0.8868 - val_loss: 0.5266 - val_accuracy: 0.7660\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2692 - accuracy: 0.8868 - val_loss: 0.5285 - val_accuracy: 0.7660\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.5324 - val_accuracy: 0.7872\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2693 - accuracy: 0.8868 - val_loss: 0.5355 - val_accuracy: 0.7872\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.2701 - accuracy: 0.8868 - val_loss: 0.5357 - val_accuracy: 0.7872\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.2703 - accuracy: 0.8868 - val_loss: 0.5373 - val_accuracy: 0.7872\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2721 - accuracy: 0.8679 - val_loss: 0.5363 - val_accuracy: 0.7872\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.5298 - val_accuracy: 0.7660\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2695 - accuracy: 0.8868 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2723 - accuracy: 0.9057 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2706 - accuracy: 0.9057 - val_loss: 0.5162 - val_accuracy: 0.7660\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 237us/step - loss: 0.2711 - accuracy: 0.9057 - val_loss: 0.5147 - val_accuracy: 0.7660\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2699 - accuracy: 0.9057 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2692 - accuracy: 0.9057 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2691 - accuracy: 0.9057 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2684 - accuracy: 0.8868 - val_loss: 0.5261 - val_accuracy: 0.7660\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2683 - accuracy: 0.8868 - val_loss: 0.5283 - val_accuracy: 0.7660\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 268us/step - loss: 0.2700 - accuracy: 0.8868 - val_loss: 0.5324 - val_accuracy: 0.7872\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2686 - accuracy: 0.8868 - val_loss: 0.5324 - val_accuracy: 0.7872\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2693 - accuracy: 0.8868 - val_loss: 0.5319 - val_accuracy: 0.7660\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2698 - accuracy: 0.8868 - val_loss: 0.5272 - val_accuracy: 0.7660\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2682 - accuracy: 0.8868 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2683 - accuracy: 0.8868 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 230us/step - loss: 0.2681 - accuracy: 0.8868 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 270us/step - loss: 0.2684 - accuracy: 0.8868 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.2683 - accuracy: 0.9057 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2690 - accuracy: 0.9057 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.2681 - accuracy: 0.9057 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2682 - accuracy: 0.8868 - val_loss: 0.5278 - val_accuracy: 0.7660\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2678 - accuracy: 0.8868 - val_loss: 0.5302 - val_accuracy: 0.7660\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2682 - accuracy: 0.8868 - val_loss: 0.5323 - val_accuracy: 0.7660\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2682 - accuracy: 0.8868 - val_loss: 0.5321 - val_accuracy: 0.7660\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2680 - accuracy: 0.8868 - val_loss: 0.5322 - val_accuracy: 0.7660\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2691 - accuracy: 0.8868 - val_loss: 0.5313 - val_accuracy: 0.7660\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 230us/step - loss: 0.2681 - accuracy: 0.8868 - val_loss: 0.5331 - val_accuracy: 0.7872\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2690 - accuracy: 0.8868 - val_loss: 0.5336 - val_accuracy: 0.7872\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2680 - accuracy: 0.8868 - val_loss: 0.5309 - val_accuracy: 0.7660\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2678 - accuracy: 0.8868 - val_loss: 0.5257 - val_accuracy: 0.7660\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.2683 - accuracy: 0.8868 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 242us/step - loss: 0.2693 - accuracy: 0.8868 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 233us/step - loss: 0.2690 - accuracy: 0.9057 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2677 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2677 - accuracy: 0.8868 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 321us/step - loss: 0.2673 - accuracy: 0.8868 - val_loss: 0.5286 - val_accuracy: 0.7660\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2674 - accuracy: 0.8868 - val_loss: 0.5314 - val_accuracy: 0.7660\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 238us/step - loss: 0.2675 - accuracy: 0.8868 - val_loss: 0.5354 - val_accuracy: 0.7872\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2677 - accuracy: 0.8868 - val_loss: 0.5374 - val_accuracy: 0.7872\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2682 - accuracy: 0.8868 - val_loss: 0.5384 - val_accuracy: 0.7872\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2686 - accuracy: 0.8868 - val_loss: 0.5387 - val_accuracy: 0.7872\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2682 - accuracy: 0.8868 - val_loss: 0.5389 - val_accuracy: 0.7872\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2681 - accuracy: 0.8868 - val_loss: 0.5387 - val_accuracy: 0.7872\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 230us/step - loss: 0.2686 - accuracy: 0.8868 - val_loss: 0.5367 - val_accuracy: 0.7872\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2685 - accuracy: 0.8868 - val_loss: 0.5365 - val_accuracy: 0.7872\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2675 - accuracy: 0.8868 - val_loss: 0.5324 - val_accuracy: 0.7660\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2672 - accuracy: 0.8868 - val_loss: 0.5281 - val_accuracy: 0.7660\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 323us/step - loss: 0.2669 - accuracy: 0.8868 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2672 - accuracy: 0.8868 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2673 - accuracy: 0.9057 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2676 - accuracy: 0.9057 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 249us/step - loss: 0.2674 - accuracy: 0.9057 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 230us/step - loss: 0.2676 - accuracy: 0.9057 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 271us/step - loss: 0.2676 - accuracy: 0.9057 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.2678 - accuracy: 0.9057 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.2677 - accuracy: 0.8868 - val_loss: 0.5262 - val_accuracy: 0.7660\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.5287 - val_accuracy: 0.7660\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.5319 - val_accuracy: 0.7660\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 252us/step - loss: 0.2681 - accuracy: 0.8868 - val_loss: 0.5353 - val_accuracy: 0.7872\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.2672 - accuracy: 0.8868 - val_loss: 0.5349 - val_accuracy: 0.7872\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 225us/step - loss: 0.2669 - accuracy: 0.8868 - val_loss: 0.5325 - val_accuracy: 0.7660\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2676 - accuracy: 0.8868 - val_loss: 0.5292 - val_accuracy: 0.7660\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.5285 - val_accuracy: 0.7660\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.5271 - val_accuracy: 0.7660\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2669 - accuracy: 0.8868 - val_loss: 0.5260 - val_accuracy: 0.7660\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2665 - accuracy: 0.8868 - val_loss: 0.5269 - val_accuracy: 0.7660\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2671 - accuracy: 0.8868 - val_loss: 0.5282 - val_accuracy: 0.7660\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 268us/step - loss: 0.2664 - accuracy: 0.8868 - val_loss: 0.5272 - val_accuracy: 0.7660\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2664 - accuracy: 0.8868 - val_loss: 0.5268 - val_accuracy: 0.7660\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2664 - accuracy: 0.8868 - val_loss: 0.5260 - val_accuracy: 0.7660\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.5265 - val_accuracy: 0.7660\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2663 - accuracy: 0.8868 - val_loss: 0.5256 - val_accuracy: 0.7660\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2665 - accuracy: 0.8868 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2669 - accuracy: 0.8868 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 265us/step - loss: 0.2664 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2663 - accuracy: 0.8868 - val_loss: 0.5267 - val_accuracy: 0.7660\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.2662 - accuracy: 0.8868 - val_loss: 0.5297 - val_accuracy: 0.7660\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 227us/step - loss: 0.2690 - accuracy: 0.8868 - val_loss: 0.5349 - val_accuracy: 0.7872\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.5340 - val_accuracy: 0.7660\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2663 - accuracy: 0.8868 - val_loss: 0.5334 - val_accuracy: 0.7660\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.5331 - val_accuracy: 0.7660\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2662 - accuracy: 0.8868 - val_loss: 0.5298 - val_accuracy: 0.7660\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 155us/step - loss: 0.2658 - accuracy: 0.8868 - val_loss: 0.5274 - val_accuracy: 0.7660\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2664 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2662 - accuracy: 0.8868 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2661 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2662 - accuracy: 0.8868 - val_loss: 0.5264 - val_accuracy: 0.7660\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.5273 - val_accuracy: 0.7660\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2658 - accuracy: 0.8868 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2657 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2660 - accuracy: 0.8868 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.2702 - accuracy: 0.8868 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.2661 - accuracy: 0.9057 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2656 - accuracy: 0.8868 - val_loss: 0.5263 - val_accuracy: 0.7660\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2654 - accuracy: 0.8868 - val_loss: 0.5297 - val_accuracy: 0.7660\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2654 - accuracy: 0.8868 - val_loss: 0.5338 - val_accuracy: 0.7660\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2657 - accuracy: 0.8868 - val_loss: 0.5364 - val_accuracy: 0.7872\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2660 - accuracy: 0.8868 - val_loss: 0.5382 - val_accuracy: 0.7872\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.2662 - accuracy: 0.8868 - val_loss: 0.5393 - val_accuracy: 0.7872\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2672 - accuracy: 0.8679 - val_loss: 0.5391 - val_accuracy: 0.7872\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 290us/step - loss: 0.2660 - accuracy: 0.8868 - val_loss: 0.5349 - val_accuracy: 0.7872\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5297 - val_accuracy: 0.7660\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2653 - accuracy: 0.9057 - val_loss: 0.5181 - val_accuracy: 0.7660\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2662 - accuracy: 0.9057 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2668 - accuracy: 0.9057 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2671 - accuracy: 0.9057 - val_loss: 0.5159 - val_accuracy: 0.7660\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2667 - accuracy: 0.9057 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 225us/step - loss: 0.2671 - accuracy: 0.9057 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.2656 - accuracy: 0.9057 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.5269 - val_accuracy: 0.7660\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.2654 - accuracy: 0.8868 - val_loss: 0.5288 - val_accuracy: 0.7660\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2671 - accuracy: 0.8868 - val_loss: 0.5281 - val_accuracy: 0.7660\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 292us/step - loss: 0.2650 - accuracy: 0.8868 - val_loss: 0.5319 - val_accuracy: 0.7660\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2653 - accuracy: 0.8868 - val_loss: 0.5338 - val_accuracy: 0.7660\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5377 - val_accuracy: 0.7872\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2654 - accuracy: 0.8868 - val_loss: 0.5392 - val_accuracy: 0.7872\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 258us/step - loss: 0.2656 - accuracy: 0.8868 - val_loss: 0.5390 - val_accuracy: 0.7872\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 239us/step - loss: 0.2669 - accuracy: 0.8868 - val_loss: 0.5373 - val_accuracy: 0.7872\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.5372 - val_accuracy: 0.7872\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.2658 - accuracy: 0.8868 - val_loss: 0.5402 - val_accuracy: 0.7872\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2658 - accuracy: 0.8868 - val_loss: 0.5392 - val_accuracy: 0.7872\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 222us/step - loss: 0.2657 - accuracy: 0.8868 - val_loss: 0.5385 - val_accuracy: 0.7872\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5346 - val_accuracy: 0.7660\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 224us/step - loss: 0.2647 - accuracy: 0.8868 - val_loss: 0.5309 - val_accuracy: 0.7660\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2644 - accuracy: 0.8868 - val_loss: 0.5258 - val_accuracy: 0.7660\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2658 - accuracy: 0.8868 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2654 - accuracy: 0.9057 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2652 - accuracy: 0.9057 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 254us/step - loss: 0.2650 - accuracy: 0.9057 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.2648 - accuracy: 0.9057 - val_loss: 0.5260 - val_accuracy: 0.7660\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 159us/step - loss: 0.2647 - accuracy: 0.8868 - val_loss: 0.5284 - val_accuracy: 0.7660\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2662 - accuracy: 0.8868 - val_loss: 0.5302 - val_accuracy: 0.7660\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2655 - accuracy: 0.8868 - val_loss: 0.5272 - val_accuracy: 0.7660\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2663 - accuracy: 0.8868 - val_loss: 0.5279 - val_accuracy: 0.7660\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2649 - accuracy: 0.8868 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 270us/step - loss: 0.2644 - accuracy: 0.9057 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2668 - accuracy: 0.9057 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2649 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2645 - accuracy: 0.9057 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2641 - accuracy: 0.9057 - val_loss: 0.5267 - val_accuracy: 0.7660\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2636 - accuracy: 0.8868 - val_loss: 0.5320 - val_accuracy: 0.7660\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.2642 - accuracy: 0.8868 - val_loss: 0.5373 - val_accuracy: 0.7872\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2646 - accuracy: 0.8868 - val_loss: 0.5398 - val_accuracy: 0.7872\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.2649 - accuracy: 0.8868 - val_loss: 0.5415 - val_accuracy: 0.7872\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2653 - accuracy: 0.8679 - val_loss: 0.5424 - val_accuracy: 0.7660\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 238us/step - loss: 0.2654 - accuracy: 0.8679 - val_loss: 0.5420 - val_accuracy: 0.7872\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 149us/step - loss: 0.2653 - accuracy: 0.8679 - val_loss: 0.5408 - val_accuracy: 0.7872\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 143us/step - loss: 0.2648 - accuracy: 0.8868 - val_loss: 0.5372 - val_accuracy: 0.7872\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2656 - accuracy: 0.8868 - val_loss: 0.5300 - val_accuracy: 0.7660\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 133us/step - loss: 0.2636 - accuracy: 0.8868 - val_loss: 0.5267 - val_accuracy: 0.7660\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 324us/step - loss: 0.2636 - accuracy: 0.8868 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 156us/step - loss: 0.2655 - accuracy: 0.9057 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2646 - accuracy: 0.9057 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.2647 - accuracy: 0.9057 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2639 - accuracy: 0.9057 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 272us/step - loss: 0.2644 - accuracy: 0.9057 - val_loss: 0.5264 - val_accuracy: 0.7660\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2634 - accuracy: 0.8868 - val_loss: 0.5315 - val_accuracy: 0.7660\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2635 - accuracy: 0.8868 - val_loss: 0.5357 - val_accuracy: 0.7660\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.2664 - accuracy: 0.8868 - val_loss: 0.5397 - val_accuracy: 0.7872\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2649 - accuracy: 0.8868 - val_loss: 0.5372 - val_accuracy: 0.7872\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2642 - accuracy: 0.8868 - val_loss: 0.5349 - val_accuracy: 0.7660\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 225us/step - loss: 0.2638 - accuracy: 0.8868 - val_loss: 0.5334 - val_accuracy: 0.7660\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2638 - accuracy: 0.8868 - val_loss: 0.5305 - val_accuracy: 0.7660\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2636 - accuracy: 0.8868 - val_loss: 0.5293 - val_accuracy: 0.7660\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2642 - accuracy: 0.8868 - val_loss: 0.5270 - val_accuracy: 0.7660\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2629 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7660\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 296us/step - loss: 0.2653 - accuracy: 0.9057 - val_loss: 0.5163 - val_accuracy: 0.7660\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.2643 - accuracy: 0.9057 - val_loss: 0.5157 - val_accuracy: 0.7660\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2643 - accuracy: 0.9057 - val_loss: 0.5168 - val_accuracy: 0.7660\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2650 - accuracy: 0.9057 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2637 - accuracy: 0.9057 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 279us/step - loss: 0.2638 - accuracy: 0.8868 - val_loss: 0.5261 - val_accuracy: 0.7660\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.2632 - accuracy: 0.8868 - val_loss: 0.5281 - val_accuracy: 0.7660\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2630 - accuracy: 0.8868 - val_loss: 0.5318 - val_accuracy: 0.7660\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 280us/step - loss: 0.2645 - accuracy: 0.8868 - val_loss: 0.5350 - val_accuracy: 0.7872\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2637 - accuracy: 0.8868 - val_loss: 0.5334 - val_accuracy: 0.7660\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2636 - accuracy: 0.8868 - val_loss: 0.5329 - val_accuracy: 0.7660\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2630 - accuracy: 0.8868 - val_loss: 0.5296 - val_accuracy: 0.7660\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2628 - accuracy: 0.8868 - val_loss: 0.5263 - val_accuracy: 0.7660\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 222us/step - loss: 0.2626 - accuracy: 0.8868 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 239us/step - loss: 0.2640 - accuracy: 0.9057 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2634 - accuracy: 0.9057 - val_loss: 0.5180 - val_accuracy: 0.7660\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2635 - accuracy: 0.9057 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2634 - accuracy: 0.9057 - val_loss: 0.5206 - val_accuracy: 0.7660\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2647 - accuracy: 0.9057 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2620 - accuracy: 0.9057 - val_loss: 0.5299 - val_accuracy: 0.7660\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 484us/step - loss: 0.2632 - accuracy: 0.8868 - val_loss: 0.5382 - val_accuracy: 0.7872\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2644 - accuracy: 0.8679 - val_loss: 0.5430 - val_accuracy: 0.7660\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2652 - accuracy: 0.8679 - val_loss: 0.5419 - val_accuracy: 0.7660\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2646 - accuracy: 0.8679 - val_loss: 0.5416 - val_accuracy: 0.7660\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2640 - accuracy: 0.8679 - val_loss: 0.5420 - val_accuracy: 0.7660\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 230us/step - loss: 0.2641 - accuracy: 0.8679 - val_loss: 0.5417 - val_accuracy: 0.7660\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.2641 - accuracy: 0.8679 - val_loss: 0.5379 - val_accuracy: 0.7872\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2637 - accuracy: 0.8868 - val_loss: 0.5341 - val_accuracy: 0.7660\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.2627 - accuracy: 0.8868 - val_loss: 0.5315 - val_accuracy: 0.7660\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.2628 - accuracy: 0.8868 - val_loss: 0.5285 - val_accuracy: 0.7660\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2625 - accuracy: 0.8868 - val_loss: 0.5272 - val_accuracy: 0.7660\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 0.2626 - accuracy: 0.9057 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2626 - accuracy: 0.9057 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 238us/step - loss: 0.2638 - accuracy: 0.9057 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2624 - accuracy: 0.9057 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2628 - accuracy: 0.9057 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.2628 - accuracy: 0.8868 - val_loss: 0.5263 - val_accuracy: 0.7660\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2629 - accuracy: 0.8868 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2622 - accuracy: 0.8868 - val_loss: 0.5264 - val_accuracy: 0.7660\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2622 - accuracy: 0.8868 - val_loss: 0.5285 - val_accuracy: 0.7660\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.2621 - accuracy: 0.8868 - val_loss: 0.5295 - val_accuracy: 0.7660\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2624 - accuracy: 0.8868 - val_loss: 0.5306 - val_accuracy: 0.7660\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2638 - accuracy: 0.8868 - val_loss: 0.5304 - val_accuracy: 0.7660\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2619 - accuracy: 0.8868 - val_loss: 0.5261 - val_accuracy: 0.7660\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2615 - accuracy: 0.8868 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 161us/step - loss: 0.2635 - accuracy: 0.9057 - val_loss: 0.5145 - val_accuracy: 0.7660\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2626 - accuracy: 0.9057 - val_loss: 0.5134 - val_accuracy: 0.7660\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2628 - accuracy: 0.9057 - val_loss: 0.5129 - val_accuracy: 0.7660\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 230us/step - loss: 0.2663 - accuracy: 0.9057 - val_loss: 0.5114 - val_accuracy: 0.7660\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 153us/step - loss: 0.2627 - accuracy: 0.9057 - val_loss: 0.5168 - val_accuracy: 0.7660\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2615 - accuracy: 0.9057 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2614 - accuracy: 0.8868 - val_loss: 0.5279 - val_accuracy: 0.7660\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.2620 - accuracy: 0.8868 - val_loss: 0.5329 - val_accuracy: 0.7872\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 259us/step - loss: 0.2646 - accuracy: 0.8679 - val_loss: 0.5363 - val_accuracy: 0.7872\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2629 - accuracy: 0.8679 - val_loss: 0.5337 - val_accuracy: 0.7872\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2625 - accuracy: 0.8868 - val_loss: 0.5299 - val_accuracy: 0.7660\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2619 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2624 - accuracy: 0.9057 - val_loss: 0.5172 - val_accuracy: 0.7660\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2617 - accuracy: 0.9057 - val_loss: 0.5153 - val_accuracy: 0.7660\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2618 - accuracy: 0.9057 - val_loss: 0.5132 - val_accuracy: 0.7660\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2621 - accuracy: 0.9057 - val_loss: 0.5122 - val_accuracy: 0.7660\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.2623 - accuracy: 0.9057 - val_loss: 0.5123 - val_accuracy: 0.7660\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2621 - accuracy: 0.9057 - val_loss: 0.5146 - val_accuracy: 0.7660\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2616 - accuracy: 0.9057 - val_loss: 0.5180 - val_accuracy: 0.7660\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 271us/step - loss: 0.2612 - accuracy: 0.9057 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2614 - accuracy: 0.8868 - val_loss: 0.5277 - val_accuracy: 0.7660\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2615 - accuracy: 0.8868 - val_loss: 0.5303 - val_accuracy: 0.7660\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2624 - accuracy: 0.8868 - val_loss: 0.5337 - val_accuracy: 0.7872\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.2622 - accuracy: 0.8868 - val_loss: 0.5335 - val_accuracy: 0.7872\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.2622 - accuracy: 0.8868 - val_loss: 0.5307 - val_accuracy: 0.7660\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 187us/step - loss: 0.2628 - accuracy: 0.8868 - val_loss: 0.5271 - val_accuracy: 0.7660\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.2615 - accuracy: 0.8868 - val_loss: 0.5264 - val_accuracy: 0.7660\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2651 - accuracy: 0.8868 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 155us/step - loss: 0.2612 - accuracy: 0.9057 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2616 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 0.2626 - accuracy: 0.8868 - val_loss: 0.5285 - val_accuracy: 0.7660\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2615 - accuracy: 0.8868 - val_loss: 0.5273 - val_accuracy: 0.7660\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 222us/step - loss: 0.2613 - accuracy: 0.8868 - val_loss: 0.5269 - val_accuracy: 0.7660\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2613 - accuracy: 0.8868 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2611 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2611 - accuracy: 0.8868 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2609 - accuracy: 0.8868 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2615 - accuracy: 0.8868 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2609 - accuracy: 0.8868 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2606 - accuracy: 0.9057 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2609 - accuracy: 0.9057 - val_loss: 0.5120 - val_accuracy: 0.7660\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2623 - accuracy: 0.9057 - val_loss: 0.5099 - val_accuracy: 0.7660\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 242us/step - loss: 0.2621 - accuracy: 0.9057 - val_loss: 0.5111 - val_accuracy: 0.7660\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2616 - accuracy: 0.9057 - val_loss: 0.5158 - val_accuracy: 0.7660\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2607 - accuracy: 0.9057 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.2604 - accuracy: 0.8868 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2610 - accuracy: 0.8868 - val_loss: 0.5295 - val_accuracy: 0.7660\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2610 - accuracy: 0.8868 - val_loss: 0.5321 - val_accuracy: 0.7872\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 166us/step - loss: 0.2616 - accuracy: 0.8868 - val_loss: 0.5322 - val_accuracy: 0.7872\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2614 - accuracy: 0.8868 - val_loss: 0.5335 - val_accuracy: 0.7872\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2624 - accuracy: 0.8868 - val_loss: 0.5308 - val_accuracy: 0.7660\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 322us/step - loss: 0.2611 - accuracy: 0.8868 - val_loss: 0.5308 - val_accuracy: 0.7660\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.2610 - accuracy: 0.8868 - val_loss: 0.5277 - val_accuracy: 0.7660\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.2616 - accuracy: 0.8868 - val_loss: 0.5267 - val_accuracy: 0.7660\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.2653 - accuracy: 0.8868 - val_loss: 0.5206 - val_accuracy: 0.7660\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2604 - accuracy: 0.9057 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2605 - accuracy: 0.9057 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 250us/step - loss: 0.2615 - accuracy: 0.9057 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.2602 - accuracy: 0.9057 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 150us/step - loss: 0.2602 - accuracy: 0.8868 - val_loss: 0.5272 - val_accuracy: 0.7660\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 286us/step - loss: 0.2603 - accuracy: 0.8868 - val_loss: 0.5292 - val_accuracy: 0.7660\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2616 - accuracy: 0.8868 - val_loss: 0.5312 - val_accuracy: 0.7660\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2608 - accuracy: 0.8868 - val_loss: 0.5293 - val_accuracy: 0.7660\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2605 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 335us/step - loss: 0.2603 - accuracy: 0.9057 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.2605 - accuracy: 0.9057 - val_loss: 0.5174 - val_accuracy: 0.7660\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.2605 - accuracy: 0.9057 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2604 - accuracy: 0.9057 - val_loss: 0.5173 - val_accuracy: 0.7660\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2600 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2603 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2628 - accuracy: 0.8868 - val_loss: 0.5258 - val_accuracy: 0.7660\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2609 - accuracy: 0.8868 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 235us/step - loss: 0.2603 - accuracy: 0.8868 - val_loss: 0.5211 - val_accuracy: 0.7660\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 258us/step - loss: 0.2619 - accuracy: 0.8868 - val_loss: 0.5169 - val_accuracy: 0.7660\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.2600 - accuracy: 0.9057 - val_loss: 0.5167 - val_accuracy: 0.7660\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 232us/step - loss: 0.2599 - accuracy: 0.9057 - val_loss: 0.5177 - val_accuracy: 0.7660\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2607 - accuracy: 0.9057 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2601 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7660\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2601 - accuracy: 0.8868 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 225us/step - loss: 0.2610 - accuracy: 0.8868 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2604 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 229us/step - loss: 0.2600 - accuracy: 0.8868 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2597 - accuracy: 0.8868 - val_loss: 0.5176 - val_accuracy: 0.7660\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2619 - accuracy: 0.8868 - val_loss: 0.5139 - val_accuracy: 0.7660\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 242us/step - loss: 0.2599 - accuracy: 0.9057 - val_loss: 0.5153 - val_accuracy: 0.7660\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2598 - accuracy: 0.9057 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.2597 - accuracy: 0.9057 - val_loss: 0.5171 - val_accuracy: 0.7660\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.2594 - accuracy: 0.9057 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2600 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.2598 - accuracy: 0.8868 - val_loss: 0.5262 - val_accuracy: 0.7660\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2597 - accuracy: 0.8868 - val_loss: 0.5256 - val_accuracy: 0.7660\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2602 - accuracy: 0.8868 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2599 - accuracy: 0.8868 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2595 - accuracy: 0.9057 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2601 - accuracy: 0.9057 - val_loss: 0.5177 - val_accuracy: 0.7660\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 155us/step - loss: 0.2609 - accuracy: 0.9057 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2593 - accuracy: 0.9057 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 227us/step - loss: 0.2593 - accuracy: 0.9057 - val_loss: 0.5165 - val_accuracy: 0.7660\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2594 - accuracy: 0.9057 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2615 - accuracy: 0.9057 - val_loss: 0.5162 - val_accuracy: 0.7660\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.2592 - accuracy: 0.9057 - val_loss: 0.5134 - val_accuracy: 0.7660\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2598 - accuracy: 0.9057 - val_loss: 0.5112 - val_accuracy: 0.7660\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2609 - accuracy: 0.9057 - val_loss: 0.5109 - val_accuracy: 0.7660\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2600 - accuracy: 0.9057 - val_loss: 0.5151 - val_accuracy: 0.7660\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 241us/step - loss: 0.2590 - accuracy: 0.9057 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.2597 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7660\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.2591 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2594 - accuracy: 0.8868 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2593 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2601 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7660\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2601 - accuracy: 0.9057 - val_loss: 0.5157 - val_accuracy: 0.7660\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2590 - accuracy: 0.9057 - val_loss: 0.5130 - val_accuracy: 0.7660\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2592 - accuracy: 0.9057 - val_loss: 0.5117 - val_accuracy: 0.7660\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2595 - accuracy: 0.9057 - val_loss: 0.5115 - val_accuracy: 0.7660\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2595 - accuracy: 0.9057 - val_loss: 0.5125 - val_accuracy: 0.7660\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2595 - accuracy: 0.9057 - val_loss: 0.5153 - val_accuracy: 0.7660\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2592 - accuracy: 0.9057 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2613 - accuracy: 0.8868 - val_loss: 0.5262 - val_accuracy: 0.7660\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2593 - accuracy: 0.8868 - val_loss: 0.5259 - val_accuracy: 0.7660\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.2591 - accuracy: 0.8868 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.2588 - accuracy: 0.8868 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2604 - accuracy: 0.9057 - val_loss: 0.5149 - val_accuracy: 0.7660\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2588 - accuracy: 0.9057 - val_loss: 0.5143 - val_accuracy: 0.7660\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2588 - accuracy: 0.9057 - val_loss: 0.5142 - val_accuracy: 0.7660\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2586 - accuracy: 0.9057 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2587 - accuracy: 0.9057 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2588 - accuracy: 0.9057 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2585 - accuracy: 0.8868 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2588 - accuracy: 0.8868 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 311us/step - loss: 0.2587 - accuracy: 0.8868 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2588 - accuracy: 0.8868 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2589 - accuracy: 0.8868 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.2589 - accuracy: 0.8868 - val_loss: 0.5207 - val_accuracy: 0.7660\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 240us/step - loss: 0.2590 - accuracy: 0.8868 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.2601 - accuracy: 0.8868 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 237us/step - loss: 0.2587 - accuracy: 0.8868 - val_loss: 0.5143 - val_accuracy: 0.7660\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2587 - accuracy: 0.9057 - val_loss: 0.5116 - val_accuracy: 0.7660\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2584 - accuracy: 0.9057 - val_loss: 0.5111 - val_accuracy: 0.7660\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 310us/step - loss: 0.2584 - accuracy: 0.9057 - val_loss: 0.5103 - val_accuracy: 0.7660\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2585 - accuracy: 0.9057 - val_loss: 0.5105 - val_accuracy: 0.7660\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2587 - accuracy: 0.9057 - val_loss: 0.5117 - val_accuracy: 0.7660\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2586 - accuracy: 0.9057 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 233us/step - loss: 0.2585 - accuracy: 0.8868 - val_loss: 0.5177 - val_accuracy: 0.7660\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2587 - accuracy: 0.8868 - val_loss: 0.5180 - val_accuracy: 0.7660\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2582 - accuracy: 0.8868 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2588 - accuracy: 0.8868 - val_loss: 0.5207 - val_accuracy: 0.7660\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2589 - accuracy: 0.8868 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 174us/step - loss: 0.2580 - accuracy: 0.8868 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2585 - accuracy: 0.8868 - val_loss: 0.5299 - val_accuracy: 0.7660\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.2592 - accuracy: 0.8679 - val_loss: 0.5318 - val_accuracy: 0.7660\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.2592 - accuracy: 0.8679 - val_loss: 0.5309 - val_accuracy: 0.7660\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2590 - accuracy: 0.8679 - val_loss: 0.5283 - val_accuracy: 0.7660\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 262us/step - loss: 0.2584 - accuracy: 0.8868 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2579 - accuracy: 0.8868 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2577 - accuracy: 0.8868 - val_loss: 0.5186 - val_accuracy: 0.7660\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.2578 - accuracy: 0.9057 - val_loss: 0.5147 - val_accuracy: 0.7660\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 166us/step - loss: 0.2590 - accuracy: 0.9057 - val_loss: 0.5118 - val_accuracy: 0.7660\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2583 - accuracy: 0.9057 - val_loss: 0.5125 - val_accuracy: 0.7660\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2582 - accuracy: 0.9057 - val_loss: 0.5142 - val_accuracy: 0.7660\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.2586 - accuracy: 0.9057 - val_loss: 0.5178 - val_accuracy: 0.7660\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2579 - accuracy: 0.9057 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 236us/step - loss: 0.2577 - accuracy: 0.9057 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2583 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.2581 - accuracy: 0.8868 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 252us/step - loss: 0.2585 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 308us/step - loss: 0.2581 - accuracy: 0.8868 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 198us/step - loss: 0.2583 - accuracy: 0.8868 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2576 - accuracy: 0.8868 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2586 - accuracy: 0.8868 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2576 - accuracy: 0.9057 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2575 - accuracy: 0.8868 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 163us/step - loss: 0.2575 - accuracy: 0.8868 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2577 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2578 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2576 - accuracy: 0.8868 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 227us/step - loss: 0.2575 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 178us/step - loss: 0.2576 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2578 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2578 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 168us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2578 - accuracy: 0.8868 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 214us/step - loss: 0.2576 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 221us/step - loss: 0.2573 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2579 - accuracy: 0.8868 - val_loss: 0.5267 - val_accuracy: 0.7660\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2575 - accuracy: 0.8868 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2576 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.2584 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7660\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2571 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 160us/step - loss: 0.2572 - accuracy: 0.8868 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2583 - accuracy: 0.8868 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2571 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 244us/step - loss: 0.2572 - accuracy: 0.8868 - val_loss: 0.5272 - val_accuracy: 0.7660\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 257us/step - loss: 0.2583 - accuracy: 0.8679 - val_loss: 0.5286 - val_accuracy: 0.7660\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2577 - accuracy: 0.8679 - val_loss: 0.5263 - val_accuracy: 0.7660\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2575 - accuracy: 0.8868 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2575 - accuracy: 0.8868 - val_loss: 0.5183 - val_accuracy: 0.7660\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2567 - accuracy: 0.9057 - val_loss: 0.5168 - val_accuracy: 0.7660\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 193us/step - loss: 0.2588 - accuracy: 0.9057 - val_loss: 0.5144 - val_accuracy: 0.7660\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2570 - accuracy: 0.9057 - val_loss: 0.5161 - val_accuracy: 0.7660\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2567 - accuracy: 0.9057 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 401us/step - loss: 0.2567 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.2570 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7447\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2570 - accuracy: 0.8868 - val_loss: 0.5252 - val_accuracy: 0.7447\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 218us/step - loss: 0.2572 - accuracy: 0.8868 - val_loss: 0.5252 - val_accuracy: 0.7447\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 224us/step - loss: 0.2569 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2567 - accuracy: 0.8868 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2563 - accuracy: 0.9057 - val_loss: 0.5171 - val_accuracy: 0.7660\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2561 - accuracy: 0.9057 - val_loss: 0.5128 - val_accuracy: 0.7660\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 259us/step - loss: 0.2579 - accuracy: 0.9057 - val_loss: 0.5080 - val_accuracy: 0.7660\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.2605 - accuracy: 0.9057 - val_loss: 0.5061 - val_accuracy: 0.7660\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2580 - accuracy: 0.9057 - val_loss: 0.5104 - val_accuracy: 0.7660\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2578 - accuracy: 0.9057 - val_loss: 0.5159 - val_accuracy: 0.7660\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.2578 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 238us/step - loss: 0.2566 - accuracy: 0.8868 - val_loss: 0.5262 - val_accuracy: 0.7660\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 341us/step - loss: 0.2566 - accuracy: 0.8868 - val_loss: 0.5286 - val_accuracy: 0.7660\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 348us/step - loss: 0.2568 - accuracy: 0.8868 - val_loss: 0.5306 - val_accuracy: 0.7660\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 268us/step - loss: 0.2573 - accuracy: 0.8868 - val_loss: 0.5302 - val_accuracy: 0.7660\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 0.2576 - accuracy: 0.8868 - val_loss: 0.5297 - val_accuracy: 0.7660\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 260us/step - loss: 0.2572 - accuracy: 0.8868 - val_loss: 0.5318 - val_accuracy: 0.7660\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2571 - accuracy: 0.8679 - val_loss: 0.5306 - val_accuracy: 0.7660\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 241us/step - loss: 0.2568 - accuracy: 0.8868 - val_loss: 0.5294 - val_accuracy: 0.7447\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 238us/step - loss: 0.2566 - accuracy: 0.8868 - val_loss: 0.5257 - val_accuracy: 0.7660\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 241us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 0.2563 - accuracy: 0.9057 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2570 - accuracy: 0.9057 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2562 - accuracy: 0.9057 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 222us/step - loss: 0.2579 - accuracy: 0.8868 - val_loss: 0.5257 - val_accuracy: 0.7660\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2562 - accuracy: 0.8868 - val_loss: 0.5256 - val_accuracy: 0.7660\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 204us/step - loss: 0.2571 - accuracy: 0.8868 - val_loss: 0.5271 - val_accuracy: 0.7447\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 240us/step - loss: 0.2565 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 217us/step - loss: 0.2569 - accuracy: 0.8868 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2560 - accuracy: 0.8868 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2560 - accuracy: 0.8868 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 220us/step - loss: 0.2570 - accuracy: 0.8868 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 234us/step - loss: 0.2560 - accuracy: 0.8868 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 261us/step - loss: 0.2570 - accuracy: 0.9057 - val_loss: 0.5160 - val_accuracy: 0.7660\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 210us/step - loss: 0.2565 - accuracy: 0.9057 - val_loss: 0.5137 - val_accuracy: 0.7660\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2559 - accuracy: 0.9057 - val_loss: 0.5143 - val_accuracy: 0.7660\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5157 - val_accuracy: 0.7660\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 247us/step - loss: 0.2561 - accuracy: 0.9057 - val_loss: 0.5147 - val_accuracy: 0.7660\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2559 - accuracy: 0.9057 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5183 - val_accuracy: 0.7660\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2555 - accuracy: 0.8868 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2557 - accuracy: 0.8868 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 187us/step - loss: 0.2559 - accuracy: 0.8868 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2559 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.2561 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.2560 - accuracy: 0.8868 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.2557 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2561 - accuracy: 0.8868 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 211us/step - loss: 0.2555 - accuracy: 0.8868 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.5206 - val_accuracy: 0.7660\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.2562 - accuracy: 0.8868 - val_loss: 0.5167 - val_accuracy: 0.7660\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 224us/step - loss: 0.2555 - accuracy: 0.9057 - val_loss: 0.5163 - val_accuracy: 0.7660\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2554 - accuracy: 0.9057 - val_loss: 0.5150 - val_accuracy: 0.7660\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2559 - accuracy: 0.9057 - val_loss: 0.5147 - val_accuracy: 0.7660\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5120 - val_accuracy: 0.7660\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2559 - accuracy: 0.9057 - val_loss: 0.5121 - val_accuracy: 0.7660\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2554 - accuracy: 0.9057 - val_loss: 0.5140 - val_accuracy: 0.7660\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5172 - val_accuracy: 0.7660\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 200us/step - loss: 0.2555 - accuracy: 0.9057 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 216us/step - loss: 0.2562 - accuracy: 0.8868 - val_loss: 0.5177 - val_accuracy: 0.7660\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 267us/step - loss: 0.2550 - accuracy: 0.8868 - val_loss: 0.5143 - val_accuracy: 0.7660\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2554 - accuracy: 0.9057 - val_loss: 0.5109 - val_accuracy: 0.7660\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 298us/step - loss: 0.2553 - accuracy: 0.9057 - val_loss: 0.5090 - val_accuracy: 0.7660\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 241us/step - loss: 0.2553 - accuracy: 0.9057 - val_loss: 0.5089 - val_accuracy: 0.7660\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 482us/step - loss: 0.2554 - accuracy: 0.9057 - val_loss: 0.5097 - val_accuracy: 0.7660\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 274us/step - loss: 0.2554 - accuracy: 0.9057 - val_loss: 0.5098 - val_accuracy: 0.7660\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2553 - accuracy: 0.9057 - val_loss: 0.5088 - val_accuracy: 0.7660\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2560 - accuracy: 0.9057 - val_loss: 0.5086 - val_accuracy: 0.7660\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2549 - accuracy: 0.9057 - val_loss: 0.5117 - val_accuracy: 0.7660\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 201us/step - loss: 0.2547 - accuracy: 0.9057 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2559 - accuracy: 0.8868 - val_loss: 0.5207 - val_accuracy: 0.7660\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 242us/step - loss: 0.2555 - accuracy: 0.8679 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.2559 - accuracy: 0.8679 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 255us/step - loss: 0.2559 - accuracy: 0.8679 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 189us/step - loss: 0.2559 - accuracy: 0.8679 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 195us/step - loss: 0.2550 - accuracy: 0.8868 - val_loss: 0.5171 - val_accuracy: 0.7660\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2544 - accuracy: 0.8868 - val_loss: 0.5138 - val_accuracy: 0.7660\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2544 - accuracy: 0.9057 - val_loss: 0.5104 - val_accuracy: 0.7660\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2558 - accuracy: 0.9057 - val_loss: 0.5076 - val_accuracy: 0.7660\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 231us/step - loss: 0.2560 - accuracy: 0.9057 - val_loss: 0.5077 - val_accuracy: 0.7660\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 206us/step - loss: 0.2557 - accuracy: 0.9057 - val_loss: 0.5071 - val_accuracy: 0.7660\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2557 - accuracy: 0.9057 - val_loss: 0.5067 - val_accuracy: 0.7660\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2561 - accuracy: 0.9057 - val_loss: 0.5077 - val_accuracy: 0.7660\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2557 - accuracy: 0.9057 - val_loss: 0.5116 - val_accuracy: 0.7660\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2553 - accuracy: 0.9057 - val_loss: 0.5150 - val_accuracy: 0.7660\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 162us/step - loss: 0.2547 - accuracy: 0.9057 - val_loss: 0.5169 - val_accuracy: 0.7660\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2580 - accuracy: 0.8868 - val_loss: 0.5218 - val_accuracy: 0.7447\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2554 - accuracy: 0.8868 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 190us/step - loss: 0.2548 - accuracy: 0.8868 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 196us/step - loss: 0.2547 - accuracy: 0.8868 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.2548 - accuracy: 0.8868 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 223us/step - loss: 0.2545 - accuracy: 0.8868 - val_loss: 0.5167 - val_accuracy: 0.7660\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2554 - accuracy: 0.8868 - val_loss: 0.5160 - val_accuracy: 0.7660\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.2545 - accuracy: 0.8868 - val_loss: 0.5121 - val_accuracy: 0.7660\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2544 - accuracy: 0.9057 - val_loss: 0.5096 - val_accuracy: 0.7660\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2549 - accuracy: 0.9057 - val_loss: 0.5083 - val_accuracy: 0.7660\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 224us/step - loss: 0.2546 - accuracy: 0.9057 - val_loss: 0.5079 - val_accuracy: 0.7660\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 254us/step - loss: 0.2547 - accuracy: 0.9057 - val_loss: 0.5081 - val_accuracy: 0.7660\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 256us/step - loss: 0.2559 - accuracy: 0.9057 - val_loss: 0.5105 - val_accuracy: 0.7660\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 224us/step - loss: 0.2544 - accuracy: 0.9057 - val_loss: 0.5106 - val_accuracy: 0.7660\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 157us/step - loss: 0.2547 - accuracy: 0.9057 - val_loss: 0.5098 - val_accuracy: 0.7660\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2546 - accuracy: 0.9057 - val_loss: 0.5114 - val_accuracy: 0.7660\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 205us/step - loss: 0.2543 - accuracy: 0.9057 - val_loss: 0.5120 - val_accuracy: 0.7660\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2544 - accuracy: 0.9057 - val_loss: 0.5130 - val_accuracy: 0.7660\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 176us/step - loss: 0.2547 - accuracy: 0.9057 - val_loss: 0.5128 - val_accuracy: 0.7660\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.2543 - accuracy: 0.9057 - val_loss: 0.5142 - val_accuracy: 0.7660\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2546 - accuracy: 0.9057 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 171us/step - loss: 0.2541 - accuracy: 0.8868 - val_loss: 0.5142 - val_accuracy: 0.7660\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 180us/step - loss: 0.2541 - accuracy: 0.9057 - val_loss: 0.5127 - val_accuracy: 0.7660\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.2567 - accuracy: 0.9057 - val_loss: 0.5107 - val_accuracy: 0.7660\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2540 - accuracy: 0.9057 - val_loss: 0.5135 - val_accuracy: 0.7660\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 164us/step - loss: 0.2552 - accuracy: 0.8868 - val_loss: 0.5177 - val_accuracy: 0.7660\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2543 - accuracy: 0.8868 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 175us/step - loss: 0.2543 - accuracy: 0.8868 - val_loss: 0.5187 - val_accuracy: 0.7660\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 172us/step - loss: 0.2549 - accuracy: 0.8868 - val_loss: 0.5167 - val_accuracy: 0.7660\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2545 - accuracy: 0.8868 - val_loss: 0.5162 - val_accuracy: 0.7660\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 155us/step - loss: 0.2552 - accuracy: 0.8868 - val_loss: 0.5173 - val_accuracy: 0.7660\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2542 - accuracy: 0.8868 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 177us/step - loss: 0.2552 - accuracy: 0.8868 - val_loss: 0.5120 - val_accuracy: 0.7660\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2545 - accuracy: 0.8868 - val_loss: 0.5120 - val_accuracy: 0.7660\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2538 - accuracy: 0.8868 - val_loss: 0.5092 - val_accuracy: 0.7660\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2544 - accuracy: 0.9057 - val_loss: 0.5064 - val_accuracy: 0.7660\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2541 - accuracy: 0.9057 - val_loss: 0.5056 - val_accuracy: 0.7660\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2538 - accuracy: 0.9057 - val_loss: 0.5041 - val_accuracy: 0.7660\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 194us/step - loss: 0.2538 - accuracy: 0.9057 - val_loss: 0.5031 - val_accuracy: 0.7660\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2540 - accuracy: 0.9057 - val_loss: 0.5028 - val_accuracy: 0.7660\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2538 - accuracy: 0.9057 - val_loss: 0.5018 - val_accuracy: 0.7660\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2542 - accuracy: 0.9057 - val_loss: 0.5016 - val_accuracy: 0.7660\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 173us/step - loss: 0.2545 - accuracy: 0.9057 - val_loss: 0.4996 - val_accuracy: 0.7660\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 181us/step - loss: 0.2540 - accuracy: 0.9057 - val_loss: 0.5006 - val_accuracy: 0.7660\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2539 - accuracy: 0.9057 - val_loss: 0.5021 - val_accuracy: 0.7660\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2540 - accuracy: 0.9057 - val_loss: 0.5030 - val_accuracy: 0.7660\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 170us/step - loss: 0.2542 - accuracy: 0.9057 - val_loss: 0.5054 - val_accuracy: 0.7660\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 185us/step - loss: 0.2548 - accuracy: 0.8868 - val_loss: 0.5108 - val_accuracy: 0.7660\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 182us/step - loss: 0.2539 - accuracy: 0.8868 - val_loss: 0.5137 - val_accuracy: 0.7447\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 183us/step - loss: 0.2542 - accuracy: 0.8868 - val_loss: 0.5151 - val_accuracy: 0.7660\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 158us/step - loss: 0.2542 - accuracy: 0.8868 - val_loss: 0.5149 - val_accuracy: 0.7447\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2542 - accuracy: 0.8868 - val_loss: 0.5113 - val_accuracy: 0.7660\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2543 - accuracy: 0.9057 - val_loss: 0.5090 - val_accuracy: 0.7660\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 197us/step - loss: 0.2534 - accuracy: 0.9057 - val_loss: 0.5097 - val_accuracy: 0.7660\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 191us/step - loss: 0.2538 - accuracy: 0.9057 - val_loss: 0.5108 - val_accuracy: 0.7660\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2535 - accuracy: 0.9057 - val_loss: 0.5103 - val_accuracy: 0.7660\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 203us/step - loss: 0.2533 - accuracy: 0.9057 - val_loss: 0.5080 - val_accuracy: 0.7660\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 192us/step - loss: 0.2537 - accuracy: 0.9057 - val_loss: 0.5060 - val_accuracy: 0.7660\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 248us/step - loss: 0.2537 - accuracy: 0.9057 - val_loss: 0.5064 - val_accuracy: 0.7660\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 184us/step - loss: 0.2534 - accuracy: 0.9057 - val_loss: 0.5060 - val_accuracy: 0.7660\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 146us/step - loss: 0.2534 - accuracy: 0.9057 - val_loss: 0.5058 - val_accuracy: 0.7660\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 368us/step - loss: 0.2536 - accuracy: 0.9057 - val_loss: 0.5054 - val_accuracy: 0.7660\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 243us/step - loss: 0.2535 - accuracy: 0.9057 - val_loss: 0.5067 - val_accuracy: 0.7660\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 276us/step - loss: 0.2537 - accuracy: 0.9057 - val_loss: 0.5089 - val_accuracy: 0.7660\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 212us/step - loss: 0.2540 - accuracy: 0.9057 - val_loss: 0.5091 - val_accuracy: 0.7660\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 213us/step - loss: 0.2530 - accuracy: 0.9057 - val_loss: 0.5119 - val_accuracy: 0.7660\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 202us/step - loss: 0.2536 - accuracy: 0.9057 - val_loss: 0.5155 - val_accuracy: 0.7447\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2532 - accuracy: 0.8868 - val_loss: 0.5169 - val_accuracy: 0.7447\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 219us/step - loss: 0.2541 - accuracy: 0.8868 - val_loss: 0.5164 - val_accuracy: 0.7447\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 179us/step - loss: 0.2532 - accuracy: 0.8868 - val_loss: 0.5185 - val_accuracy: 0.7660\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 199us/step - loss: 0.2533 - accuracy: 0.8679 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 0.2543 - accuracy: 0.8679 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 209us/step - loss: 0.2534 - accuracy: 0.8679 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 208us/step - loss: 0.2535 - accuracy: 0.8679 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 186us/step - loss: 0.2541 - accuracy: 0.8679 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 215us/step - loss: 0.2533 - accuracy: 0.8679 - val_loss: 0.5201 - val_accuracy: 0.7660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pauHDvWiWkAJ"
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "QTmYr4YdWkAQ",
    "outputId": "a1f1818a-b4a0-4070-b5d9-867888d34764"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
      "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2ab7837ef0>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# svm = SVC(C=0.5, kernel='linear')\n",
    "# svm.fit(X_test, y_test)\n",
    "\n",
    "plot_decision_regions(X_train, y_train, clf=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "yamZMPJLWkAT",
    "outputId": "e0b8f1db-9a75-4ead-a13a-b3a0a52d2a4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
      "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2aa38d8978>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_regions(X_train, y_train, clf=model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veO7mTaHozZA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AD_Z11_B_EarlyStopping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
