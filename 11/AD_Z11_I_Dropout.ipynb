{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "AD_Z11_I_Dropout.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SgjMzpIiEKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a70b06ef-aa6d-4560-f5c8-411df55888bb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)\n",
        "\n",
        "print(keras.__version__)\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(123)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0QCMWcxKE18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "e93c851a-e587-4b18-c731-061e73e51854"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT7d7aKTKK2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f218e69c-b709-42fa-d904-1e95347a40a5"
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyLWkvRKiEK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4dabbf2c-7488-4bda-f63d-f28bd83a2d20"
      },
      "source": [
        "# Wczytaj dane treningowe i testowe\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
        "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
        "\n",
        "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
        "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
        "             'wage_class']\n",
        "train_set.columns = col_labels\n",
        "test_set.columns = col_labels\n",
        "\n",
        "train = train_set.replace('?', np.nan).dropna()\n",
        "test = test_set.replace('?', np.nan).dropna()\n",
        "\n",
        "train_set.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>wage_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  ... hours_per_week  native_country wage_class\n",
              "0   39         State-gov   77516  ...             40   United-States      <=50K\n",
              "1   50  Self-emp-not-inc   83311  ...             13   United-States      <=50K\n",
              "2   38           Private  215646  ...             40   United-States      <=50K\n",
              "3   53           Private  234721  ...             40   United-States      <=50K\n",
              "4   28           Private  338409  ...             40            Cuba      <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHrovTxvKEGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1A_WAN1iELJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c90f31a0-6456-4753-9456-26c965ceb935"
      },
      "source": [
        "dataset = pd.concat([train,test])\n",
        "\n",
        "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
        "\n",
        "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
        "\n",
        "dataset.drop([\"education\"],axis=1,inplace=True)\n",
        "\n",
        "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
        "\n",
        "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
        "\n",
        "dataset['native_country'] = dataset['native_country'].replace(d)\n",
        "\n",
        "dataset = pd.get_dummies(dataset,drop_first=True)\n",
        "\n",
        "train = dataset.iloc[:train.shape[0]]\n",
        "test = dataset.iloc[train.shape[0]:]\n",
        "\n",
        "X_train = train.drop(\"wage_class\",axis=1)\n",
        "y_train = train.wage_class\n",
        "\n",
        "X_test = test.drop(\"wage_class\",axis=1)\n",
        "y_test = test.wage_class\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "X_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30162, 41)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15060, 41)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYpwjSJ3iELQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7d66153-c30b-4a9d-b2ba-cf35e27c22be"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from keras.callbacks import History\n",
        "\n",
        "# learning rate schedule\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.0001\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "\n",
        "history_Adam = History()\n",
        "model = Sequential()\n",
        "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(50,activation=\"sigmoid\"))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(10,activation=\"sigmoid\"))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
        "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, early_stopping])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               4200      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 9,771\n",
            "Trainable params: 9,771\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30162 samples, validate on 15060 samples\n",
            "Epoch 1/100\n",
            "30162/30162 [==============================] - 3s 84us/step - loss: 0.5906 - accuracy: 0.7223 - val_loss: 0.5417 - val_accuracy: 0.7543\n",
            "Epoch 2/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.5417 - accuracy: 0.7502 - val_loss: 0.4798 - val_accuracy: 0.7543\n",
            "Epoch 3/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.4769 - accuracy: 0.7725 - val_loss: 0.4143 - val_accuracy: 0.8107\n",
            "Epoch 4/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.4352 - accuracy: 0.7921 - val_loss: 0.3858 - val_accuracy: 0.8344\n",
            "Epoch 5/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.4154 - accuracy: 0.8048 - val_loss: 0.3727 - val_accuracy: 0.8374\n",
            "Epoch 6/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.4037 - accuracy: 0.8103 - val_loss: 0.3653 - val_accuracy: 0.8382\n",
            "Epoch 7/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3954 - accuracy: 0.8117 - val_loss: 0.3606 - val_accuracy: 0.8364\n",
            "Epoch 8/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3897 - accuracy: 0.8152 - val_loss: 0.3574 - val_accuracy: 0.8373\n",
            "Epoch 9/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3885 - accuracy: 0.8185 - val_loss: 0.3552 - val_accuracy: 0.8367\n",
            "Epoch 10/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3826 - accuracy: 0.8190 - val_loss: 0.3538 - val_accuracy: 0.8366\n",
            "Epoch 11/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3828 - accuracy: 0.8212 - val_loss: 0.3527 - val_accuracy: 0.8369\n",
            "Epoch 12/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3800 - accuracy: 0.8257 - val_loss: 0.3518 - val_accuracy: 0.8378\n",
            "Epoch 13/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3781 - accuracy: 0.8226 - val_loss: 0.3508 - val_accuracy: 0.8377\n",
            "Epoch 14/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3778 - accuracy: 0.8229 - val_loss: 0.3500 - val_accuracy: 0.8383\n",
            "Epoch 15/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3757 - accuracy: 0.8267 - val_loss: 0.3491 - val_accuracy: 0.8387\n",
            "Epoch 16/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3766 - accuracy: 0.8245 - val_loss: 0.3483 - val_accuracy: 0.8392\n",
            "Epoch 17/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3754 - accuracy: 0.8245 - val_loss: 0.3477 - val_accuracy: 0.8401\n",
            "Epoch 18/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3744 - accuracy: 0.8245 - val_loss: 0.3470 - val_accuracy: 0.8408\n",
            "Epoch 19/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3719 - accuracy: 0.8292 - val_loss: 0.3462 - val_accuracy: 0.8412\n",
            "Epoch 20/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3724 - accuracy: 0.8295 - val_loss: 0.3459 - val_accuracy: 0.8414\n",
            "Epoch 21/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3740 - accuracy: 0.8237 - val_loss: 0.3456 - val_accuracy: 0.8416\n",
            "Epoch 22/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3693 - accuracy: 0.8296 - val_loss: 0.3452 - val_accuracy: 0.8421\n",
            "Epoch 23/100\n",
            "30162/30162 [==============================] - 2s 69us/step - loss: 0.3717 - accuracy: 0.8270 - val_loss: 0.3450 - val_accuracy: 0.8420\n",
            "Epoch 24/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3733 - accuracy: 0.8266 - val_loss: 0.3447 - val_accuracy: 0.8424\n",
            "Epoch 25/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3725 - accuracy: 0.8266 - val_loss: 0.3444 - val_accuracy: 0.8425\n",
            "Epoch 26/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3710 - accuracy: 0.8273 - val_loss: 0.3442 - val_accuracy: 0.8426\n",
            "Epoch 27/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3693 - accuracy: 0.8294 - val_loss: 0.3438 - val_accuracy: 0.8425\n",
            "Epoch 28/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3693 - accuracy: 0.8287 - val_loss: 0.3436 - val_accuracy: 0.8426\n",
            "Epoch 29/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3676 - accuracy: 0.8331 - val_loss: 0.3432 - val_accuracy: 0.8434\n",
            "Epoch 30/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3688 - accuracy: 0.8303 - val_loss: 0.3431 - val_accuracy: 0.8432\n",
            "Epoch 31/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3657 - accuracy: 0.8309 - val_loss: 0.3429 - val_accuracy: 0.8433\n",
            "Epoch 32/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3697 - accuracy: 0.8298 - val_loss: 0.3428 - val_accuracy: 0.8433\n",
            "Epoch 33/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3680 - accuracy: 0.8294 - val_loss: 0.3427 - val_accuracy: 0.8435\n",
            "Epoch 34/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3698 - accuracy: 0.8278 - val_loss: 0.3426 - val_accuracy: 0.8435\n",
            "Epoch 35/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3677 - accuracy: 0.8292 - val_loss: 0.3424 - val_accuracy: 0.8436\n",
            "Epoch 36/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3676 - accuracy: 0.8305 - val_loss: 0.3423 - val_accuracy: 0.8434\n",
            "Epoch 37/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3673 - accuracy: 0.8296 - val_loss: 0.3421 - val_accuracy: 0.8440\n",
            "Epoch 38/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3711 - accuracy: 0.8276 - val_loss: 0.3420 - val_accuracy: 0.8444\n",
            "Epoch 39/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3680 - accuracy: 0.8292 - val_loss: 0.3419 - val_accuracy: 0.8444\n",
            "Epoch 40/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3663 - accuracy: 0.8310 - val_loss: 0.3419 - val_accuracy: 0.8444\n",
            "Epoch 41/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3677 - accuracy: 0.8316 - val_loss: 0.3418 - val_accuracy: 0.8442\n",
            "Epoch 42/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3676 - accuracy: 0.8310 - val_loss: 0.3417 - val_accuracy: 0.8442\n",
            "Epoch 43/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3676 - accuracy: 0.8286 - val_loss: 0.3416 - val_accuracy: 0.8446\n",
            "Epoch 44/100\n",
            "30162/30162 [==============================] - 2s 69us/step - loss: 0.3662 - accuracy: 0.8295 - val_loss: 0.3416 - val_accuracy: 0.8445\n",
            "Epoch 45/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3688 - accuracy: 0.8296 - val_loss: 0.3415 - val_accuracy: 0.8444\n",
            "Epoch 46/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3660 - accuracy: 0.8303 - val_loss: 0.3415 - val_accuracy: 0.8445\n",
            "Epoch 47/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3691 - accuracy: 0.8294 - val_loss: 0.3414 - val_accuracy: 0.8445\n",
            "Epoch 48/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3664 - accuracy: 0.8299 - val_loss: 0.3413 - val_accuracy: 0.8444\n",
            "Epoch 49/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3664 - accuracy: 0.8294 - val_loss: 0.3413 - val_accuracy: 0.8445\n",
            "Epoch 50/100\n",
            "30162/30162 [==============================] - 2s 69us/step - loss: 0.3643 - accuracy: 0.8308 - val_loss: 0.3413 - val_accuracy: 0.8446\n",
            "Epoch 51/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3640 - accuracy: 0.8316 - val_loss: 0.3412 - val_accuracy: 0.8446\n",
            "Epoch 52/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3681 - accuracy: 0.8308 - val_loss: 0.3412 - val_accuracy: 0.8446\n",
            "Epoch 53/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3635 - accuracy: 0.8308 - val_loss: 0.3411 - val_accuracy: 0.8445\n",
            "Epoch 54/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3650 - accuracy: 0.8313 - val_loss: 0.3411 - val_accuracy: 0.8446\n",
            "Epoch 55/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3671 - accuracy: 0.8322 - val_loss: 0.3411 - val_accuracy: 0.8446\n",
            "Epoch 56/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3668 - accuracy: 0.8316 - val_loss: 0.3411 - val_accuracy: 0.8448\n",
            "Epoch 57/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3678 - accuracy: 0.8312 - val_loss: 0.3410 - val_accuracy: 0.8448\n",
            "Epoch 58/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3649 - accuracy: 0.8301 - val_loss: 0.3410 - val_accuracy: 0.8446\n",
            "Epoch 59/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3674 - accuracy: 0.8303 - val_loss: 0.3410 - val_accuracy: 0.8448\n",
            "Epoch 60/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3675 - accuracy: 0.8315 - val_loss: 0.3410 - val_accuracy: 0.8446\n",
            "Epoch 61/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3677 - accuracy: 0.8300 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
            "Epoch 62/100\n",
            "30162/30162 [==============================] - 2s 64us/step - loss: 0.3681 - accuracy: 0.8311 - val_loss: 0.3409 - val_accuracy: 0.8447\n",
            "Epoch 63/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3669 - accuracy: 0.8291 - val_loss: 0.3409 - val_accuracy: 0.8447\n",
            "Epoch 64/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3649 - accuracy: 0.8312 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
            "Epoch 65/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3686 - accuracy: 0.8283 - val_loss: 0.3409 - val_accuracy: 0.8448\n",
            "Epoch 66/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3649 - accuracy: 0.8304 - val_loss: 0.3409 - val_accuracy: 0.8448\n",
            "Epoch 67/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3657 - accuracy: 0.8318 - val_loss: 0.3409 - val_accuracy: 0.8449\n",
            "Epoch 68/100\n",
            "30162/30162 [==============================] - 2s 69us/step - loss: 0.3662 - accuracy: 0.8302 - val_loss: 0.3409 - val_accuracy: 0.8450\n",
            "Epoch 69/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3655 - accuracy: 0.8311 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 70/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3645 - accuracy: 0.8310 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 71/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3655 - accuracy: 0.8332 - val_loss: 0.3408 - val_accuracy: 0.8448\n",
            "Epoch 72/100\n",
            "30162/30162 [==============================] - 2s 69us/step - loss: 0.3663 - accuracy: 0.8306 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
            "Epoch 73/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3662 - accuracy: 0.8296 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
            "Epoch 74/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3639 - accuracy: 0.8333 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 75/100\n",
            "30162/30162 [==============================] - 2s 69us/step - loss: 0.3660 - accuracy: 0.8307 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 76/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3659 - accuracy: 0.8308 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
            "Epoch 77/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3662 - accuracy: 0.8325 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 78/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3663 - accuracy: 0.8309 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 79/100\n",
            "30162/30162 [==============================] - 2s 71us/step - loss: 0.3651 - accuracy: 0.8315 - val_loss: 0.3408 - val_accuracy: 0.8449\n",
            "Epoch 80/100\n",
            "30162/30162 [==============================] - 2s 80us/step - loss: 0.3659 - accuracy: 0.8312 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 81/100\n",
            "30162/30162 [==============================] - 2s 76us/step - loss: 0.3637 - accuracy: 0.8303 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
            "Epoch 82/100\n",
            "30162/30162 [==============================] - 2s 77us/step - loss: 0.3654 - accuracy: 0.8315 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 83/100\n",
            "30162/30162 [==============================] - 2s 78us/step - loss: 0.3688 - accuracy: 0.8293 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 84/100\n",
            "30162/30162 [==============================] - 2s 70us/step - loss: 0.3657 - accuracy: 0.8321 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 85/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3643 - accuracy: 0.8310 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 86/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3659 - accuracy: 0.8291 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 87/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3662 - accuracy: 0.8308 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 88/100\n",
            "30162/30162 [==============================] - 2s 69us/step - loss: 0.3649 - accuracy: 0.8307 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 89/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3660 - accuracy: 0.8315 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 90/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3639 - accuracy: 0.8307 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 91/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3665 - accuracy: 0.8280 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 92/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3655 - accuracy: 0.8307 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 93/100\n",
            "30162/30162 [==============================] - 2s 65us/step - loss: 0.3664 - accuracy: 0.8310 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 94/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3658 - accuracy: 0.8309 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
            "Epoch 95/100\n",
            "30162/30162 [==============================] - 2s 68us/step - loss: 0.3649 - accuracy: 0.8301 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
            "Epoch 96/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3642 - accuracy: 0.8317 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
            "Epoch 97/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3669 - accuracy: 0.8278 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
            "Epoch 98/100\n",
            "30162/30162 [==============================] - 2s 66us/step - loss: 0.3638 - accuracy: 0.8316 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
            "Epoch 99/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3647 - accuracy: 0.8335 - val_loss: 0.3407 - val_accuracy: 0.8451\n",
            "Epoch 100/100\n",
            "30162/30162 [==============================] - 2s 67us/step - loss: 0.3633 - accuracy: 0.8323 - val_loss: 0.3407 - val_accuracy: 0.8451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd2a199b908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oD0yf-PiELW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ffd4a66c-652c-4488-e2d0-f4be21fac358"
      },
      "source": [
        "plt.plot(history_Adam.history['accuracy'], label = \"adam train\")\n",
        "plt.plot(history_Adam.history['val_accuracy'], label = \"adam test\")\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JowdheF9iELd",
        "colab_type": "text"
      },
      "source": [
        "# Zad.\n",
        "Do poniższego modelu dodaj\n",
        "```python\n",
        "model.add(Dropout(0.8))\n",
        "```\n",
        "w każdej warstwie.\n",
        "\n",
        "Zwizualizuj wyniki:\n",
        "\n",
        "* porównaj krzywe uczenia\n",
        "* narysuj granice decyzyjne (dane są w 2D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0qS9T9SiELf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ff15a30d-f086-4b94-e535-eb43a1e34917"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
        "\n",
        "n_train=53\n",
        "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
        "y_train, y_test = y[:n_train], y[n_train:]\n",
        "\n",
        "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvVtJnu8iELl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9308f822-be00-48de-da72-6860efe0a3f6"
      },
      "source": [
        "from keras.callbacks import History\n",
        "\n",
        "\n",
        "history_Adam = History()\n",
        "model = Sequential()\n",
        "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.8))\n",
        "model.add(Dense(500,activation=\"sigmoid\"))\n",
        "model.add(Dense(200,activation=\"sigmoid\"))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1000)              3000      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 200)               100200    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 603,901\n",
            "Trainable params: 603,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 53 samples, validate on 47 samples\n",
            "Epoch 1/1000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.7750 - accuracy: 0.3962 - val_loss: 0.7674 - val_accuracy: 0.4468\n",
            "Epoch 2/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.6840 - accuracy: 0.5472 - val_loss: 0.6649 - val_accuracy: 0.5532\n",
            "Epoch 3/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.6742 - accuracy: 0.4528 - val_loss: 0.6555 - val_accuracy: 0.5532\n",
            "Epoch 4/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.6696 - accuracy: 0.4717 - val_loss: 0.6391 - val_accuracy: 0.7660\n",
            "Epoch 5/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.6256 - accuracy: 0.7925 - val_loss: 0.6540 - val_accuracy: 0.5319\n",
            "Epoch 6/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.6152 - accuracy: 0.5472 - val_loss: 0.6490 - val_accuracy: 0.5106\n",
            "Epoch 7/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.5926 - accuracy: 0.6226 - val_loss: 0.5929 - val_accuracy: 0.7872\n",
            "Epoch 8/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.5496 - accuracy: 0.8679 - val_loss: 0.5622 - val_accuracy: 0.7660\n",
            "Epoch 9/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.5420 - accuracy: 0.8113 - val_loss: 0.5427 - val_accuracy: 0.7660\n",
            "Epoch 10/1000\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.4941 - accuracy: 0.8491 - val_loss: 0.5162 - val_accuracy: 0.7660\n",
            "Epoch 11/1000\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.4557 - accuracy: 0.8113 - val_loss: 0.5022 - val_accuracy: 0.7872\n",
            "Epoch 12/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.4395 - accuracy: 0.8302 - val_loss: 0.4806 - val_accuracy: 0.7447\n",
            "Epoch 13/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.4015 - accuracy: 0.8302 - val_loss: 0.4705 - val_accuracy: 0.7447\n",
            "Epoch 14/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.3738 - accuracy: 0.8491 - val_loss: 0.4825 - val_accuracy: 0.7447\n",
            "Epoch 15/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.3473 - accuracy: 0.8491 - val_loss: 0.5101 - val_accuracy: 0.7660\n",
            "Epoch 16/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.3443 - accuracy: 0.8491 - val_loss: 0.5141 - val_accuracy: 0.7660\n",
            "Epoch 17/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.3170 - accuracy: 0.8491 - val_loss: 0.5062 - val_accuracy: 0.7660\n",
            "Epoch 18/1000\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.3273 - accuracy: 0.8491 - val_loss: 0.4970 - val_accuracy: 0.7447\n",
            "Epoch 19/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.3108 - accuracy: 0.8491 - val_loss: 0.4976 - val_accuracy: 0.7447\n",
            "Epoch 20/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.3259 - accuracy: 0.8491 - val_loss: 0.5031 - val_accuracy: 0.7660\n",
            "Epoch 21/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.3135 - accuracy: 0.8679 - val_loss: 0.5160 - val_accuracy: 0.7660\n",
            "Epoch 22/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.2819 - accuracy: 0.8679 - val_loss: 0.5319 - val_accuracy: 0.7872\n",
            "Epoch 23/1000\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.2835 - accuracy: 0.8679 - val_loss: 0.5363 - val_accuracy: 0.7872\n",
            "Epoch 24/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.2820 - accuracy: 0.8679 - val_loss: 0.5288 - val_accuracy: 0.7872\n",
            "Epoch 25/1000\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.2719 - accuracy: 0.8679 - val_loss: 0.5168 - val_accuracy: 0.7872\n",
            "Epoch 26/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.2837 - accuracy: 0.8679 - val_loss: 0.5023 - val_accuracy: 0.7872\n",
            "Epoch 27/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.2639 - accuracy: 0.8868 - val_loss: 0.4883 - val_accuracy: 0.8085\n",
            "Epoch 28/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.2627 - accuracy: 0.8868 - val_loss: 0.4826 - val_accuracy: 0.8085\n",
            "Epoch 29/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.2598 - accuracy: 0.9057 - val_loss: 0.4948 - val_accuracy: 0.8085\n",
            "Epoch 30/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.2407 - accuracy: 0.9057 - val_loss: 0.5113 - val_accuracy: 0.7872\n",
            "Epoch 31/1000\n",
            "53/53 [==============================] - 0s 782us/step - loss: 0.2528 - accuracy: 0.8679 - val_loss: 0.5087 - val_accuracy: 0.8085\n",
            "Epoch 32/1000\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.2422 - accuracy: 0.9057 - val_loss: 0.4784 - val_accuracy: 0.8085\n",
            "Epoch 33/1000\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.2591 - accuracy: 0.8868 - val_loss: 0.4463 - val_accuracy: 0.8085\n",
            "Epoch 34/1000\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.2445 - accuracy: 0.9057 - val_loss: 0.4402 - val_accuracy: 0.8085\n",
            "Epoch 35/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.2415 - accuracy: 0.8868 - val_loss: 0.4408 - val_accuracy: 0.8085\n",
            "Epoch 36/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.2498 - accuracy: 0.8868 - val_loss: 0.4590 - val_accuracy: 0.8085\n",
            "Epoch 37/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.2322 - accuracy: 0.9245 - val_loss: 0.4947 - val_accuracy: 0.8298\n",
            "Epoch 38/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.2361 - accuracy: 0.8868 - val_loss: 0.5072 - val_accuracy: 0.8298\n",
            "Epoch 39/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.2429 - accuracy: 0.9245 - val_loss: 0.4996 - val_accuracy: 0.8298\n",
            "Epoch 40/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.2258 - accuracy: 0.9057 - val_loss: 0.4716 - val_accuracy: 0.7872\n",
            "Epoch 41/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.2172 - accuracy: 0.9057 - val_loss: 0.4491 - val_accuracy: 0.8085\n",
            "Epoch 42/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.2197 - accuracy: 0.9057 - val_loss: 0.4481 - val_accuracy: 0.8085\n",
            "Epoch 43/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.2369 - accuracy: 0.9057 - val_loss: 0.4597 - val_accuracy: 0.8085\n",
            "Epoch 44/1000\n",
            "53/53 [==============================] - 0s 863us/step - loss: 0.2300 - accuracy: 0.9057 - val_loss: 0.4845 - val_accuracy: 0.8085\n",
            "Epoch 45/1000\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.2320 - accuracy: 0.8491 - val_loss: 0.4970 - val_accuracy: 0.8085\n",
            "Epoch 46/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.2382 - accuracy: 0.8868 - val_loss: 0.5016 - val_accuracy: 0.8298\n",
            "Epoch 47/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.2120 - accuracy: 0.9057 - val_loss: 0.4971 - val_accuracy: 0.8085\n",
            "Epoch 48/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.2316 - accuracy: 0.8868 - val_loss: 0.4888 - val_accuracy: 0.8085\n",
            "Epoch 49/1000\n",
            "53/53 [==============================] - 0s 608us/step - loss: 0.2199 - accuracy: 0.8868 - val_loss: 0.4804 - val_accuracy: 0.8085\n",
            "Epoch 50/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.2219 - accuracy: 0.8868 - val_loss: 0.4748 - val_accuracy: 0.8298\n",
            "Epoch 51/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.2293 - accuracy: 0.8868 - val_loss: 0.4768 - val_accuracy: 0.8298\n",
            "Epoch 52/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.2188 - accuracy: 0.9057 - val_loss: 0.4808 - val_accuracy: 0.8085\n",
            "Epoch 53/1000\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.2085 - accuracy: 0.9245 - val_loss: 0.4981 - val_accuracy: 0.8085\n",
            "Epoch 54/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.2078 - accuracy: 0.9057 - val_loss: 0.5083 - val_accuracy: 0.8085\n",
            "Epoch 55/1000\n",
            "53/53 [==============================] - 0s 879us/step - loss: 0.2327 - accuracy: 0.9057 - val_loss: 0.5020 - val_accuracy: 0.8085\n",
            "Epoch 56/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.2472 - accuracy: 0.8868 - val_loss: 0.4980 - val_accuracy: 0.8085\n",
            "Epoch 57/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.1893 - accuracy: 0.9245 - val_loss: 0.4810 - val_accuracy: 0.8085\n",
            "Epoch 58/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.2314 - accuracy: 0.8868 - val_loss: 0.4781 - val_accuracy: 0.8085\n",
            "Epoch 59/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.1742 - accuracy: 0.9434 - val_loss: 0.4791 - val_accuracy: 0.8085\n",
            "Epoch 60/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.2165 - accuracy: 0.8868 - val_loss: 0.4690 - val_accuracy: 0.8298\n",
            "Epoch 61/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.2144 - accuracy: 0.8868 - val_loss: 0.4632 - val_accuracy: 0.8298\n",
            "Epoch 62/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.1821 - accuracy: 0.9245 - val_loss: 0.4542 - val_accuracy: 0.8298\n",
            "Epoch 63/1000\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.2499 - accuracy: 0.9057 - val_loss: 0.4635 - val_accuracy: 0.8298\n",
            "Epoch 64/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.2203 - accuracy: 0.8868 - val_loss: 0.4632 - val_accuracy: 0.8298\n",
            "Epoch 65/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.1999 - accuracy: 0.9434 - val_loss: 0.4724 - val_accuracy: 0.8085\n",
            "Epoch 66/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.1943 - accuracy: 0.9057 - val_loss: 0.4801 - val_accuracy: 0.8085\n",
            "Epoch 67/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.2051 - accuracy: 0.9057 - val_loss: 0.4716 - val_accuracy: 0.8298\n",
            "Epoch 68/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.2074 - accuracy: 0.9057 - val_loss: 0.4509 - val_accuracy: 0.8298\n",
            "Epoch 69/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.1872 - accuracy: 0.9245 - val_loss: 0.4360 - val_accuracy: 0.8298\n",
            "Epoch 70/1000\n",
            "53/53 [==============================] - 0s 827us/step - loss: 0.1984 - accuracy: 0.9057 - val_loss: 0.4360 - val_accuracy: 0.8298\n",
            "Epoch 71/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.2110 - accuracy: 0.9057 - val_loss: 0.4482 - val_accuracy: 0.8298\n",
            "Epoch 72/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.2398 - accuracy: 0.8868 - val_loss: 0.4732 - val_accuracy: 0.8085\n",
            "Epoch 73/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.1995 - accuracy: 0.9057 - val_loss: 0.4837 - val_accuracy: 0.8085\n",
            "Epoch 74/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.2128 - accuracy: 0.8868 - val_loss: 0.4837 - val_accuracy: 0.8085\n",
            "Epoch 75/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.1888 - accuracy: 0.9434 - val_loss: 0.4769 - val_accuracy: 0.8085\n",
            "Epoch 76/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.1911 - accuracy: 0.9245 - val_loss: 0.4606 - val_accuracy: 0.8298\n",
            "Epoch 77/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.1903 - accuracy: 0.9245 - val_loss: 0.4454 - val_accuracy: 0.8298\n",
            "Epoch 78/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.1993 - accuracy: 0.9057 - val_loss: 0.4378 - val_accuracy: 0.8298\n",
            "Epoch 79/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.1611 - accuracy: 0.9434 - val_loss: 0.4386 - val_accuracy: 0.8298\n",
            "Epoch 80/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.2101 - accuracy: 0.9057 - val_loss: 0.4527 - val_accuracy: 0.8298\n",
            "Epoch 81/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.1908 - accuracy: 0.9434 - val_loss: 0.4802 - val_accuracy: 0.8085\n",
            "Epoch 82/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.1801 - accuracy: 0.9623 - val_loss: 0.4908 - val_accuracy: 0.8085\n",
            "Epoch 83/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.2087 - accuracy: 0.9245 - val_loss: 0.5023 - val_accuracy: 0.8085\n",
            "Epoch 84/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.2176 - accuracy: 0.9057 - val_loss: 0.4989 - val_accuracy: 0.8085\n",
            "Epoch 85/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.2031 - accuracy: 0.9245 - val_loss: 0.4849 - val_accuracy: 0.8085\n",
            "Epoch 86/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.1821 - accuracy: 0.9245 - val_loss: 0.4697 - val_accuracy: 0.8298\n",
            "Epoch 87/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.2083 - accuracy: 0.9057 - val_loss: 0.4726 - val_accuracy: 0.8298\n",
            "Epoch 88/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.1655 - accuracy: 0.9245 - val_loss: 0.4770 - val_accuracy: 0.8298\n",
            "Epoch 89/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.1978 - accuracy: 0.9245 - val_loss: 0.4688 - val_accuracy: 0.8298\n",
            "Epoch 90/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.1814 - accuracy: 0.9245 - val_loss: 0.4735 - val_accuracy: 0.8298\n",
            "Epoch 91/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.1696 - accuracy: 0.9434 - val_loss: 0.4797 - val_accuracy: 0.8298\n",
            "Epoch 92/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.1898 - accuracy: 0.8868 - val_loss: 0.4709 - val_accuracy: 0.8298\n",
            "Epoch 93/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.2043 - accuracy: 0.9434 - val_loss: 0.4709 - val_accuracy: 0.8298\n",
            "Epoch 94/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.1849 - accuracy: 0.9245 - val_loss: 0.4870 - val_accuracy: 0.8085\n",
            "Epoch 95/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.2120 - accuracy: 0.9057 - val_loss: 0.5004 - val_accuracy: 0.8085\n",
            "Epoch 96/1000\n",
            "53/53 [==============================] - 0s 828us/step - loss: 0.1843 - accuracy: 0.9057 - val_loss: 0.5019 - val_accuracy: 0.8085\n",
            "Epoch 97/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.1760 - accuracy: 0.9434 - val_loss: 0.4889 - val_accuracy: 0.8085\n",
            "Epoch 98/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.1955 - accuracy: 0.9057 - val_loss: 0.4598 - val_accuracy: 0.8298\n",
            "Epoch 99/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.2085 - accuracy: 0.9057 - val_loss: 0.4577 - val_accuracy: 0.8298\n",
            "Epoch 100/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.1686 - accuracy: 0.9434 - val_loss: 0.4572 - val_accuracy: 0.8298\n",
            "Epoch 101/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.1732 - accuracy: 0.9245 - val_loss: 0.4625 - val_accuracy: 0.8298\n",
            "Epoch 102/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.2280 - accuracy: 0.9057 - val_loss: 0.4673 - val_accuracy: 0.8298\n",
            "Epoch 103/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.2038 - accuracy: 0.8868 - val_loss: 0.4812 - val_accuracy: 0.8298\n",
            "Epoch 104/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.1634 - accuracy: 0.9434 - val_loss: 0.4891 - val_accuracy: 0.8085\n",
            "Epoch 105/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.1841 - accuracy: 0.9434 - val_loss: 0.4972 - val_accuracy: 0.8085\n",
            "Epoch 106/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.1727 - accuracy: 0.9434 - val_loss: 0.4747 - val_accuracy: 0.8298\n",
            "Epoch 107/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.2010 - accuracy: 0.9434 - val_loss: 0.4596 - val_accuracy: 0.8298\n",
            "Epoch 108/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.2035 - accuracy: 0.9057 - val_loss: 0.4540 - val_accuracy: 0.8298\n",
            "Epoch 109/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.2276 - accuracy: 0.8868 - val_loss: 0.4503 - val_accuracy: 0.8298\n",
            "Epoch 110/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.2086 - accuracy: 0.9057 - val_loss: 0.4507 - val_accuracy: 0.8298\n",
            "Epoch 111/1000\n",
            "53/53 [==============================] - 0s 799us/step - loss: 0.1924 - accuracy: 0.9434 - val_loss: 0.4598 - val_accuracy: 0.8298\n",
            "Epoch 112/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.1478 - accuracy: 0.9434 - val_loss: 0.4680 - val_accuracy: 0.8298\n",
            "Epoch 113/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.2063 - accuracy: 0.9245 - val_loss: 0.4479 - val_accuracy: 0.8298\n",
            "Epoch 114/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.1634 - accuracy: 0.9623 - val_loss: 0.4298 - val_accuracy: 0.8298\n",
            "Epoch 115/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.1988 - accuracy: 0.9245 - val_loss: 0.4239 - val_accuracy: 0.8298\n",
            "Epoch 116/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.1985 - accuracy: 0.9057 - val_loss: 0.4433 - val_accuracy: 0.8298\n",
            "Epoch 117/1000\n",
            "53/53 [==============================] - 0s 612us/step - loss: 0.2031 - accuracy: 0.9245 - val_loss: 0.4582 - val_accuracy: 0.8298\n",
            "Epoch 118/1000\n",
            "53/53 [==============================] - 0s 633us/step - loss: 0.1710 - accuracy: 0.9434 - val_loss: 0.4551 - val_accuracy: 0.8298\n",
            "Epoch 119/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.2158 - accuracy: 0.9245 - val_loss: 0.4502 - val_accuracy: 0.8298\n",
            "Epoch 120/1000\n",
            "53/53 [==============================] - 0s 598us/step - loss: 0.1904 - accuracy: 0.9245 - val_loss: 0.4328 - val_accuracy: 0.8298\n",
            "Epoch 121/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.1929 - accuracy: 0.9057 - val_loss: 0.4246 - val_accuracy: 0.8298\n",
            "Epoch 122/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.1491 - accuracy: 0.9434 - val_loss: 0.4187 - val_accuracy: 0.8298\n",
            "Epoch 123/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.1995 - accuracy: 0.8868 - val_loss: 0.4225 - val_accuracy: 0.8298\n",
            "Epoch 124/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.1499 - accuracy: 0.9623 - val_loss: 0.4196 - val_accuracy: 0.8298\n",
            "Epoch 125/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.2006 - accuracy: 0.9245 - val_loss: 0.4188 - val_accuracy: 0.8298\n",
            "Epoch 126/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.1783 - accuracy: 0.9434 - val_loss: 0.4169 - val_accuracy: 0.8298\n",
            "Epoch 127/1000\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.2229 - accuracy: 0.9245 - val_loss: 0.4420 - val_accuracy: 0.8298\n",
            "Epoch 128/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.1761 - accuracy: 0.9245 - val_loss: 0.4597 - val_accuracy: 0.8511\n",
            "Epoch 129/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.1809 - accuracy: 0.9245 - val_loss: 0.4730 - val_accuracy: 0.8298\n",
            "Epoch 130/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.1788 - accuracy: 0.9245 - val_loss: 0.4588 - val_accuracy: 0.8511\n",
            "Epoch 131/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.1487 - accuracy: 0.9623 - val_loss: 0.4153 - val_accuracy: 0.8298\n",
            "Epoch 132/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.1628 - accuracy: 0.9434 - val_loss: 0.3973 - val_accuracy: 0.8511\n",
            "Epoch 133/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.1919 - accuracy: 0.9245 - val_loss: 0.4002 - val_accuracy: 0.8511\n",
            "Epoch 134/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.1557 - accuracy: 0.9245 - val_loss: 0.4094 - val_accuracy: 0.8298\n",
            "Epoch 135/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.1508 - accuracy: 0.9434 - val_loss: 0.4194 - val_accuracy: 0.8298\n",
            "Epoch 136/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.1506 - accuracy: 0.9434 - val_loss: 0.4269 - val_accuracy: 0.8298\n",
            "Epoch 137/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.1593 - accuracy: 0.9434 - val_loss: 0.4351 - val_accuracy: 0.8298\n",
            "Epoch 138/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.1585 - accuracy: 0.9434 - val_loss: 0.4374 - val_accuracy: 0.8298\n",
            "Epoch 139/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.1944 - accuracy: 0.9434 - val_loss: 0.4436 - val_accuracy: 0.8298\n",
            "Epoch 140/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.2131 - accuracy: 0.8679 - val_loss: 0.4509 - val_accuracy: 0.8511\n",
            "Epoch 141/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.1386 - accuracy: 0.9434 - val_loss: 0.4273 - val_accuracy: 0.8298\n",
            "Epoch 142/1000\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.1552 - accuracy: 0.9623 - val_loss: 0.4064 - val_accuracy: 0.8511\n",
            "Epoch 143/1000\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.1606 - accuracy: 0.9245 - val_loss: 0.4111 - val_accuracy: 0.8298\n",
            "Epoch 144/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.2051 - accuracy: 0.9057 - val_loss: 0.4264 - val_accuracy: 0.8298\n",
            "Epoch 145/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.1429 - accuracy: 0.9623 - val_loss: 0.4241 - val_accuracy: 0.8298\n",
            "Epoch 146/1000\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.1526 - accuracy: 0.9623 - val_loss: 0.4101 - val_accuracy: 0.8511\n",
            "Epoch 147/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.1371 - accuracy: 0.9811 - val_loss: 0.3961 - val_accuracy: 0.8511\n",
            "Epoch 148/1000\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.1465 - accuracy: 0.9434 - val_loss: 0.4006 - val_accuracy: 0.8511\n",
            "Epoch 149/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.1400 - accuracy: 0.9623 - val_loss: 0.4139 - val_accuracy: 0.8511\n",
            "Epoch 150/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.1656 - accuracy: 0.9057 - val_loss: 0.4215 - val_accuracy: 0.8511\n",
            "Epoch 151/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.2198 - accuracy: 0.9245 - val_loss: 0.4314 - val_accuracy: 0.8511\n",
            "Epoch 152/1000\n",
            "53/53 [==============================] - 0s 601us/step - loss: 0.1671 - accuracy: 0.9057 - val_loss: 0.4323 - val_accuracy: 0.8511\n",
            "Epoch 153/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.2066 - accuracy: 0.9245 - val_loss: 0.4091 - val_accuracy: 0.8511\n",
            "Epoch 154/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.1710 - accuracy: 0.9245 - val_loss: 0.4108 - val_accuracy: 0.8511\n",
            "Epoch 155/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.1695 - accuracy: 0.9623 - val_loss: 0.4072 - val_accuracy: 0.8511\n",
            "Epoch 156/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.1530 - accuracy: 0.9434 - val_loss: 0.4229 - val_accuracy: 0.8511\n",
            "Epoch 157/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.1546 - accuracy: 0.9434 - val_loss: 0.4291 - val_accuracy: 0.8511\n",
            "Epoch 158/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.1455 - accuracy: 0.9623 - val_loss: 0.4174 - val_accuracy: 0.8511\n",
            "Epoch 159/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.1361 - accuracy: 0.9623 - val_loss: 0.3875 - val_accuracy: 0.8723\n",
            "Epoch 160/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.1568 - accuracy: 0.9434 - val_loss: 0.3674 - val_accuracy: 0.8723\n",
            "Epoch 161/1000\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.1406 - accuracy: 0.9434 - val_loss: 0.3455 - val_accuracy: 0.8511\n",
            "Epoch 162/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.1707 - accuracy: 0.9434 - val_loss: 0.3423 - val_accuracy: 0.8511\n",
            "Epoch 163/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.1802 - accuracy: 0.9434 - val_loss: 0.3607 - val_accuracy: 0.8723\n",
            "Epoch 164/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.2149 - accuracy: 0.9245 - val_loss: 0.3825 - val_accuracy: 0.8723\n",
            "Epoch 165/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.1415 - accuracy: 0.9245 - val_loss: 0.3925 - val_accuracy: 0.8511\n",
            "Epoch 166/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.1507 - accuracy: 0.9623 - val_loss: 0.3776 - val_accuracy: 0.8723\n",
            "Epoch 167/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.1401 - accuracy: 0.9623 - val_loss: 0.3679 - val_accuracy: 0.8723\n",
            "Epoch 168/1000\n",
            "53/53 [==============================] - 0s 775us/step - loss: 0.2128 - accuracy: 0.9245 - val_loss: 0.3633 - val_accuracy: 0.8723\n",
            "Epoch 169/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.1469 - accuracy: 0.9623 - val_loss: 0.3612 - val_accuracy: 0.8723\n",
            "Epoch 170/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.1243 - accuracy: 0.9623 - val_loss: 0.3645 - val_accuracy: 0.8723\n",
            "Epoch 171/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.1377 - accuracy: 0.9434 - val_loss: 0.3665 - val_accuracy: 0.8723\n",
            "Epoch 172/1000\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.1034 - accuracy: 0.9811 - val_loss: 0.3690 - val_accuracy: 0.8723\n",
            "Epoch 173/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.1543 - accuracy: 0.9434 - val_loss: 0.3634 - val_accuracy: 0.8723\n",
            "Epoch 174/1000\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.1540 - accuracy: 0.9434 - val_loss: 0.3546 - val_accuracy: 0.8723\n",
            "Epoch 175/1000\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.1667 - accuracy: 0.9434 - val_loss: 0.3474 - val_accuracy: 0.8723\n",
            "Epoch 176/1000\n",
            "53/53 [==============================] - 0s 752us/step - loss: 0.1209 - accuracy: 0.9811 - val_loss: 0.3416 - val_accuracy: 0.8723\n",
            "Epoch 177/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.1293 - accuracy: 0.9811 - val_loss: 0.3511 - val_accuracy: 0.8723\n",
            "Epoch 178/1000\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.1058 - accuracy: 0.9623 - val_loss: 0.3631 - val_accuracy: 0.8723\n",
            "Epoch 179/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.1293 - accuracy: 0.9245 - val_loss: 0.3694 - val_accuracy: 0.8723\n",
            "Epoch 180/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.1022 - accuracy: 0.9811 - val_loss: 0.3581 - val_accuracy: 0.8723\n",
            "Epoch 181/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.1328 - accuracy: 0.9623 - val_loss: 0.3453 - val_accuracy: 0.8723\n",
            "Epoch 182/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.1159 - accuracy: 0.9623 - val_loss: 0.3412 - val_accuracy: 0.8723\n",
            "Epoch 183/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.1074 - accuracy: 0.9623 - val_loss: 0.3404 - val_accuracy: 0.8723\n",
            "Epoch 184/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.1133 - accuracy: 0.9434 - val_loss: 0.3488 - val_accuracy: 0.8723\n",
            "Epoch 185/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.1391 - accuracy: 0.9434 - val_loss: 0.3552 - val_accuracy: 0.8723\n",
            "Epoch 186/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.1221 - accuracy: 0.9434 - val_loss: 0.3501 - val_accuracy: 0.8723\n",
            "Epoch 187/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.1422 - accuracy: 0.9434 - val_loss: 0.3692 - val_accuracy: 0.8936\n",
            "Epoch 188/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.1021 - accuracy: 0.9623 - val_loss: 0.3864 - val_accuracy: 0.8936\n",
            "Epoch 189/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.1577 - accuracy: 0.9245 - val_loss: 0.3919 - val_accuracy: 0.8936\n",
            "Epoch 190/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.1235 - accuracy: 0.9434 - val_loss: 0.3719 - val_accuracy: 0.8723\n",
            "Epoch 191/1000\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.1249 - accuracy: 0.9623 - val_loss: 0.3545 - val_accuracy: 0.8723\n",
            "Epoch 192/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.1030 - accuracy: 0.9623 - val_loss: 0.3442 - val_accuracy: 0.8723\n",
            "Epoch 193/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.1050 - accuracy: 0.9623 - val_loss: 0.3401 - val_accuracy: 0.8723\n",
            "Epoch 194/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.1073 - accuracy: 0.9623 - val_loss: 0.3469 - val_accuracy: 0.8723\n",
            "Epoch 195/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.1451 - accuracy: 0.9057 - val_loss: 0.3665 - val_accuracy: 0.8723\n",
            "Epoch 196/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.1434 - accuracy: 0.9245 - val_loss: 0.3737 - val_accuracy: 0.8936\n",
            "Epoch 197/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.1108 - accuracy: 0.9434 - val_loss: 0.3412 - val_accuracy: 0.8723\n",
            "Epoch 198/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0885 - accuracy: 0.9623 - val_loss: 0.3155 - val_accuracy: 0.8723\n",
            "Epoch 199/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.2034 - accuracy: 0.9245 - val_loss: 0.3178 - val_accuracy: 0.8723\n",
            "Epoch 200/1000\n",
            "53/53 [==============================] - 0s 766us/step - loss: 0.1883 - accuracy: 0.9245 - val_loss: 0.3512 - val_accuracy: 0.8936\n",
            "Epoch 201/1000\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9623 - val_loss: 0.3719 - val_accuracy: 0.8936\n",
            "Epoch 202/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0969 - accuracy: 0.9811 - val_loss: 0.3723 - val_accuracy: 0.8936\n",
            "Epoch 203/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.1136 - accuracy: 0.9623 - val_loss: 0.3422 - val_accuracy: 0.8936\n",
            "Epoch 204/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.1040 - accuracy: 0.9623 - val_loss: 0.3077 - val_accuracy: 0.8723\n",
            "Epoch 205/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0987 - accuracy: 0.9811 - val_loss: 0.2867 - val_accuracy: 0.8723\n",
            "Epoch 206/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.1266 - accuracy: 0.9057 - val_loss: 0.2827 - val_accuracy: 0.8723\n",
            "Epoch 207/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.1163 - accuracy: 0.9811 - val_loss: 0.2817 - val_accuracy: 0.8723\n",
            "Epoch 208/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.1039 - accuracy: 0.9245 - val_loss: 0.3077 - val_accuracy: 0.8723\n",
            "Epoch 209/1000\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0642 - accuracy: 0.9811 - val_loss: 0.3296 - val_accuracy: 0.8723\n",
            "Epoch 210/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0929 - accuracy: 0.9811 - val_loss: 0.3462 - val_accuracy: 0.8936\n",
            "Epoch 211/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.1587 - accuracy: 0.9245 - val_loss: 0.3701 - val_accuracy: 0.8936\n",
            "Epoch 212/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.1190 - accuracy: 0.9623 - val_loss: 0.3724 - val_accuracy: 0.8936\n",
            "Epoch 213/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.1022 - accuracy: 0.9623 - val_loss: 0.3277 - val_accuracy: 0.8723\n",
            "Epoch 214/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.1160 - accuracy: 0.9623 - val_loss: 0.2962 - val_accuracy: 0.8723\n",
            "Epoch 215/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.8723\n",
            "Epoch 216/1000\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.1316 - accuracy: 0.9434 - val_loss: 0.2589 - val_accuracy: 0.8936\n",
            "Epoch 217/1000\n",
            "53/53 [==============================] - 0s 626us/step - loss: 0.1518 - accuracy: 0.9057 - val_loss: 0.2715 - val_accuracy: 0.8723\n",
            "Epoch 218/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0919 - accuracy: 0.9623 - val_loss: 0.3018 - val_accuracy: 0.8723\n",
            "Epoch 219/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.1065 - accuracy: 0.9623 - val_loss: 0.3428 - val_accuracy: 0.8936\n",
            "Epoch 220/1000\n",
            "53/53 [==============================] - 0s 614us/step - loss: 0.0770 - accuracy: 0.9811 - val_loss: 0.3497 - val_accuracy: 0.8936\n",
            "Epoch 221/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.1115 - accuracy: 0.9623 - val_loss: 0.3216 - val_accuracy: 0.8936\n",
            "Epoch 222/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0937 - accuracy: 0.9623 - val_loss: 0.2811 - val_accuracy: 0.8723\n",
            "Epoch 223/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0878 - accuracy: 0.9623 - val_loss: 0.2556 - val_accuracy: 0.8936\n",
            "Epoch 224/1000\n",
            "53/53 [==============================] - 0s 772us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.8936\n",
            "Epoch 225/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.1231 - accuracy: 0.9245 - val_loss: 0.2379 - val_accuracy: 0.8936\n",
            "Epoch 226/1000\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0958 - accuracy: 0.9623 - val_loss: 0.2382 - val_accuracy: 0.8936\n",
            "Epoch 227/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.1096 - accuracy: 0.9623 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
            "Epoch 228/1000\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0915 - accuracy: 0.9623 - val_loss: 0.2789 - val_accuracy: 0.8936\n",
            "Epoch 229/1000\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0800 - accuracy: 0.9811 - val_loss: 0.2851 - val_accuracy: 0.8936\n",
            "Epoch 230/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0837 - accuracy: 0.9623 - val_loss: 0.2893 - val_accuracy: 0.8936\n",
            "Epoch 231/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0694 - accuracy: 0.9811 - val_loss: 0.2724 - val_accuracy: 0.8723\n",
            "Epoch 232/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0841 - accuracy: 0.9434 - val_loss: 0.2720 - val_accuracy: 0.8723\n",
            "Epoch 233/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0754 - accuracy: 0.9623 - val_loss: 0.2758 - val_accuracy: 0.8723\n",
            "Epoch 234/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0782 - accuracy: 0.9811 - val_loss: 0.2913 - val_accuracy: 0.8936\n",
            "Epoch 235/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0711 - accuracy: 0.9623 - val_loss: 0.2897 - val_accuracy: 0.8936\n",
            "Epoch 236/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0962 - accuracy: 0.9434 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
            "Epoch 237/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.8936\n",
            "Epoch 238/1000\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0930 - accuracy: 0.9434 - val_loss: 0.2664 - val_accuracy: 0.8936\n",
            "Epoch 239/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 0.2466 - val_accuracy: 0.8936\n",
            "Epoch 240/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.8936\n",
            "Epoch 241/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.1187 - accuracy: 0.9434 - val_loss: 0.2444 - val_accuracy: 0.8936\n",
            "Epoch 242/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0707 - accuracy: 0.9811 - val_loss: 0.2771 - val_accuracy: 0.8936\n",
            "Epoch 243/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0610 - accuracy: 0.9811 - val_loss: 0.2933 - val_accuracy: 0.8936\n",
            "Epoch 244/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0864 - accuracy: 0.9811 - val_loss: 0.2966 - val_accuracy: 0.8936\n",
            "Epoch 245/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.2764 - val_accuracy: 0.9149\n",
            "Epoch 246/1000\n",
            "53/53 [==============================] - 0s 736us/step - loss: 0.1101 - accuracy: 0.9623 - val_loss: 0.2576 - val_accuracy: 0.9149\n",
            "Epoch 247/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
            "Epoch 248/1000\n",
            "53/53 [==============================] - 0s 640us/step - loss: 0.0864 - accuracy: 0.9623 - val_loss: 0.2344 - val_accuracy: 0.9149\n",
            "Epoch 249/1000\n",
            "53/53 [==============================] - 0s 662us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9149\n",
            "Epoch 250/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0688 - accuracy: 0.9623 - val_loss: 0.2388 - val_accuracy: 0.9149\n",
            "Epoch 251/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0500 - accuracy: 0.9811 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
            "Epoch 252/1000\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0714 - accuracy: 0.9623 - val_loss: 0.2471 - val_accuracy: 0.9149\n",
            "Epoch 253/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0669 - accuracy: 0.9623 - val_loss: 0.2574 - val_accuracy: 0.9149\n",
            "Epoch 254/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9149\n",
            "Epoch 255/1000\n",
            "53/53 [==============================] - 0s 662us/step - loss: 0.1046 - accuracy: 0.9434 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
            "Epoch 256/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.1021 - accuracy: 0.9434 - val_loss: 0.2725 - val_accuracy: 0.9149\n",
            "Epoch 257/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.8936\n",
            "Epoch 258/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.8936\n",
            "Epoch 259/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
            "Epoch 260/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0768 - accuracy: 0.9623 - val_loss: 0.3005 - val_accuracy: 0.9149\n",
            "Epoch 261/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.1397 - accuracy: 0.9434 - val_loss: 0.3298 - val_accuracy: 0.8936\n",
            "Epoch 262/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0810 - accuracy: 0.9623 - val_loss: 0.3324 - val_accuracy: 0.8936\n",
            "Epoch 263/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0713 - accuracy: 0.9623 - val_loss: 0.3034 - val_accuracy: 0.9149\n",
            "Epoch 264/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0807 - accuracy: 0.9623 - val_loss: 0.2575 - val_accuracy: 0.8723\n",
            "Epoch 265/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0950 - accuracy: 0.9434 - val_loss: 0.2497 - val_accuracy: 0.8723\n",
            "Epoch 266/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0851 - accuracy: 0.9623 - val_loss: 0.2544 - val_accuracy: 0.8723\n",
            "Epoch 267/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.8723\n",
            "Epoch 268/1000\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
            "Epoch 269/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0598 - accuracy: 0.9623 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
            "Epoch 270/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0514 - accuracy: 0.9623 - val_loss: 0.3068 - val_accuracy: 0.9149\n",
            "Epoch 271/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 0.2885 - val_accuracy: 0.9149\n",
            "Epoch 272/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.1328 - accuracy: 0.9245 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
            "Epoch 273/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0701 - accuracy: 0.9434 - val_loss: 0.2173 - val_accuracy: 0.8936\n",
            "Epoch 274/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0624 - accuracy: 0.9623 - val_loss: 0.1978 - val_accuracy: 0.9149\n",
            "Epoch 275/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0390 - accuracy: 0.9811 - val_loss: 0.1919 - val_accuracy: 0.9149\n",
            "Epoch 276/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0977 - accuracy: 0.9623 - val_loss: 0.2065 - val_accuracy: 0.8936\n",
            "Epoch 277/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0825 - accuracy: 0.9811 - val_loss: 0.2096 - val_accuracy: 0.8936\n",
            "Epoch 278/1000\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
            "Epoch 279/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9149\n",
            "Epoch 280/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.1097 - accuracy: 0.9434 - val_loss: 0.2579 - val_accuracy: 0.9149\n",
            "Epoch 281/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9149\n",
            "Epoch 282/1000\n",
            "53/53 [==============================] - 0s 804us/step - loss: 0.0820 - accuracy: 0.9623 - val_loss: 0.2217 - val_accuracy: 0.8936\n",
            "Epoch 283/1000\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0662 - accuracy: 0.9623 - val_loss: 0.2103 - val_accuracy: 0.9149\n",
            "Epoch 284/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0714 - accuracy: 0.9434 - val_loss: 0.2144 - val_accuracy: 0.8936\n",
            "Epoch 285/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0482 - accuracy: 0.9811 - val_loss: 0.2212 - val_accuracy: 0.8936\n",
            "Epoch 286/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9149\n",
            "Epoch 287/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
            "Epoch 288/1000\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
            "Epoch 289/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.1211 - accuracy: 0.9434 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
            "Epoch 290/1000\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0638 - accuracy: 0.9434 - val_loss: 0.2148 - val_accuracy: 0.8936\n",
            "Epoch 291/1000\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0346 - accuracy: 0.9811 - val_loss: 0.1973 - val_accuracy: 0.9149\n",
            "Epoch 292/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0715 - accuracy: 0.9434 - val_loss: 0.2004 - val_accuracy: 0.9149\n",
            "Epoch 293/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0630 - accuracy: 0.9811 - val_loss: 0.2012 - val_accuracy: 0.9149\n",
            "Epoch 294/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.2014 - val_accuracy: 0.9149\n",
            "Epoch 295/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
            "Epoch 296/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0892 - accuracy: 0.9434 - val_loss: 0.2211 - val_accuracy: 0.8936\n",
            "Epoch 297/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0412 - accuracy: 0.9811 - val_loss: 0.2071 - val_accuracy: 0.9149\n",
            "Epoch 298/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9149\n",
            "Epoch 299/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0580 - accuracy: 0.9623 - val_loss: 0.1816 - val_accuracy: 0.9149\n",
            "Epoch 300/1000\n",
            "53/53 [==============================] - 0s 762us/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.1833 - val_accuracy: 0.8936\n",
            "Epoch 301/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.1882 - val_accuracy: 0.9149\n",
            "Epoch 302/1000\n",
            "53/53 [==============================] - 0s 662us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9149\n",
            "Epoch 303/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0351 - accuracy: 0.9811 - val_loss: 0.1988 - val_accuracy: 0.9149\n",
            "Epoch 304/1000\n",
            "53/53 [==============================] - 0s 814us/step - loss: 0.0670 - accuracy: 0.9623 - val_loss: 0.2142 - val_accuracy: 0.9149\n",
            "Epoch 305/1000\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.8936\n",
            "Epoch 306/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 0.2511 - val_accuracy: 0.8936\n",
            "Epoch 307/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 0.2659 - val_accuracy: 0.8936\n",
            "Epoch 308/1000\n",
            "53/53 [==============================] - 0s 735us/step - loss: 0.0712 - accuracy: 0.9623 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
            "Epoch 309/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0381 - accuracy: 0.9811 - val_loss: 0.2897 - val_accuracy: 0.9149\n",
            "Epoch 310/1000\n",
            "53/53 [==============================] - 0s 625us/step - loss: 0.0490 - accuracy: 0.9811 - val_loss: 0.3176 - val_accuracy: 0.9149\n",
            "Epoch 311/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0573 - accuracy: 0.9623 - val_loss: 0.3406 - val_accuracy: 0.9149\n",
            "Epoch 312/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0434 - accuracy: 0.9811 - val_loss: 0.3143 - val_accuracy: 0.9149\n",
            "Epoch 313/1000\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0340 - accuracy: 0.9811 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
            "Epoch 314/1000\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.2408 - val_accuracy: 0.8936\n",
            "Epoch 315/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0707 - accuracy: 0.9434 - val_loss: 0.2300 - val_accuracy: 0.8936\n",
            "Epoch 316/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
            "Epoch 317/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.2177 - val_accuracy: 0.8936\n",
            "Epoch 318/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
            "Epoch 319/1000\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9149\n",
            "Epoch 320/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0625 - accuracy: 0.9623 - val_loss: 0.2422 - val_accuracy: 0.8936\n",
            "Epoch 321/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.8936\n",
            "Epoch 322/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.2564 - val_accuracy: 0.8936\n",
            "Epoch 323/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0583 - accuracy: 0.9623 - val_loss: 0.2503 - val_accuracy: 0.8936\n",
            "Epoch 324/1000\n",
            "53/53 [==============================] - 0s 896us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.8936\n",
            "Epoch 325/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0468 - accuracy: 0.9811 - val_loss: 0.2683 - val_accuracy: 0.8936\n",
            "Epoch 326/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 0.2770 - val_accuracy: 0.8936\n",
            "Epoch 327/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.8936\n",
            "Epoch 328/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.8936\n",
            "Epoch 329/1000\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
            "Epoch 330/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0479 - accuracy: 0.9623 - val_loss: 0.2375 - val_accuracy: 0.9149\n",
            "Epoch 331/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.8936\n",
            "Epoch 332/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0445 - accuracy: 0.9811 - val_loss: 0.2239 - val_accuracy: 0.8936\n",
            "Epoch 333/1000\n",
            "53/53 [==============================] - 0s 854us/step - loss: 0.0925 - accuracy: 0.9434 - val_loss: 0.2396 - val_accuracy: 0.8936\n",
            "Epoch 334/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.8936\n",
            "Epoch 335/1000\n",
            "53/53 [==============================] - 0s 621us/step - loss: 0.0407 - accuracy: 0.9811 - val_loss: 0.2581 - val_accuracy: 0.8723\n",
            "Epoch 336/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.8936\n",
            "Epoch 337/1000\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.8936\n",
            "Epoch 338/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0385 - accuracy: 0.9811 - val_loss: 0.2596 - val_accuracy: 0.8936\n",
            "Epoch 339/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.0594 - accuracy: 0.9623 - val_loss: 0.2676 - val_accuracy: 0.8723\n",
            "Epoch 340/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0694 - accuracy: 0.9623 - val_loss: 0.2841 - val_accuracy: 0.8723\n",
            "Epoch 341/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.8723\n",
            "Epoch 342/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0454 - accuracy: 0.9811 - val_loss: 0.2946 - val_accuracy: 0.8723\n",
            "Epoch 343/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0375 - accuracy: 0.9811 - val_loss: 0.3101 - val_accuracy: 0.9149\n",
            "Epoch 344/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9149\n",
            "Epoch 345/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0623 - accuracy: 0.9811 - val_loss: 0.3069 - val_accuracy: 0.9149\n",
            "Epoch 346/1000\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.0809 - accuracy: 0.9811 - val_loss: 0.3013 - val_accuracy: 0.9149\n",
            "Epoch 347/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0616 - accuracy: 0.9434 - val_loss: 0.3004 - val_accuracy: 0.8723\n",
            "Epoch 348/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0345 - accuracy: 0.9811 - val_loss: 0.2890 - val_accuracy: 0.8723\n",
            "Epoch 349/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0557 - accuracy: 0.9623 - val_loss: 0.2755 - val_accuracy: 0.8723\n",
            "Epoch 350/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0433 - accuracy: 0.9811 - val_loss: 0.2677 - val_accuracy: 0.8936\n",
            "Epoch 351/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.1197 - accuracy: 0.9623 - val_loss: 0.2751 - val_accuracy: 0.8723\n",
            "Epoch 352/1000\n",
            "53/53 [==============================] - 0s 849us/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 0.2936 - val_accuracy: 0.8936\n",
            "Epoch 353/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3148 - val_accuracy: 0.9149\n",
            "Epoch 354/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0277 - accuracy: 0.9811 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
            "Epoch 355/1000\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0411 - accuracy: 0.9811 - val_loss: 0.3019 - val_accuracy: 0.8936\n",
            "Epoch 356/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.8936\n",
            "Epoch 357/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0307 - accuracy: 0.9811 - val_loss: 0.2585 - val_accuracy: 0.9149\n",
            "Epoch 358/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.8936\n",
            "Epoch 359/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.8936\n",
            "Epoch 360/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.2280 - val_accuracy: 0.9149\n",
            "Epoch 361/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
            "Epoch 362/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9149\n",
            "Epoch 363/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9149\n",
            "Epoch 364/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0758 - accuracy: 0.9623 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
            "Epoch 365/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0437 - accuracy: 0.9623 - val_loss: 0.2433 - val_accuracy: 0.9149\n",
            "Epoch 366/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9149\n",
            "Epoch 367/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0513 - accuracy: 0.9811 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
            "Epoch 368/1000\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0338 - accuracy: 0.9811 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
            "Epoch 369/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0507 - accuracy: 0.9623 - val_loss: 0.2910 - val_accuracy: 0.8936\n",
            "Epoch 370/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9149\n",
            "Epoch 371/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0950 - accuracy: 0.9811 - val_loss: 0.2918 - val_accuracy: 0.8936\n",
            "Epoch 372/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0459 - accuracy: 0.9811 - val_loss: 0.2798 - val_accuracy: 0.8936\n",
            "Epoch 373/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.1065 - accuracy: 0.9623 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
            "Epoch 374/1000\n",
            "53/53 [==============================] - 0s 762us/step - loss: 0.0531 - accuracy: 0.9434 - val_loss: 0.2906 - val_accuracy: 0.8723\n",
            "Epoch 375/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0391 - accuracy: 0.9811 - val_loss: 0.3087 - val_accuracy: 0.8723\n",
            "Epoch 376/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.0317 - accuracy: 0.9811 - val_loss: 0.3629 - val_accuracy: 0.8936\n",
            "Epoch 377/1000\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.0663 - accuracy: 0.9623 - val_loss: 0.3900 - val_accuracy: 0.8936\n",
            "Epoch 378/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0272 - accuracy: 0.9811 - val_loss: 0.4143 - val_accuracy: 0.8936\n",
            "Epoch 379/1000\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0403 - accuracy: 0.9811 - val_loss: 0.4383 - val_accuracy: 0.9149\n",
            "Epoch 380/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0277 - accuracy: 0.9811 - val_loss: 0.4321 - val_accuracy: 0.8936\n",
            "Epoch 381/1000\n",
            "53/53 [==============================] - 0s 826us/step - loss: 0.0466 - accuracy: 0.9811 - val_loss: 0.4047 - val_accuracy: 0.8723\n",
            "Epoch 382/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.3977 - val_accuracy: 0.8723\n",
            "Epoch 383/1000\n",
            "53/53 [==============================] - 0s 855us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.8723\n",
            "Epoch 384/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0487 - accuracy: 0.9811 - val_loss: 0.3599 - val_accuracy: 0.8723\n",
            "Epoch 385/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0397 - accuracy: 0.9811 - val_loss: 0.3449 - val_accuracy: 0.8723\n",
            "Epoch 386/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.0485 - accuracy: 0.9623 - val_loss: 0.3298 - val_accuracy: 0.8723\n",
            "Epoch 387/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.8723\n",
            "Epoch 388/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0835 - accuracy: 0.9811 - val_loss: 0.3074 - val_accuracy: 0.8723\n",
            "Epoch 389/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.8936\n",
            "Epoch 390/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 0.2873 - val_accuracy: 0.8936\n",
            "Epoch 391/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0520 - accuracy: 0.9623 - val_loss: 0.2613 - val_accuracy: 0.8936\n",
            "Epoch 392/1000\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.1157 - accuracy: 0.9623 - val_loss: 0.2513 - val_accuracy: 0.8936\n",
            "Epoch 393/1000\n",
            "53/53 [==============================] - 0s 590us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9149\n",
            "Epoch 394/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9149\n",
            "Epoch 395/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0495 - accuracy: 0.9811 - val_loss: 0.2720 - val_accuracy: 0.9149\n",
            "Epoch 396/1000\n",
            "53/53 [==============================] - 0s 635us/step - loss: 0.0262 - accuracy: 0.9811 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
            "Epoch 397/1000\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9149\n",
            "Epoch 398/1000\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0729 - accuracy: 0.9623 - val_loss: 0.2267 - val_accuracy: 0.8936\n",
            "Epoch 399/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0323 - accuracy: 0.9811 - val_loss: 0.2120 - val_accuracy: 0.9149\n",
            "Epoch 400/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0345 - accuracy: 0.9811 - val_loss: 0.2080 - val_accuracy: 0.9149\n",
            "Epoch 401/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0575 - accuracy: 0.9434 - val_loss: 0.2143 - val_accuracy: 0.9149\n",
            "Epoch 402/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0606 - accuracy: 0.9623 - val_loss: 0.2352 - val_accuracy: 0.9149\n",
            "Epoch 403/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9149\n",
            "Epoch 404/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0913 - accuracy: 0.9623 - val_loss: 0.3044 - val_accuracy: 0.9149\n",
            "Epoch 405/1000\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.0381 - accuracy: 0.9811 - val_loss: 0.2892 - val_accuracy: 0.9149\n",
            "Epoch 406/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0380 - accuracy: 0.9623 - val_loss: 0.2505 - val_accuracy: 0.9362\n",
            "Epoch 407/1000\n",
            "53/53 [==============================] - 0s 803us/step - loss: 0.0483 - accuracy: 0.9811 - val_loss: 0.2023 - val_accuracy: 0.9362\n",
            "Epoch 408/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9149\n",
            "Epoch 409/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0379 - accuracy: 0.9811 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
            "Epoch 410/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0342 - accuracy: 0.9811 - val_loss: 0.1788 - val_accuracy: 0.9149\n",
            "Epoch 411/1000\n",
            "53/53 [==============================] - 0s 631us/step - loss: 0.0389 - accuracy: 0.9811 - val_loss: 0.1820 - val_accuracy: 0.9362\n",
            "Epoch 412/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0917 - accuracy: 0.9434 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
            "Epoch 413/1000\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0971 - accuracy: 0.9623 - val_loss: 0.3665 - val_accuracy: 0.9149\n",
            "Epoch 414/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0433 - accuracy: 0.9811 - val_loss: 0.4624 - val_accuracy: 0.9149\n",
            "Epoch 415/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0783 - accuracy: 0.9434 - val_loss: 0.4656 - val_accuracy: 0.9149\n",
            "Epoch 416/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0715 - accuracy: 0.9623 - val_loss: 0.3758 - val_accuracy: 0.9149\n",
            "Epoch 417/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8936\n",
            "Epoch 418/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.8936\n",
            "Epoch 419/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0654 - accuracy: 0.9623 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
            "Epoch 420/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0548 - accuracy: 0.9623 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
            "Epoch 421/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0269 - accuracy: 0.9811 - val_loss: 0.3281 - val_accuracy: 0.8723\n",
            "Epoch 422/1000\n",
            "53/53 [==============================] - 0s 815us/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.3734 - val_accuracy: 0.9149\n",
            "Epoch 423/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0410 - accuracy: 0.9811 - val_loss: 0.4227 - val_accuracy: 0.9149\n",
            "Epoch 424/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0698 - accuracy: 0.9811 - val_loss: 0.4296 - val_accuracy: 0.9149\n",
            "Epoch 425/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0608 - accuracy: 0.9811 - val_loss: 0.4047 - val_accuracy: 0.9149\n",
            "Epoch 426/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0262 - accuracy: 0.9811 - val_loss: 0.3404 - val_accuracy: 0.8936\n",
            "Epoch 427/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0566 - accuracy: 0.9623 - val_loss: 0.2967 - val_accuracy: 0.8936\n",
            "Epoch 428/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.8936\n",
            "Epoch 429/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0420 - accuracy: 0.9811 - val_loss: 0.2884 - val_accuracy: 0.8936\n",
            "Epoch 430/1000\n",
            "53/53 [==============================] - 0s 840us/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.8936\n",
            "Epoch 431/1000\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0595 - accuracy: 0.9811 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
            "Epoch 432/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0485 - accuracy: 0.9811 - val_loss: 0.3156 - val_accuracy: 0.8936\n",
            "Epoch 433/1000\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.8936\n",
            "Epoch 434/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.8936\n",
            "Epoch 435/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.8936\n",
            "Epoch 436/1000\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.0992 - accuracy: 0.9623 - val_loss: 0.3205 - val_accuracy: 0.8936\n",
            "Epoch 437/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0784 - accuracy: 0.9434 - val_loss: 0.2986 - val_accuracy: 0.9149\n",
            "Epoch 438/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0511 - accuracy: 0.9811 - val_loss: 0.2723 - val_accuracy: 0.8936\n",
            "Epoch 439/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0261 - accuracy: 0.9811 - val_loss: 0.2639 - val_accuracy: 0.8936\n",
            "Epoch 440/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0438 - accuracy: 0.9811 - val_loss: 0.2642 - val_accuracy: 0.8936\n",
            "Epoch 441/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 0.2706 - val_accuracy: 0.8936\n",
            "Epoch 442/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9149\n",
            "Epoch 443/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0749 - accuracy: 0.9434 - val_loss: 0.2945 - val_accuracy: 0.9149\n",
            "Epoch 444/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
            "Epoch 445/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
            "Epoch 446/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0262 - accuracy: 0.9811 - val_loss: 0.2741 - val_accuracy: 0.9149\n",
            "Epoch 447/1000\n",
            "53/53 [==============================] - 0s 641us/step - loss: 0.0798 - accuracy: 0.9434 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
            "Epoch 448/1000\n",
            "53/53 [==============================] - 0s 761us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9149\n",
            "Epoch 449/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0300 - accuracy: 0.9811 - val_loss: 0.2673 - val_accuracy: 0.8936\n",
            "Epoch 450/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0570 - accuracy: 0.9623 - val_loss: 0.2771 - val_accuracy: 0.8936\n",
            "Epoch 451/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0218 - accuracy: 0.9811 - val_loss: 0.2936 - val_accuracy: 0.9149\n",
            "Epoch 452/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9149\n",
            "Epoch 453/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9149\n",
            "Epoch 454/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.8936\n",
            "Epoch 455/1000\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.8936\n",
            "Epoch 456/1000\n",
            "53/53 [==============================] - 0s 780us/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
            "Epoch 457/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0559 - accuracy: 0.9623 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
            "Epoch 458/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9149\n",
            "Epoch 459/1000\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.8936\n",
            "Epoch 460/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0578 - accuracy: 0.9623 - val_loss: 0.2591 - val_accuracy: 0.8936\n",
            "Epoch 461/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.8936\n",
            "Epoch 462/1000\n",
            "53/53 [==============================] - 0s 844us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.8936\n",
            "Epoch 463/1000\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.8936\n",
            "Epoch 464/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0701 - accuracy: 0.9434 - val_loss: 0.2810 - val_accuracy: 0.9149\n",
            "Epoch 465/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 0.3093 - val_accuracy: 0.9362\n",
            "Epoch 466/1000\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.0342 - accuracy: 0.9811 - val_loss: 0.3485 - val_accuracy: 0.9149\n",
            "Epoch 467/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9149\n",
            "Epoch 468/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.3516 - val_accuracy: 0.9149\n",
            "Epoch 469/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.0275 - accuracy: 0.9811 - val_loss: 0.3186 - val_accuracy: 0.9149\n",
            "Epoch 470/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0298 - accuracy: 0.9811 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
            "Epoch 471/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
            "Epoch 472/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
            "Epoch 473/1000\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
            "Epoch 474/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
            "Epoch 475/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0314 - accuracy: 0.9811 - val_loss: 0.2289 - val_accuracy: 0.9149\n",
            "Epoch 476/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
            "Epoch 477/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
            "Epoch 478/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9149\n",
            "Epoch 479/1000\n",
            "53/53 [==============================] - 0s 744us/step - loss: 0.0361 - accuracy: 0.9623 - val_loss: 0.2818 - val_accuracy: 0.9149\n",
            "Epoch 480/1000\n",
            "53/53 [==============================] - 0s 858us/step - loss: 0.0420 - accuracy: 0.9623 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
            "Epoch 481/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9362\n",
            "Epoch 482/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0370 - accuracy: 0.9811 - val_loss: 0.2411 - val_accuracy: 0.9362\n",
            "Epoch 483/1000\n",
            "53/53 [==============================] - 0s 606us/step - loss: 0.0455 - accuracy: 0.9811 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
            "Epoch 484/1000\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
            "Epoch 485/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0236 - accuracy: 0.9811 - val_loss: 0.2373 - val_accuracy: 0.9362\n",
            "Epoch 486/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9149\n",
            "Epoch 487/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9149\n",
            "Epoch 488/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0805 - accuracy: 0.9811 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
            "Epoch 489/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0501 - accuracy: 0.9623 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
            "Epoch 490/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9149\n",
            "Epoch 491/1000\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9149\n",
            "Epoch 492/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0239 - accuracy: 0.9811 - val_loss: 0.2909 - val_accuracy: 0.8936\n",
            "Epoch 493/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.8936\n",
            "Epoch 494/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0419 - accuracy: 0.9811 - val_loss: 0.2850 - val_accuracy: 0.8936\n",
            "Epoch 495/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
            "Epoch 496/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0223 - accuracy: 0.9811 - val_loss: 0.3085 - val_accuracy: 0.9149\n",
            "Epoch 497/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9149\n",
            "Epoch 498/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0317 - accuracy: 0.9811 - val_loss: 0.3289 - val_accuracy: 0.9149\n",
            "Epoch 499/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0239 - accuracy: 0.9811 - val_loss: 0.3143 - val_accuracy: 0.9149\n",
            "Epoch 500/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0346 - accuracy: 0.9811 - val_loss: 0.3035 - val_accuracy: 0.9149\n",
            "Epoch 501/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.8936\n",
            "Epoch 502/1000\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9149\n",
            "Epoch 503/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9149\n",
            "Epoch 504/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9149\n",
            "Epoch 505/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0628 - accuracy: 0.9623 - val_loss: 0.3120 - val_accuracy: 0.9149\n",
            "Epoch 506/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
            "Epoch 507/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9149\n",
            "Epoch 508/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0223 - accuracy: 0.9811 - val_loss: 0.3052 - val_accuracy: 0.9149\n",
            "Epoch 509/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0560 - accuracy: 0.9623 - val_loss: 0.3146 - val_accuracy: 0.8936\n",
            "Epoch 510/1000\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.1165 - accuracy: 0.9623 - val_loss: 0.3404 - val_accuracy: 0.8936\n",
            "Epoch 511/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.8723\n",
            "Epoch 512/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0326 - accuracy: 0.9811 - val_loss: 0.3863 - val_accuracy: 0.8723\n",
            "Epoch 513/1000\n",
            "53/53 [==============================] - 0s 612us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.8723\n",
            "Epoch 514/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.8723\n",
            "Epoch 515/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.8723\n",
            "Epoch 516/1000\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0247 - accuracy: 0.9811 - val_loss: 0.3934 - val_accuracy: 0.8723\n",
            "Epoch 517/1000\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0541 - accuracy: 0.9811 - val_loss: 0.3707 - val_accuracy: 0.8936\n",
            "Epoch 518/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0190 - accuracy: 0.9811 - val_loss: 0.3557 - val_accuracy: 0.8936\n",
            "Epoch 519/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.8936\n",
            "Epoch 520/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.8936\n",
            "Epoch 521/1000\n",
            "53/53 [==============================] - 0s 611us/step - loss: 0.0440 - accuracy: 0.9811 - val_loss: 0.3362 - val_accuracy: 0.8936\n",
            "Epoch 522/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0296 - accuracy: 0.9811 - val_loss: 0.3345 - val_accuracy: 0.8936\n",
            "Epoch 523/1000\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0340 - accuracy: 0.9811 - val_loss: 0.3352 - val_accuracy: 0.8936\n",
            "Epoch 524/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.8936\n",
            "Epoch 525/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0517 - accuracy: 0.9623 - val_loss: 0.3382 - val_accuracy: 0.8936\n",
            "Epoch 526/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.8936\n",
            "Epoch 527/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.8936\n",
            "Epoch 528/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0331 - accuracy: 0.9811 - val_loss: 0.3309 - val_accuracy: 0.8936\n",
            "Epoch 529/1000\n",
            "53/53 [==============================] - 0s 626us/step - loss: 0.0253 - accuracy: 0.9811 - val_loss: 0.3304 - val_accuracy: 0.8936\n",
            "Epoch 530/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0212 - accuracy: 0.9811 - val_loss: 0.3351 - val_accuracy: 0.8936\n",
            "Epoch 531/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.8936\n",
            "Epoch 532/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0424 - accuracy: 0.9811 - val_loss: 0.3338 - val_accuracy: 0.8936\n",
            "Epoch 533/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0451 - accuracy: 0.9811 - val_loss: 0.3196 - val_accuracy: 0.8936\n",
            "Epoch 534/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.3173 - val_accuracy: 0.8936\n",
            "Epoch 535/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.8936\n",
            "Epoch 536/1000\n",
            "53/53 [==============================] - 0s 776us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.8936\n",
            "Epoch 537/1000\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0442 - accuracy: 0.9811 - val_loss: 0.3276 - val_accuracy: 0.8936\n",
            "Epoch 538/1000\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.8936\n",
            "Epoch 539/1000\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.1004 - accuracy: 0.9811 - val_loss: 0.3572 - val_accuracy: 0.8936\n",
            "Epoch 540/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8936\n",
            "Epoch 541/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.8936\n",
            "Epoch 542/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0413 - accuracy: 0.9811 - val_loss: 0.5240 - val_accuracy: 0.8936\n",
            "Epoch 543/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0362 - accuracy: 0.9811 - val_loss: 0.5241 - val_accuracy: 0.8936\n",
            "Epoch 544/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0423 - accuracy: 0.9811 - val_loss: 0.5004 - val_accuracy: 0.8936\n",
            "Epoch 545/1000\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0547 - accuracy: 0.9623 - val_loss: 0.4627 - val_accuracy: 0.8723\n",
            "Epoch 546/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0593 - accuracy: 0.9811 - val_loss: 0.4489 - val_accuracy: 0.8723\n",
            "Epoch 547/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.8723\n",
            "Epoch 548/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0778 - accuracy: 0.9623 - val_loss: 0.4678 - val_accuracy: 0.9149\n",
            "Epoch 549/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0327 - accuracy: 0.9811 - val_loss: 0.4878 - val_accuracy: 0.9149\n",
            "Epoch 550/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0541 - accuracy: 0.9623 - val_loss: 0.4771 - val_accuracy: 0.9149\n",
            "Epoch 551/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0444 - accuracy: 0.9811 - val_loss: 0.4149 - val_accuracy: 0.9149\n",
            "Epoch 552/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.8936\n",
            "Epoch 553/1000\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.8936\n",
            "Epoch 554/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.8936\n",
            "Epoch 555/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
            "Epoch 556/1000\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0532 - accuracy: 0.9623 - val_loss: 0.3010 - val_accuracy: 0.9149\n",
            "Epoch 557/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0217 - accuracy: 0.9811 - val_loss: 0.3053 - val_accuracy: 0.9149\n",
            "Epoch 558/1000\n",
            "53/53 [==============================] - 0s 902us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9149\n",
            "Epoch 559/1000\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9149\n",
            "Epoch 560/1000\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.9149\n",
            "Epoch 561/1000\n",
            "53/53 [==============================] - 0s 932us/step - loss: 0.0239 - accuracy: 0.9811 - val_loss: 0.3114 - val_accuracy: 0.9149\n",
            "Epoch 562/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9149\n",
            "Epoch 563/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0320 - accuracy: 0.9811 - val_loss: 0.3338 - val_accuracy: 0.9149\n",
            "Epoch 564/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.8936\n",
            "Epoch 565/1000\n",
            "53/53 [==============================] - 0s 575us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.8936\n",
            "Epoch 566/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.8936\n",
            "Epoch 567/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0477 - accuracy: 0.9811 - val_loss: 0.3698 - val_accuracy: 0.8936\n",
            "Epoch 568/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.8936\n",
            "Epoch 569/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0327 - accuracy: 0.9811 - val_loss: 0.3510 - val_accuracy: 0.9149\n",
            "Epoch 570/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.8936\n",
            "Epoch 571/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.0365 - accuracy: 0.9811 - val_loss: 0.3476 - val_accuracy: 0.8936\n",
            "Epoch 572/1000\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8936\n",
            "Epoch 573/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.8936\n",
            "Epoch 574/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0289 - accuracy: 0.9811 - val_loss: 0.3878 - val_accuracy: 0.8936\n",
            "Epoch 575/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0321 - accuracy: 0.9811 - val_loss: 0.3616 - val_accuracy: 0.9149\n",
            "Epoch 576/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.8936\n",
            "Epoch 577/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0364 - accuracy: 0.9623 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
            "Epoch 578/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0263 - accuracy: 0.9811 - val_loss: 0.3359 - val_accuracy: 0.8936\n",
            "Epoch 579/1000\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.8936\n",
            "Epoch 580/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0368 - accuracy: 0.9623 - val_loss: 0.3319 - val_accuracy: 0.8936\n",
            "Epoch 581/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9149\n",
            "Epoch 582/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9149\n",
            "Epoch 583/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9149\n",
            "Epoch 584/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0511 - accuracy: 0.9811 - val_loss: 0.3661 - val_accuracy: 0.9149\n",
            "Epoch 585/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9149\n",
            "Epoch 586/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0628 - accuracy: 0.9623 - val_loss: 0.3222 - val_accuracy: 0.8936\n",
            "Epoch 587/1000\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0411 - accuracy: 0.9811 - val_loss: 0.3082 - val_accuracy: 0.9149\n",
            "Epoch 588/1000\n",
            "53/53 [==============================] - 0s 565us/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.3219 - val_accuracy: 0.8936\n",
            "Epoch 589/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0363 - accuracy: 0.9811 - val_loss: 0.3731 - val_accuracy: 0.8936\n",
            "Epoch 590/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9149\n",
            "Epoch 591/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.9149\n",
            "Epoch 592/1000\n",
            "53/53 [==============================] - 0s 627us/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.5742 - val_accuracy: 0.9149\n",
            "Epoch 593/1000\n",
            "53/53 [==============================] - 0s 787us/step - loss: 0.0370 - accuracy: 0.9811 - val_loss: 0.5672 - val_accuracy: 0.9149\n",
            "Epoch 594/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0887 - accuracy: 0.9811 - val_loss: 0.4940 - val_accuracy: 0.9149\n",
            "Epoch 595/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.8936\n",
            "Epoch 596/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.8936\n",
            "Epoch 597/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0412 - accuracy: 0.9811 - val_loss: 0.3670 - val_accuracy: 0.8936\n",
            "Epoch 598/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0729 - accuracy: 0.9811 - val_loss: 0.3544 - val_accuracy: 0.8936\n",
            "Epoch 599/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 0.3364 - val_accuracy: 0.8936\n",
            "Epoch 600/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0297 - accuracy: 0.9811 - val_loss: 0.3174 - val_accuracy: 0.8936\n",
            "Epoch 601/1000\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0347 - accuracy: 0.9811 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
            "Epoch 602/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9149\n",
            "Epoch 603/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9149\n",
            "Epoch 604/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9149\n",
            "Epoch 605/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0307 - accuracy: 0.9811 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
            "Epoch 606/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0339 - accuracy: 0.9811 - val_loss: 0.2824 - val_accuracy: 0.9149\n",
            "Epoch 607/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0228 - accuracy: 0.9811 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
            "Epoch 608/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9149\n",
            "Epoch 609/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0890 - accuracy: 0.9623 - val_loss: 0.3311 - val_accuracy: 0.9149\n",
            "Epoch 610/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9149\n",
            "Epoch 611/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0575 - accuracy: 0.9623 - val_loss: 0.4238 - val_accuracy: 0.9149\n",
            "Epoch 612/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0599 - accuracy: 0.9623 - val_loss: 0.3799 - val_accuracy: 0.9149\n",
            "Epoch 613/1000\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.8936\n",
            "Epoch 614/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0574 - accuracy: 0.9623 - val_loss: 0.3494 - val_accuracy: 0.8936\n",
            "Epoch 615/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0374 - accuracy: 0.9623 - val_loss: 0.3597 - val_accuracy: 0.8936\n",
            "Epoch 616/1000\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0742 - accuracy: 0.9811 - val_loss: 0.3943 - val_accuracy: 0.8936\n",
            "Epoch 617/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0670 - accuracy: 0.9434 - val_loss: 0.4602 - val_accuracy: 0.9149\n",
            "Epoch 618/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0391 - accuracy: 0.9811 - val_loss: 0.4922 - val_accuracy: 0.9149\n",
            "Epoch 619/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0404 - accuracy: 0.9811 - val_loss: 0.4816 - val_accuracy: 0.9149\n",
            "Epoch 620/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0312 - accuracy: 0.9811 - val_loss: 0.4393 - val_accuracy: 0.9149\n",
            "Epoch 621/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.8936\n",
            "Epoch 622/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9149\n",
            "Epoch 623/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.1039 - accuracy: 0.9811 - val_loss: 0.3417 - val_accuracy: 0.8936\n",
            "Epoch 624/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.8936\n",
            "Epoch 625/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8936\n",
            "Epoch 626/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0421 - accuracy: 0.9623 - val_loss: 0.5183 - val_accuracy: 0.9149\n",
            "Epoch 627/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.9149\n",
            "Epoch 628/1000\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.1104 - accuracy: 0.9623 - val_loss: 0.4902 - val_accuracy: 0.8936\n",
            "Epoch 629/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.8723\n",
            "Epoch 630/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.8723\n",
            "Epoch 631/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0400 - accuracy: 0.9811 - val_loss: 0.4243 - val_accuracy: 0.8936\n",
            "Epoch 632/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0965 - accuracy: 0.9434 - val_loss: 0.4391 - val_accuracy: 0.8723\n",
            "Epoch 633/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0403 - accuracy: 0.9811 - val_loss: 0.4751 - val_accuracy: 0.8936\n",
            "Epoch 634/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0271 - accuracy: 0.9811 - val_loss: 0.5139 - val_accuracy: 0.9149\n",
            "Epoch 635/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0411 - accuracy: 0.9623 - val_loss: 0.5378 - val_accuracy: 0.9149\n",
            "Epoch 636/1000\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0563 - accuracy: 0.9623 - val_loss: 0.5209 - val_accuracy: 0.9149\n",
            "Epoch 637/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0311 - accuracy: 0.9811 - val_loss: 0.4432 - val_accuracy: 0.8936\n",
            "Epoch 638/1000\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9149\n",
            "Epoch 639/1000\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.9149\n",
            "Epoch 640/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0345 - accuracy: 0.9811 - val_loss: 0.3381 - val_accuracy: 0.9149\n",
            "Epoch 641/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0483 - accuracy: 0.9811 - val_loss: 0.3414 - val_accuracy: 0.9149\n",
            "Epoch 642/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.0430 - accuracy: 0.9811 - val_loss: 0.3463 - val_accuracy: 0.9149\n",
            "Epoch 643/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0379 - accuracy: 0.9811 - val_loss: 0.3679 - val_accuracy: 0.9149\n",
            "Epoch 644/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0574 - accuracy: 0.9811 - val_loss: 0.3709 - val_accuracy: 0.9149\n",
            "Epoch 645/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0365 - accuracy: 0.9811 - val_loss: 0.3676 - val_accuracy: 0.9149\n",
            "Epoch 646/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0273 - accuracy: 0.9811 - val_loss: 0.3358 - val_accuracy: 0.9149\n",
            "Epoch 647/1000\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9149\n",
            "Epoch 648/1000\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9149\n",
            "Epoch 649/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0446 - accuracy: 0.9623 - val_loss: 0.3235 - val_accuracy: 0.8936\n",
            "Epoch 650/1000\n",
            "53/53 [==============================] - 0s 815us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.8936\n",
            "Epoch 651/1000\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0239 - accuracy: 0.9811 - val_loss: 0.3928 - val_accuracy: 0.9149\n",
            "Epoch 652/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9149\n",
            "Epoch 653/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0337 - accuracy: 0.9811 - val_loss: 0.4720 - val_accuracy: 0.9149\n",
            "Epoch 654/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9149\n",
            "Epoch 655/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0468 - accuracy: 0.9811 - val_loss: 0.4634 - val_accuracy: 0.9149\n",
            "Epoch 656/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0404 - accuracy: 0.9623 - val_loss: 0.4095 - val_accuracy: 0.8936\n",
            "Epoch 657/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0468 - accuracy: 0.9811 - val_loss: 0.3750 - val_accuracy: 0.8936\n",
            "Epoch 658/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0378 - accuracy: 0.9811 - val_loss: 0.3587 - val_accuracy: 0.8936\n",
            "Epoch 659/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0646 - accuracy: 0.9623 - val_loss: 0.3631 - val_accuracy: 0.8936\n",
            "Epoch 660/1000\n",
            "53/53 [==============================] - 0s 815us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8936\n",
            "Epoch 661/1000\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.8936\n",
            "Epoch 662/1000\n",
            "53/53 [==============================] - 0s 601us/step - loss: 0.0295 - accuracy: 0.9811 - val_loss: 0.3884 - val_accuracy: 0.9149\n",
            "Epoch 663/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9149\n",
            "Epoch 664/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0633 - accuracy: 0.9623 - val_loss: 0.3684 - val_accuracy: 0.9149\n",
            "Epoch 665/1000\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.8936\n",
            "Epoch 666/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0276 - accuracy: 0.9811 - val_loss: 0.3186 - val_accuracy: 0.9149\n",
            "Epoch 667/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0174 - accuracy: 0.9811 - val_loss: 0.3065 - val_accuracy: 0.9149\n",
            "Epoch 668/1000\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9149\n",
            "Epoch 669/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.0434 - accuracy: 0.9623 - val_loss: 0.3045 - val_accuracy: 0.9362\n",
            "Epoch 670/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9149\n",
            "Epoch 671/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9149\n",
            "Epoch 672/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9149\n",
            "Epoch 673/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8936\n",
            "Epoch 674/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0195 - accuracy: 0.9811 - val_loss: 0.4454 - val_accuracy: 0.8936\n",
            "Epoch 675/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8936\n",
            "Epoch 676/1000\n",
            "53/53 [==============================] - 0s 776us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9149\n",
            "Epoch 677/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9149\n",
            "Epoch 678/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9149\n",
            "Epoch 679/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0631 - accuracy: 0.9811 - val_loss: 0.3748 - val_accuracy: 0.9149\n",
            "Epoch 680/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9149\n",
            "Epoch 681/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0224 - accuracy: 0.9811 - val_loss: 0.3584 - val_accuracy: 0.9149\n",
            "Epoch 682/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0301 - accuracy: 0.9811 - val_loss: 0.3547 - val_accuracy: 0.9149\n",
            "Epoch 683/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9149\n",
            "Epoch 684/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9149\n",
            "Epoch 685/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0476 - accuracy: 0.9623 - val_loss: 0.3661 - val_accuracy: 0.9149\n",
            "Epoch 686/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9149\n",
            "Epoch 687/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9149\n",
            "Epoch 688/1000\n",
            "53/53 [==============================] - 0s 840us/step - loss: 0.1047 - accuracy: 0.9811 - val_loss: 0.3623 - val_accuracy: 0.9149\n",
            "Epoch 689/1000\n",
            "53/53 [==============================] - 0s 832us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9149\n",
            "Epoch 690/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
            "Epoch 691/1000\n",
            "53/53 [==============================] - 0s 903us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.8936\n",
            "Epoch 692/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0438 - accuracy: 0.9623 - val_loss: 0.3499 - val_accuracy: 0.8936\n",
            "Epoch 693/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0246 - accuracy: 0.9811 - val_loss: 0.3527 - val_accuracy: 0.8936\n",
            "Epoch 694/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.8936\n",
            "Epoch 695/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9149\n",
            "Epoch 696/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9149\n",
            "Epoch 697/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0222 - accuracy: 0.9811 - val_loss: 0.3833 - val_accuracy: 0.9149\n",
            "Epoch 698/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9149\n",
            "Epoch 699/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9149\n",
            "Epoch 700/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0195 - accuracy: 0.9811 - val_loss: 0.3929 - val_accuracy: 0.9149\n",
            "Epoch 701/1000\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9149\n",
            "Epoch 702/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9149\n",
            "Epoch 703/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9149\n",
            "Epoch 704/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0249 - accuracy: 0.9811 - val_loss: 0.3478 - val_accuracy: 0.9149\n",
            "Epoch 705/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9149\n",
            "Epoch 706/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9149\n",
            "Epoch 707/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.3266 - val_accuracy: 0.9149\n",
            "Epoch 708/1000\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9149\n",
            "Epoch 709/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9149\n",
            "Epoch 710/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0309 - accuracy: 0.9811 - val_loss: 0.3404 - val_accuracy: 0.9149\n",
            "Epoch 711/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0296 - accuracy: 0.9811 - val_loss: 0.3656 - val_accuracy: 0.9149\n",
            "Epoch 712/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0495 - accuracy: 0.9811 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
            "Epoch 713/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9149\n",
            "Epoch 714/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0273 - accuracy: 0.9811 - val_loss: 0.3566 - val_accuracy: 0.9149\n",
            "Epoch 715/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0462 - accuracy: 0.9811 - val_loss: 0.3376 - val_accuracy: 0.8936\n",
            "Epoch 716/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
            "Epoch 717/1000\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9149\n",
            "Epoch 718/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0568 - accuracy: 0.9623 - val_loss: 0.3365 - val_accuracy: 0.9149\n",
            "Epoch 719/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0663 - accuracy: 0.9811 - val_loss: 0.3363 - val_accuracy: 0.9149\n",
            "Epoch 720/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0140 - accuracy: 0.9811 - val_loss: 0.3609 - val_accuracy: 0.9149\n",
            "Epoch 721/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9362\n",
            "Epoch 722/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9149\n",
            "Epoch 723/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0231 - accuracy: 0.9811 - val_loss: 0.4339 - val_accuracy: 0.9149\n",
            "Epoch 724/1000\n",
            "53/53 [==============================] - 0s 926us/step - loss: 0.0539 - accuracy: 0.9811 - val_loss: 0.4113 - val_accuracy: 0.9362\n",
            "Epoch 725/1000\n",
            "53/53 [==============================] - 0s 824us/step - loss: 0.0501 - accuracy: 0.9811 - val_loss: 0.3740 - val_accuracy: 0.9362\n",
            "Epoch 726/1000\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.3292 - val_accuracy: 0.9149\n",
            "Epoch 727/1000\n",
            "53/53 [==============================] - 0s 641us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9362\n",
            "Epoch 728/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9149\n",
            "Epoch 729/1000\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0334 - accuracy: 0.9623 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
            "Epoch 730/1000\n",
            "53/53 [==============================] - 0s 782us/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.3150 - val_accuracy: 0.9149\n",
            "Epoch 731/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9362\n",
            "Epoch 732/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0236 - accuracy: 0.9811 - val_loss: 0.3535 - val_accuracy: 0.9149\n",
            "Epoch 733/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9362\n",
            "Epoch 734/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0209 - accuracy: 0.9811 - val_loss: 0.4336 - val_accuracy: 0.9149\n",
            "Epoch 735/1000\n",
            "53/53 [==============================] - 0s 744us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9149\n",
            "Epoch 736/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9149\n",
            "Epoch 737/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0250 - accuracy: 0.9811 - val_loss: 0.4119 - val_accuracy: 0.9362\n",
            "Epoch 738/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0258 - accuracy: 0.9811 - val_loss: 0.3706 - val_accuracy: 0.9362\n",
            "Epoch 739/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0249 - accuracy: 0.9811 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
            "Epoch 740/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9149\n",
            "Epoch 741/1000\n",
            "53/53 [==============================] - 0s 880us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9149\n",
            "Epoch 742/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0448 - accuracy: 0.9811 - val_loss: 0.3073 - val_accuracy: 0.9149\n",
            "Epoch 743/1000\n",
            "53/53 [==============================] - 0s 621us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9149\n",
            "Epoch 744/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9362\n",
            "Epoch 745/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0567 - accuracy: 0.9623 - val_loss: 0.3181 - val_accuracy: 0.9362\n",
            "Epoch 746/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9149\n",
            "Epoch 747/1000\n",
            "53/53 [==============================] - 0s 635us/step - loss: 0.0427 - accuracy: 0.9811 - val_loss: 0.3586 - val_accuracy: 0.9362\n",
            "Epoch 748/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.0446 - accuracy: 0.9811 - val_loss: 0.3674 - val_accuracy: 0.9362\n",
            "Epoch 749/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.1809 - accuracy: 0.9245 - val_loss: 0.3831 - val_accuracy: 0.9362\n",
            "Epoch 750/1000\n",
            "53/53 [==============================] - 0s 630us/step - loss: 0.0190 - accuracy: 0.9811 - val_loss: 0.3991 - val_accuracy: 0.8936\n",
            "Epoch 751/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.8936\n",
            "Epoch 752/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0234 - accuracy: 0.9811 - val_loss: 0.4428 - val_accuracy: 0.8936\n",
            "Epoch 753/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8936\n",
            "Epoch 754/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0175 - accuracy: 0.9811 - val_loss: 0.4825 - val_accuracy: 0.8936\n",
            "Epoch 755/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0980 - accuracy: 0.9811 - val_loss: 0.5129 - val_accuracy: 0.8936\n",
            "Epoch 756/1000\n",
            "53/53 [==============================] - 0s 626us/step - loss: 0.0763 - accuracy: 0.9811 - val_loss: 0.5233 - val_accuracy: 0.8936\n",
            "Epoch 757/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.8936\n",
            "Epoch 758/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0578 - accuracy: 0.9623 - val_loss: 0.4709 - val_accuracy: 0.8723\n",
            "Epoch 759/1000\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0343 - accuracy: 0.9811 - val_loss: 0.4349 - val_accuracy: 0.8936\n",
            "Epoch 760/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0216 - accuracy: 0.9811 - val_loss: 0.4180 - val_accuracy: 0.9149\n",
            "Epoch 761/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0699 - accuracy: 0.9434 - val_loss: 0.4042 - val_accuracy: 0.9149\n",
            "Epoch 762/1000\n",
            "53/53 [==============================] - 0s 630us/step - loss: 0.0295 - accuracy: 0.9811 - val_loss: 0.3910 - val_accuracy: 0.8936\n",
            "Epoch 763/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.8936\n",
            "Epoch 764/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0203 - accuracy: 0.9811 - val_loss: 0.3812 - val_accuracy: 0.8936\n",
            "Epoch 765/1000\n",
            "53/53 [==============================] - 0s 604us/step - loss: 0.0581 - accuracy: 0.9811 - val_loss: 0.3791 - val_accuracy: 0.9149\n",
            "Epoch 766/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9149\n",
            "Epoch 767/1000\n",
            "53/53 [==============================] - 0s 650us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
            "Epoch 768/1000\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9149\n",
            "Epoch 769/1000\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9149\n",
            "Epoch 770/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9149\n",
            "Epoch 771/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0276 - accuracy: 0.9811 - val_loss: 0.3616 - val_accuracy: 0.9149\n",
            "Epoch 772/1000\n",
            "53/53 [==============================] - 0s 591us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9149\n",
            "Epoch 773/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.8936\n",
            "Epoch 774/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0434 - accuracy: 0.9811 - val_loss: 0.3367 - val_accuracy: 0.8936\n",
            "Epoch 775/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.8936\n",
            "Epoch 776/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.8936\n",
            "Epoch 777/1000\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
            "Epoch 778/1000\n",
            "53/53 [==============================] - 0s 629us/step - loss: 0.0689 - accuracy: 0.9811 - val_loss: 0.3305 - val_accuracy: 0.9149\n",
            "Epoch 779/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.8936\n",
            "Epoch 780/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.8936\n",
            "Epoch 781/1000\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0722 - accuracy: 0.9811 - val_loss: 0.3475 - val_accuracy: 0.8936\n",
            "Epoch 782/1000\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0218 - accuracy: 0.9811 - val_loss: 0.3478 - val_accuracy: 0.8936\n",
            "Epoch 783/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0237 - accuracy: 0.9811 - val_loss: 0.3513 - val_accuracy: 0.9149\n",
            "Epoch 784/1000\n",
            "53/53 [==============================] - 0s 613us/step - loss: 0.1063 - accuracy: 0.9811 - val_loss: 0.3877 - val_accuracy: 0.9149\n",
            "Epoch 785/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8936\n",
            "Epoch 786/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0678 - accuracy: 0.9623 - val_loss: 0.5012 - val_accuracy: 0.9149\n",
            "Epoch 787/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.8936\n",
            "Epoch 788/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.8723\n",
            "Epoch 789/1000\n",
            "53/53 [==============================] - 0s 798us/step - loss: 0.0238 - accuracy: 0.9811 - val_loss: 0.4593 - val_accuracy: 0.8936\n",
            "Epoch 790/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0379 - accuracy: 0.9811 - val_loss: 0.4620 - val_accuracy: 0.8936\n",
            "Epoch 791/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.8723\n",
            "Epoch 792/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0302 - accuracy: 0.9811 - val_loss: 0.4925 - val_accuracy: 0.8723\n",
            "Epoch 793/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8723\n",
            "Epoch 794/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.8936\n",
            "Epoch 795/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 0.9149\n",
            "Epoch 796/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.9149\n",
            "Epoch 797/1000\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5593 - val_accuracy: 0.9149\n",
            "Epoch 798/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0811 - accuracy: 0.9434 - val_loss: 0.5299 - val_accuracy: 0.9149\n",
            "Epoch 799/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8936\n",
            "Epoch 800/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0291 - accuracy: 0.9811 - val_loss: 0.4755 - val_accuracy: 0.8936\n",
            "Epoch 801/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.8936\n",
            "Epoch 802/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.8936\n",
            "Epoch 803/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9149\n",
            "Epoch 804/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9149\n",
            "Epoch 805/1000\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0178 - accuracy: 0.9811 - val_loss: 0.4097 - val_accuracy: 0.9149\n",
            "Epoch 806/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9149\n",
            "Epoch 807/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0313 - accuracy: 0.9811 - val_loss: 0.4086 - val_accuracy: 0.9149\n",
            "Epoch 808/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.8936\n",
            "Epoch 809/1000\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.8936\n",
            "Epoch 810/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.8936\n",
            "Epoch 811/1000\n",
            "53/53 [==============================] - 0s 770us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.8936\n",
            "Epoch 812/1000\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.8936\n",
            "Epoch 813/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8936\n",
            "Epoch 814/1000\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.8936\n",
            "Epoch 815/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0264 - accuracy: 0.9811 - val_loss: 0.4051 - val_accuracy: 0.8936\n",
            "Epoch 816/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.8936\n",
            "Epoch 817/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0334 - accuracy: 0.9811 - val_loss: 0.4046 - val_accuracy: 0.8936\n",
            "Epoch 818/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.8936\n",
            "Epoch 819/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8936\n",
            "Epoch 820/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9149\n",
            "Epoch 821/1000\n",
            "53/53 [==============================] - 0s 807us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9149\n",
            "Epoch 822/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9149\n",
            "Epoch 823/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0240 - accuracy: 0.9811 - val_loss: 0.4634 - val_accuracy: 0.8936\n",
            "Epoch 824/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9149\n",
            "Epoch 825/1000\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.9149\n",
            "Epoch 826/1000\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.9149\n",
            "Epoch 827/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0463 - accuracy: 0.9811 - val_loss: 0.5256 - val_accuracy: 0.8936\n",
            "Epoch 828/1000\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8723\n",
            "Epoch 829/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8936\n",
            "Epoch 830/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0434 - accuracy: 0.9811 - val_loss: 0.4905 - val_accuracy: 0.8936\n",
            "Epoch 831/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0308 - accuracy: 0.9811 - val_loss: 0.5163 - val_accuracy: 0.8723\n",
            "Epoch 832/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.8723\n",
            "Epoch 833/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5558 - val_accuracy: 0.8723\n",
            "Epoch 834/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.8723\n",
            "Epoch 835/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8723\n",
            "Epoch 836/1000\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.8936\n",
            "Epoch 837/1000\n",
            "53/53 [==============================] - 0s 795us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.9149\n",
            "Epoch 838/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0300 - accuracy: 0.9811 - val_loss: 0.5998 - val_accuracy: 0.9149\n",
            "Epoch 839/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0647 - accuracy: 0.9811 - val_loss: 0.5780 - val_accuracy: 0.8723\n",
            "Epoch 840/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0728 - accuracy: 0.9811 - val_loss: 0.5714 - val_accuracy: 0.8723\n",
            "Epoch 841/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.8723\n",
            "Epoch 842/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.8723\n",
            "Epoch 843/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.8723\n",
            "Epoch 844/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0361 - accuracy: 0.9811 - val_loss: 0.5151 - val_accuracy: 0.8723\n",
            "Epoch 845/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.8936\n",
            "Epoch 846/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0265 - accuracy: 0.9811 - val_loss: 0.4785 - val_accuracy: 0.8936\n",
            "Epoch 847/1000\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.9149\n",
            "Epoch 848/1000\n",
            "53/53 [==============================] - 0s 604us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9149\n",
            "Epoch 849/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0181 - accuracy: 0.9811 - val_loss: 0.4677 - val_accuracy: 0.9149\n",
            "Epoch 850/1000\n",
            "53/53 [==============================] - 0s 783us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.8936\n",
            "Epoch 851/1000\n",
            "53/53 [==============================] - 0s 633us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9149\n",
            "Epoch 852/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0148 - accuracy: 0.9811 - val_loss: 0.5416 - val_accuracy: 0.9149\n",
            "Epoch 853/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.5262 - val_accuracy: 0.9149\n",
            "Epoch 854/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8936\n",
            "Epoch 855/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0261 - accuracy: 0.9811 - val_loss: 0.4659 - val_accuracy: 0.9149\n",
            "Epoch 856/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0146 - accuracy: 0.9811 - val_loss: 0.4383 - val_accuracy: 0.8936\n",
            "Epoch 857/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.8936\n",
            "Epoch 858/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.8936\n",
            "Epoch 859/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0291 - accuracy: 0.9811 - val_loss: 0.4205 - val_accuracy: 0.9149\n",
            "Epoch 860/1000\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.8936\n",
            "Epoch 861/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0250 - accuracy: 0.9811 - val_loss: 0.4128 - val_accuracy: 0.8936\n",
            "Epoch 862/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.8936\n",
            "Epoch 863/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9149\n",
            "Epoch 864/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9149\n",
            "Epoch 865/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9149\n",
            "Epoch 866/1000\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0388 - accuracy: 0.9623 - val_loss: 0.4584 - val_accuracy: 0.9149\n",
            "Epoch 867/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0228 - accuracy: 0.9811 - val_loss: 0.4491 - val_accuracy: 0.9149\n",
            "Epoch 868/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9149\n",
            "Epoch 869/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9149\n",
            "Epoch 870/1000\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0340 - accuracy: 0.9811 - val_loss: 0.4303 - val_accuracy: 0.9149\n",
            "Epoch 871/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0397 - accuracy: 0.9811 - val_loss: 0.4278 - val_accuracy: 0.9149\n",
            "Epoch 872/1000\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9149\n",
            "Epoch 873/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9149\n",
            "Epoch 874/1000\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.0354 - accuracy: 0.9811 - val_loss: 0.4211 - val_accuracy: 0.9149\n",
            "Epoch 875/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.8936\n",
            "Epoch 876/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9149\n",
            "Epoch 877/1000\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9149\n",
            "Epoch 878/1000\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9149\n",
            "Epoch 879/1000\n",
            "53/53 [==============================] - 0s 735us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9149\n",
            "Epoch 880/1000\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9149\n",
            "Epoch 881/1000\n",
            "53/53 [==============================] - 0s 891us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9149\n",
            "Epoch 882/1000\n",
            "53/53 [==============================] - 0s 859us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9149\n",
            "Epoch 883/1000\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.8936\n",
            "Epoch 884/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9149\n",
            "Epoch 885/1000\n",
            "53/53 [==============================] - 0s 736us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9149\n",
            "Epoch 886/1000\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0279 - accuracy: 0.9811 - val_loss: 0.3921 - val_accuracy: 0.8936\n",
            "Epoch 887/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.1019 - accuracy: 0.9623 - val_loss: 0.3926 - val_accuracy: 0.8936\n",
            "Epoch 888/1000\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9149\n",
            "Epoch 889/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9149\n",
            "Epoch 890/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9149\n",
            "Epoch 891/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9149\n",
            "Epoch 892/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9149\n",
            "Epoch 893/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9149\n",
            "Epoch 894/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9149\n",
            "Epoch 895/1000\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.9149\n",
            "Epoch 896/1000\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9149\n",
            "Epoch 897/1000\n",
            "53/53 [==============================] - 0s 615us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9149\n",
            "Epoch 898/1000\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.9149\n",
            "Epoch 899/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9149\n",
            "Epoch 900/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9149\n",
            "Epoch 901/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.8936\n",
            "Epoch 902/1000\n",
            "53/53 [==============================] - 0s 819us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9149\n",
            "Epoch 903/1000\n",
            "53/53 [==============================] - 0s 858us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.9149\n",
            "Epoch 904/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9149\n",
            "Epoch 905/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9149\n",
            "Epoch 906/1000\n",
            "53/53 [==============================] - 0s 621us/step - loss: 0.0187 - accuracy: 0.9811 - val_loss: 0.4531 - val_accuracy: 0.9149\n",
            "Epoch 907/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9149\n",
            "Epoch 908/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9149\n",
            "Epoch 909/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0287 - accuracy: 0.9811 - val_loss: 0.4100 - val_accuracy: 0.9149\n",
            "Epoch 910/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9149\n",
            "Epoch 911/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0214 - accuracy: 0.9811 - val_loss: 0.3874 - val_accuracy: 0.9149\n",
            "Epoch 912/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0166 - accuracy: 0.9811 - val_loss: 0.3846 - val_accuracy: 0.9149\n",
            "Epoch 913/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9149\n",
            "Epoch 914/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9149\n",
            "Epoch 915/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9149\n",
            "Epoch 916/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.9149\n",
            "Epoch 917/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9149\n",
            "Epoch 918/1000\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0155 - accuracy: 0.9811 - val_loss: 0.4090 - val_accuracy: 0.9149\n",
            "Epoch 919/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0187 - accuracy: 0.9811 - val_loss: 0.3978 - val_accuracy: 0.9149\n",
            "Epoch 920/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.9149\n",
            "Epoch 921/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9362\n",
            "Epoch 922/1000\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.0431 - accuracy: 0.9811 - val_loss: 0.3744 - val_accuracy: 0.9362\n",
            "Epoch 923/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9149\n",
            "Epoch 924/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9149\n",
            "Epoch 925/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0226 - accuracy: 0.9811 - val_loss: 0.3836 - val_accuracy: 0.9149\n",
            "Epoch 926/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.8936\n",
            "Epoch 927/1000\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0374 - accuracy: 0.9811 - val_loss: 0.3882 - val_accuracy: 0.9149\n",
            "Epoch 928/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9149\n",
            "Epoch 929/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9149\n",
            "Epoch 930/1000\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9149\n",
            "Epoch 931/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9149\n",
            "Epoch 932/1000\n",
            "53/53 [==============================] - 0s 618us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9149\n",
            "Epoch 933/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0231 - accuracy: 0.9811 - val_loss: 0.3991 - val_accuracy: 0.9149\n",
            "Epoch 934/1000\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9149\n",
            "Epoch 935/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8936\n",
            "Epoch 936/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.8936\n",
            "Epoch 937/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.8936\n",
            "Epoch 938/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9149\n",
            "Epoch 939/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9149\n",
            "Epoch 940/1000\n",
            "53/53 [==============================] - 0s 762us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9149\n",
            "Epoch 941/1000\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.4282 - val_accuracy: 0.9149\n",
            "Epoch 942/1000\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.0406 - accuracy: 0.9623 - val_loss: 0.4051 - val_accuracy: 0.9149\n",
            "Epoch 943/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.8936\n",
            "Epoch 944/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0197 - accuracy: 0.9811 - val_loss: 0.3880 - val_accuracy: 0.9149\n",
            "Epoch 945/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9149\n",
            "Epoch 946/1000\n",
            "53/53 [==============================] - 0s 604us/step - loss: 0.0166 - accuracy: 0.9811 - val_loss: 0.3909 - val_accuracy: 0.9149\n",
            "Epoch 947/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 8.8196e-04 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.9149\n",
            "Epoch 948/1000\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9149\n",
            "Epoch 949/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9149\n",
            "Epoch 950/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9149\n",
            "Epoch 951/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9149\n",
            "Epoch 952/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9149\n",
            "Epoch 953/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9149\n",
            "Epoch 954/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9149\n",
            "Epoch 955/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9362\n",
            "Epoch 956/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9362\n",
            "Epoch 957/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9362\n",
            "Epoch 958/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0322 - accuracy: 0.9811 - val_loss: 0.3702 - val_accuracy: 0.9362\n",
            "Epoch 959/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9362\n",
            "Epoch 960/1000\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.9362\n",
            "Epoch 961/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9149\n",
            "Epoch 962/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9149\n",
            "Epoch 963/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9149\n",
            "Epoch 964/1000\n",
            "53/53 [==============================] - 0s 736us/step - loss: 0.0353 - accuracy: 0.9811 - val_loss: 0.3642 - val_accuracy: 0.9149\n",
            "Epoch 965/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9149\n",
            "Epoch 966/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9362\n",
            "Epoch 967/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9149\n",
            "Epoch 968/1000\n",
            "53/53 [==============================] - 0s 787us/step - loss: 0.0240 - accuracy: 0.9811 - val_loss: 0.3889 - val_accuracy: 0.9149\n",
            "Epoch 969/1000\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0211 - accuracy: 0.9811 - val_loss: 0.3871 - val_accuracy: 0.9149\n",
            "Epoch 970/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0344 - accuracy: 0.9811 - val_loss: 0.3985 - val_accuracy: 0.9149\n",
            "Epoch 971/1000\n",
            "53/53 [==============================] - 0s 610us/step - loss: 0.0169 - accuracy: 0.9811 - val_loss: 0.4031 - val_accuracy: 0.9149\n",
            "Epoch 972/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9149\n",
            "Epoch 973/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9149\n",
            "Epoch 974/1000\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9362\n",
            "Epoch 975/1000\n",
            "53/53 [==============================] - 0s 819us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9362\n",
            "Epoch 976/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0229 - accuracy: 0.9811 - val_loss: 0.4232 - val_accuracy: 0.9149\n",
            "Epoch 977/1000\n",
            "53/53 [==============================] - 0s 779us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9149\n",
            "Epoch 978/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.9149\n",
            "Epoch 979/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0280 - accuracy: 0.9811 - val_loss: 0.5315 - val_accuracy: 0.8936\n",
            "Epoch 980/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.8723\n",
            "Epoch 981/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8723\n",
            "Epoch 982/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.8723\n",
            "Epoch 983/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.8723\n",
            "Epoch 984/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0160 - accuracy: 0.9811 - val_loss: 0.5828 - val_accuracy: 0.8723\n",
            "Epoch 985/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.5785 - val_accuracy: 0.8723\n",
            "Epoch 986/1000\n",
            "53/53 [==============================] - 0s 819us/step - loss: 0.0353 - accuracy: 0.9811 - val_loss: 0.5825 - val_accuracy: 0.8723\n",
            "Epoch 987/1000\n",
            "53/53 [==============================] - 0s 980us/step - loss: 0.0173 - accuracy: 0.9811 - val_loss: 0.5942 - val_accuracy: 0.8936\n",
            "Epoch 988/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9149\n",
            "Epoch 989/1000\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0221 - accuracy: 0.9811 - val_loss: 0.6293 - val_accuracy: 0.9149\n",
            "Epoch 990/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0244 - accuracy: 0.9811 - val_loss: 0.6166 - val_accuracy: 0.9149\n",
            "Epoch 991/1000\n",
            "53/53 [==============================] - 0s 776us/step - loss: 0.0477 - accuracy: 0.9811 - val_loss: 0.5808 - val_accuracy: 0.9149\n",
            "Epoch 992/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0530 - accuracy: 0.9623 - val_loss: 0.5274 - val_accuracy: 0.8936\n",
            "Epoch 993/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.8936\n",
            "Epoch 994/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8936\n",
            "Epoch 995/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0208 - accuracy: 0.9811 - val_loss: 0.4758 - val_accuracy: 0.8936\n",
            "Epoch 996/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.8936\n",
            "Epoch 997/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0452 - accuracy: 0.9811 - val_loss: 0.4756 - val_accuracy: 0.8936\n",
            "Epoch 998/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.9149\n",
            "Epoch 999/1000\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.9149\n",
            "Epoch 1000/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd29d5877f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCgqEmGsiELr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "5afdf8fe-64ef-4cd6-f848-fd027b25a603"
      },
      "source": [
        "plt.plot(history_Adam.history['loss'], label = \"train\")\n",
        "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3xUVfr/P2cmk0x6QkIPJQgiHaVYWAtWEAWVtbu77FeX1V1X3V1x8SeL2FbXwroqFuyuvQOCUhQU6QGRXgICCS0hkJ7JlJzfH+eeuefeuXfmTjKTmQnn/XrxujO3ngwzn/vc5zyFUEohkUgkksTHFusBSCQSiSQySEGXSCSSNoIUdIlEImkjSEGXSCSSNoIUdIlEImkjSEGXSCSSNkKSlZ0IIWMA/BeAHcBrlNIndNu7A3gbQI6yz1RK6YJg58zPz6c9e/ZszpglEonkpGX9+vXHKKXtjbaFFHRCiB3ALACXACgFsI4QMpdSuk3YbRqAjymlLxFC+gNYAKBnsPP27NkTRUVFFv8EiUQikQAAIWS/2TYrLpeRAIoppXsppW4AHwKYoNuHAshSXmcDONScgUokEomk+VhxuXQFUCK8LwVwpm6fGQAWEUL+AiAdwMURGZ1EIpFILBOpSdEbAbxFKS0AcDmA/xFCAs5NCJlMCCkihBSVl5dH6NISiUQiAaxZ6AcBdBPeFyjrRG4FMAYAKKWrCCFOAPkAysSdKKWzAcwGgOHDh8siMhKJJGw8Hg9KS0vhcrliPZSo4nQ6UVBQAIfDYfkYK4K+DkAfQkghmJDfAOAm3T4HAFwE4C1CSD8ATgDSBJdIJBGntLQUmZmZ6NmzJwghsR5OVKCUoqKiAqWlpSgsLLR8XEiXC6XUC+BOAAsBbAeLZtlKCHmYEDJe2e3vAP5ACPkZwAcAJlFZxlEikUQBl8uFvLy8NivmAEAIQV5eXthPIZbi0JWY8gW6ddOF19sAjArryhKJRNJM2rKYc5rzNyZcpui6fcfxzKKd8PiaYj0UiUQiiSsSTtA37D+B578rhtsrBV0ikbQ+lZWVePHFF8M+7vLLL0dlZWUURqSScILerXINHkp6E15PY6yHIpFITkLMBN3r9QY9bsGCBcjJyYnWsABY9KHHE+1rd+LypMU44WkEy2GSSCSS1mPq1KnYs2cPhg4dCofDAafTidzcXOzYsQO7du3CVVddhZKSErhcLtx9992YPHkyALXcSW1tLcaOHYtf/epXWLlyJbp27Yo5c+YgNTW1xWNLOEGHzQ4AaGryxXggEokk1jw0byu2HaqO6Dn7d8nCg1cOMN3+xBNPYMuWLdi4cSOWLVuGcePGYcuWLf7wwjfeeAPt2rVDQ0MDRowYgYkTJyIvL09zjt27d+ODDz7Aq6++iuuuuw6fffYZbrnllhaPPeEEnSiC7gvxeCORSCStwciRIzWx4s899xy++OILAEBJSQl2794dIOiFhYUYOnQoAGDYsGHYt29fRMaSeIJOFAvdJwVdIjnZCWZJtxbp6arrd9myZViyZAlWrVqFtLQ0XHDBBYax5CkpKf7XdrsdDQ0NERlLwk2KcpeLzyddLhKJpPXJzMxETU2N4baqqirk5uYiLS0NO3bswOrVq1t1bIlnodukhS6RSGJHXl4eRo0ahYEDByI1NRUdO3b0bxszZgxefvll9OvXD3379sVZZ53VqmNLQEFnQ5aTohKJJFa8//77hutTUlLw9ddfG27jfvL8/Hxs2bLFv/7ee++N2LgS1uUiLXSJRCLRknCCbvP70KWgSyQSiUjCCTqxcwtdulwkEolEJPEEXQlbpE3SQpdIJBKRxBN0uwxblEgkEiMST9CVKBcqBV0ikUg0JJyg2/y1XKTLRSKRtC7NLZ3LefbZZ1FfXx/BEWmxJOiEkDGEkJ2EkGJCyFSD7f8hhGxU/u0ihESt6C93uUgLXSKRtDYJL+iEzULOAjAWQH8ANxJC+ov7UEr/SikdSikdCuB5AJ9HY7CAmFgkLXSJRNK6iKVzp0yZAgB46qmnMGLECAwePBgPPvggAKCurg7jxo3DkCFDMHDgQHz00Ud47rnncOjQIYwePRqjR4+OyvisZIqOBFBMKd0LAISQDwFMALDNZP8bATwYmeEFwlP/qcwUlUgkX08FjmyO7Dk7DQLGPmG4SSydCwCLFi3C7t27sXbtWlBKMX78ePzwww8oLy9Hly5dMH/+fACsxkt2djZmzpyJpUuXIj8/P7JjVrDicukKoER4X6qsC4AQ0gNAIYDvTLZPJoQUEUKKysvLwx0rAFaZDJBx6BKJJPYsWrQIixYtwumnn44zzjgDO3bswO7duzFo0CAsXrwY//jHP7B8+XJkZ2e3yngiXcvlBgCfUkoN1ZZSOhvAbAAYPnw4bc4FiF2JcpEuF4lEYmJJtxaUUtx///344x//GLBtw4YNWLBgAaZNm4aLLroI06dPj/p4rFjoBwF0E94XKOuMuAHABy0dVDCky0UikcQKfencyy67DG+88QZqa2sBAAcPHkRZWRkOHTqEtLQ03HLLLZgyZQo2bNhgeHyksWKhrwPQhxBSCCbkNwC4Sb8TIeQ0ALkAVkV0hDrsioUuXS4SiaS1EUvnjh07Fk899RS2b9+Os88+GwCQkZGBd999F8XFxZgyZQpsNhscDgdeeuklAMDkyZMxZswYdOnSBUuXLo34+AiloT0fhJDLATwLwA7gDUrpY4SQhwEUUUrnKvvMAOCklAaENRoxfPhwWlRUFPaAD279EV0/GYcVI1/EqMtvDvt4iUSS2Gzfvh39+vWL9TBaBaO/lRCynlI63Gh/Sz50SukCAAt066br3s8Ia6TNpF2GEwBQWRfY1kkikUhOZhIuUzQ1ORkAcLw2Mj34JBKJpK2QcIIOwoZ84Fj0JhYkEkl8Y8VVnOg0529MPEFXolzKq6OXPiuRSOIXp9OJioqKNi3qlFJUVFTA6XSGdVzC9RRFEvsDHU0uUEpBCInxgCQSSWtSUFCA0tJSNDc5MVFwOp0oKCgI65jEE/SsLqAg6IIKeJsoHHYp6BLJyYTD4UBhYWGshxGXJJ7LJSkFLkc2/ur4DO566UeXSCQSTuIJOoBUD6vOa//h3zEeiUQikcQPCSnoHFK+I9ZDkEgkkrghoQXd50iP9RAkEokkbkhoQffaU2M9BIlEIokbElLQV43+CADQ5JMldCUSiYSTkILe0PF07GnqDOrzxHooEolEEhxvI3Bsd6tcKiEFPdluhxd2UJ871kORSCSS4Cy4F3hhOFB/POqXSkhBT022wQs7mrxS0CUSSZyz70e2rC2L+qUSUtA7ZafCgyS43Y2xHopEIpEEx5HGlnXRL1WQkILeMTMFXtjhlYIukUjiHYcSjVd7NOqXsiTohJAxhJCdhJBiQohhRyJCyHWEkG2EkK2EkPcjO0wtSXYbqC0ZPq+cFJVIJHEOrwrpiX6F2JDFuQghdgCzAFwCoBTAOkLIXErpNmGfPgDuBzCKUnqCENIhWgPmUHsSiE9a6BKJJM5pUgxPT/S7rFmx0EcCKKaU7qWUugF8CGCCbp8/AJhFKT0BAJTSqHv/qc0B0iTj0CUSSZzjUbqreeND0LsCKBHelyrrRE4FcCohZAUhZDUhZEykBmiKzQHSJF0uEslJw7cPA59MApqaYj2S8HBVsWWcCLoVkgD0AXABgBsBvEoIydHvRAiZTAgpIoQUtbQ4PbFLC10iOalY/gyw9Qug4USsR2KdpiagvoK9jhNBPwigm/C+QFknUgpgLqXUQyn9BcAuMIHXQCmdTSkdTikd3r59++aOmZGUDDuVFrpEclLgFebLGqtjN45waTgOcMMzTnzo6wD0IYQUEkKSAdwAYK5uny/BrHMQQvLBXDB7IzjOAKjdCQeViUUSyUlBzWH1dWMCNbapOaK+jgcLnVLqBXAngIUAtgP4mFK6lRDyMCFkvLLbQgAVhJBtAJYCmEIprYjWoAHAZ3fCCRnlIpGcFNQIMdyJJOhbP1dft4KgW+opSildAGCBbt104TUF8DflX6vQlJQKJ5WCLpGcFNQKlm6iCHptOfP7A0BSqhrtEkUSMlMUYILuID5AVlyUJDJNPu1jucQY0UKvj+rDf+TY9qX6ul0h0ArFBBNW0GmSky1bIftKIokaq14AnukLHI/qlFPiw9PmbUlAorSePLAaSMsHppYAdoc6ORpFElfQlfoIjQ11MR6JRNICDm5gy5J1sR1HvFN7BMjsDHQdDuxaGOvRWKOiGOg8GHBmATaHtNCDksQE3dMoBV2SwOQoEcHVpbEdR7xTWw6ktwf6XAwc2wm4E+B3X30QyFb+f+3JreIeTlxBV0pSehtqYzwQiaQFEDtb8gJOJxMla7W+8WDUVwDp+UBOD/a+Ks5vgJQCDZVAai57b3dIQQ8GTckCAPjqK2M8EomkBRAS6xHEBkqB1y8B3rjU2v71FUBaHpBdwN5X63Mb4wxPPSvKlaokzNuTpcslKM5sAFLQJZKEhKfvn9hnbf/640zQucUb7+n/DYouObmgSws9KFS58/nq4/w/ViKxwsnmcuEWts1CKozXDTRWMUHnAtkQ54YcL8iVKgp69C10S4lF8UhuO1ZyvbbyWIxHIpG0AC7kJ1uhuWolld8ZUMNPy7FiwMFClJHWThVIV7wLOrfQmScB9mS1LnoUSVgLvWfXzgCAmsoESTKQSIygPrY82UpB1xxiSy54Rhz/BXhhGLDgPvY+LQ9IcjJxdFUBdceAmQOAI1uiP95w0btcbNLlEpTs9FTU0FQQ8U6970dg/8rYDUoiCRefYpmH82M/uhV4vBtQFecTg8GoVgQ9JdN8H+5f3zmfLVPbsUlkZzYT9OIlLNxzxbNRHWqz4LrUyi6XhBV0m42gGulweIRSmm+NA94cG7tBSSThwl0tVlwu+1cCvywHit5kJWS3z4vu2KIJF/RgIqdP8efimJwOuOuZSIY6R6wImBRtnTj0hPWhA0At0pDsUQr11B9XNzQ1AbaEvVdJTia4q8WKoHNj5ew72dIb/WJPUYOXww2WIKQX9OQMdemuU2P447GeE6/ZLvrQpcslODUkAyle5YOrEzog1cuJUkkrcmI/sOmT5kWqNDXD5aKUvdA0fYg1Pq860WkFvm+wWkz6bdw9k5wOuGvVcrTxaKF76gF7CmBTbjp2B9AKTe0TWtBrNYIuiHht1HtUSyQqn90GfH5b84pGcR96OJOiSmG61ijHaplvZwAzT9M+KQeDG13uIIKu3+a30NOZhc7L6MaloLvU6ByA3YR9blZdM4oktKDX2zLg9Cmp/6JVXicFXdKKlO9ky+bERvtdLiF+6F5BtHh2aTyFOm7/ii2tlrbln5Wn3vzJRrTQiU19MuGCzt018ehy8dT7600BEJ6qotvkIqF96PW2DKR6a4AvbtdaR9WHgcZaICUjdoOTnDzYlZ+Ruxl1hay6XER/Oe9NyR/n4wE+Fiv9Pj0NzP3Ao1U8DUBymvF+nORM9UbGfej8826FTkBh43WpIg6o4u5pYDekKGHJQieEjCGE7CSEFBNCphpsn0QIKSeEbFT+3Rb5oQbSYM+Ek7qAnz8ADv2kbpjzJ+Dxrsyq8eoex3xeoPjbky8zTxI9bEq0RXME3arLxSdY41zco/z4HhY849NKSj7fJ6srW5r50TWCLohgcgb7rLmFHo9Zo54GraDz1+46oHxXcFdTCwgp6IQQO4BZAMYC6A/gRkJIf4NdP6KUDlX+vRbhcRriStLFsDqz2UQEZ8c84NH22vCuda8B714D7PiqNYYoORng4XONLbHQQ7hPRMHnFno8uVx4xIkVceX7cEE3i3TRCL1ggOl96PGYNep1qXMdgCroVaXArBHAxveiclkrFvpIAMWU0r2UUjeADwFMiMpowsRl1wl6Wh6Q0UF9X7KWLX96D9j8KYtE4P710iANBfYsBd79tfoYvPMbYP7fIzdwSdvC1hKXi8WwRdElwy3XePId0ya2DPYZuOtYj00ekZbVhS2tWOjixGdyBnPZcCGPp8lhjpmFfuIXtszoGJXLWhH0rgBKhPelyjo9EwkhmwghnxJCuhmdiBAymRBSRAgpKi8vN9olLNwOAws9PV99zx/t3LXAZ7eySARuRR3dZn7ixf8EihezzFMA+OB6Ztm764G93wP7V7V47JI2hL0FLpcmqy4XQdA8ddpj4wEekhcslHL1S8C3DwM//oe9D+VyEecNxCcY7n7h0WxeV/y5UD0NxhY6bzWY2Tkql41UlMs8AD0ppYMBLAbwttFOlNLZlNLhlNLh7du3b/FF3UlZ2hXnT2VdTTg8dVj8oR3eyJaVB8xPrDTPQOV+7fq6MuCd8cCbY5o1XkkbhQtrc+LCQ6X+e1yspoko3rySX1wJujL+YNZykuIOLS1iS26hm/mTvW7VhSpOfHJBF5trx1NMPsDGo7HQFU2p2MOWmZ2iclkrgn4QgGhxFyjr/FBKKyil/BN9DcCwyAwvOO5kQdD/ug3oO0aNVQXUO7jYFaVkDVsGm7zhX466Y9qJJ6vdVSQnF3zi3V0fvh/db6GbTHDOuxt4bijgEqJHuA86rgRd+QyCCSuvZe5WfN/ZISx0XyPQaZDyRudDB9TG0UD8Zc36GtUbGMCaRQPAkc1sGUOXyzoAfQghhYSQZAA3AJgr7kAIEZ8fxgPYHrkhmuN1CILOw57E+spctHllN5GGE9rHNEpZ30IAaFCSI+ortJM8h39u+aAlbQ9uPa6exaKrwok+8fvQTSz0fcvZUnxa5L7jePKh8xtZMGHVhBcSIEOxUs0mRb1uZsmOmwn8VpCctHaB5/PEWeiit1EboJGpCPjxPUrVyOSoXDakoFNKvQDuBLAQTKg/ppRuJYQ8TAgZr+x2FyFkKyHkZwB3AZgUldHq8CYLpTcdyl27XS91XbDZ7yYP+yJ5Gtgj7PKngad7M/84T0uuO6a1Ao5IQZcYoM9UrA3jSS6UyyVVES+xs4+Zy2Xzp8AbMShO5/Oqfv1gFrq4zZmtWtrBLHR7MjDiVqDH2ep60f/MQ0bjLRbd69Ja6CmZqvcgSv5zwGJiEaV0AYAFunXThdf3A7g/skMLjS1ZDNxX7njn/IX5uoveCDwgszMrCpRVwMpuLriXPQId3QL0uYzts3uhai1t/gTY/LF6fJnw4CELgEk4ejGuOqj6h0MRqtoiT44T/cVmLpfPbmVLfdp5tBGTiYL50MVtqTmqoAfzoYuiyBH9z+n57Dcdd4Lu1k6KAkBuIXB0M5DbM2qXTWhFSk4yGH5KBnD5M8YH8AiYcU+z5e7FTMwBdeL00EbhAN3M+QnhsbexKvD8rmoZAXMyoneXhFN6IlTYoj8cUHBL+JtimBxjJVszkvB4cCCEhS6IbmquIOgm8w7cQtfjzAGUJvF+33S8hS56XYFuFX6Tb1cYtcsmtKCnJJmkPttsgXdHEODK54ALpwGnjgGG/R4awT64gS2rSmCKWC+m4QSz0kU+/T8WAeMyEHtJ24TSQGENx7cdKvU/WHy32TGt/f0TbyBWfeipuew36kjXVkrV7N9obKETAmQXsNfpeYHnjjWUKpOiOg06848s2mXw9VG7dEILenKSDdM8vwe9xiAxVQwZAtgH2fUM4Lwp7AuR20NbSIh/ESsVQe83Xt12zl2B53/tYpaFKsITmepk+d6I464D1r8df/HGRlZyONEnoVL/jSz0UNdpbUEXI3CCTU6K2zK7sN9hVme12YUen9vYQgfUBEIephxPFjp/StHfjHpfBNx/UIjciTwJLegpSTa867sE7v7XBG5M0gm6vpBRp8HGJ+UJEmfeDkwrY/8Blz6ixpGmKRZBfYXBD4qq2ySR5dNbgXl3AUc2xXokWoxENZxyrqHCFvl6IwvdTNBbu7YJt9BtScEtZbEeOHc/ZHbWzg+ImFnoAJsHA4CCkeq+8QL/OwO8BIj6vFtCC3qynQ3f7W0K3Ki30PV0MCpHI548jX2Z+KQUn4k/VRdF8MPTalQMtx7NHiElzYdn7cYbRm6PsFwunuDHcAvdKL7dTNCjGZPtqg6cxOQ+9IyOwQVdvGnl9mDL9HxjA6jJx+YK7CaCfukjwFUvA4Xnsvf8b173upq4FCv4zcXs6SKKJLagK5OijYaCrivHqRf4UIH9Dl2Jy+FKBMFIXSHJ7x4B3r6SvQ7245O0jHisAQ6YuFya4UMPdUw4PvRoWqtPdANmnaldx108GR1CCLqXWa2jH1D9yKnt1LwPEb/bwkQU09oBQ28Umn0o6f8LH2AlBqxSfTjyzbb5Z2BkoUeZhBb0TCeLuqxxGfyouIDzON5kXW10mw0YdC1w8Qx1XbaQEKuvzzzuGeAf+4Eup6uPe5yK3WzJH7V8jSxsae5f1FRfSQvhgh5HJWMBVVT590xcZ+n4ENUW/S4XIx+6yWcR7Q4+VbqyGdzlkt4huA+9ycvqt5x/n1r/Jq2dcYAB/y2ZWegcf+MIJZ/E26DWSwlFUxPrsvT6Jdb2twrPHJaCHh65aezufaLe4AvM43C5a6XbmYH7THwN+NVf1fc53dXX3FfOIUTtOn7RPwPP5fNoa3rsXQpseAdYZLCvJHwUPY87QeeWNU9rB5rncjF78uDrDQXdooXudevCcSOMq5ol+DizQ7tcbLrUl7Q89mSrTwL0i2IItwUXTW+jmtB1fI+1yXP+ZFAdLQtdulzCIieN3eUrjQQ9WanE2PtC4OZPgUseCn1C0a8ezAc/5Abgls+168SJKJ9bLf6V1g6SCECUr2q8ulz6CxWlI+ly4euN/OLiZyFa+HoLfe6dwOzzWx59pS+VwWmsAZxZzIgK5XLRCzp/stHXVgrXQvc0sAQjgFnqVnqbRmvy2BtkUjTKJLigKxZ6ncGPgYcGpXcA+lyirZNuRo9zrF/cmaN9X6ur/HZMccNIQTfH42KTWJas7jj1oXMh7dAPuL9Uuy4UTU3qvEuT19iqNPt7kzO1TwJiBIneQt/0EVu2NJzRrD55YzVL9EkKJei+wGgz/vvQT4yahf7psScDIOy6YvE8K24X8akgkvNePotjjwIJLegZKexuX+c2+NKfdQcw/nlmTYeCz0Z3G8n84wN/HfoYZ7b2vViO1+dmLhcgaq2m2gRFrwPz/2ZcpsEMGqcuF1sSq9dBbNZ92Fys+QS+YcSMiaCn5mpvhKKIm11fzOi0SsMJYN8K9lqcmBXF3VXNLPQkZ2gfeoDLhQu6zqK2KuiEsM+9sUZrVB23MHclWuih6u+4qoGN71tz5fCbWqiniyiQ0ILudLDhuzwGP/LUHOCM36qTL8G46WPgkkfYhM09m4Ffv27h4jpBP/6L+rqyBDi2i73mP6LvHgOeO519ceOpSl4s4YWVrFSx9LtcfMzSFD/vWML/L/n3zJ5s3eXC9+Mp8EbWrdm5Mjtpt1kR9OY04HjnKuCty5lP20zQuYWekslcQ2bf76AuF52gW3W5ACxireYI+5eUyo7hSX7BEC30UKHGS2YAX96hVr8MhtWbURRIcEFnj28uj0HYYjicMhoYdRe721sN/NcL+qEN6uvyHerrHV8Bx4qBH55kj4FPFgKf/6Fl420r8MdvK2F2YtjiK+exGuHxgN9Cd6hLyy4XZT8egWX0OZi5XDI76XzoQVwunOZY6LwhjLtWe17Rp99YwwSdTwyb9RoIaqHrXS4WJ0UB9llwQc/qAgy8hj397VoU/DhxnLUh6u/wz66iOPR4pA+9eTjsNiTZiLGFHm3EL5ozB9jymfq+fCdbprdnP4QXdP0+tn4R/fElAjxyg4t1UISwRbGUbKzhbg8uVPYk6xY6F/4UZQJfFMnNnzKrULw52JKAFMWQyOig3RbMQudja46gcxprzOuPc5eLmEVthJEPPSWLjU/vcgnHQs/twYyo6oNM3EcqBtP717KWkQfXq/u6642bS4cqqMY/QysTqdJCbz5Ohx0NsRB0ALjxI+D6dwNDrtw1zEUQKhv1ZMessYERRolF8eC68rtclB+8zRG+D50LuiiSn93Kem+KNwebA7j9B+DXbzDrr8lE0PUWOp8jarGgm1noVUyYQwq6gYVOiHFykd9CtyCKp13BfoMla1gpga7DgF4XsG3vjAfeViKQmpqA/w4G3lbqNDVUqpOqIS10JdbeitvKH7YoBT1snA57y10uzaXvGKDflcAlD6vruK83qyDQGpFo4T8OS4WVDBKLmuMTjjR6l4s9HJcL96Fzl4uRD104l93BamkPnMiE0dSHrhN0PraWCLq7VmehK/9nlKphi5YE3eA3kdYuMKTSP7FoweVy6hi1+1Feb7Yc+Udh7DVMzKtKmK/80AbmnmmoZOV309oxQXfXAdvnGV+D+9itRMP44jyxiBAyhhCykxBSTAiZGmS/iYQQSggZHrkhBsfpsKExVhY6Z9TdrIjX9e8B7U9j69r1VK0MiTHcQjfrWCPCLXQxyiUcCz9acPG2C4Ju2eWi7JcShqBzbElBfOi67x33aLXkBqi30PnThLuOhV6mZDbPQgdY44fyHUBVqRpFcnA925fXfAkGIaySIcAyuQGg8DyWG9DtLHVMPJQYAMq2sXVp7Vhoc105MPcu4KNb1L6fIjwKJhwLPR5ruRBC7ABmARgLoD+AGwkhAb4EQkgmgLsBrIn0IIMRU5eLSEoG0O8KdbI0t1BNdNBDEv7BKDJwQbYU2mngcmktQd/0MXDA5Gsthi0CYbpclO8tt9BDPanYBEG3O5iQ8pT5YBY6F/hIWujc5cJdESlZ5hOcHKNMUYCVta4oBv4zAHjpHDYftX0e0GNUYPCBGRc/BFzzKnCq0nksJQO47h3WwQxg/nUeeQawQIXaoyxCJqM9s9B5ZMyhn7TnFvsNW2keEue1XEYCKKaU7qWUugF8CGCCwX6PAPg3gFatNJ/qsMdmUtQMojxStisEBl+n3dZbqRlBm+LD/xtruLXjtiA03EIXP7fWKIJWd4xFJb0z3ng7v8H4J0Ud1v9v+c3APykaItpHY6Hbtdf3mljolKoCYyboP38E7Pw6+LU9Lp2Frgg6r4XuzGI+4+RMoM5E0KnBpCjARLe70jO0fCdrFHN8D9A3jP6oGe3Z700/wc7L9FYfYjWXnNlsorWqhAl6Zicm6nVlapJXpdDkZgGyHsEAACAASURBVNE09o/3TA11U9w2BziyBQCxFjIdYaz0FO0KQGzjUwpAUxiFEHIGgG6U0vmEkCkRHF9InA5b7HzoRnDrJLeQPfINvo7FnwPALZ8Cq14EFt7PrMvUHPPznAxwQT++jwlP0GgXZVswSzQaHN2qXNfETtHHoetdISKVB1gBOP0Er1GUixGidcut9SYPgGT1s3CkaT8Xnwf+Ov1m1uUXk9lyhi6TVJO41KB9QvDoLXQh+qbWpL65mcvFkQr8bh77jBtOKPWPaGQ6+2R1Zcvqg8zlkt+XuVeqSphVntGB3QCrDqruPN5w4+B6YOXzwrkKgvc6aKwBPv4te53ktBi9FVla/OxPCLEBmAng7xb2nUwIKSKEFJWXR6ZmeNy4XDiZSlnebiOVjixdtdtD9VE8mfC7XGrMu9ZwuJvKI7hZWuMpp1LpI2vmD/Vb6EJikdG4Dv0EPDsIWP+mus6nmxQNlmUJBPrQxetzqzwli712VQWGGtYbxIfrqxyKiC4gj0vnclFe83ICTqXHZ1YX8/9LM0EH2N+WkskK5F33NnOXRKJsRnp79pmUbWf/8k9lT8+lRexmyF0uTR7VQq9Rxr/pE/U87XqxyJlg9XDEBLkYRLgA1gT9IAChriwKlHWcTAADASwjhOwDcBaAuUYTo5TS2ZTS4ZTS4e3bt9dvbhYpSXHmcrnqZeB3X6mPekkprIXdpAXsPRf0nV+zR0ujVGJPA/DN/W2/lZ27TnVRhYoD5saOpp5IKwg6j3k3E3R92KLdxIdepdR52bVQXcct4GCToiJ6HzqgTsryY1My2fWf6M6eDMUnGqNsSHGdXtzFz9rboHO5KPMePH6cT4hmdQ0i6CY+9Ghis7GJ0qLXWU/gbiOBjgPV3sEZHdmkKCc5U7XCi5ewSdVhk4ArnmXCX3MYWPea2tRGRKyrHiOXqhVBXwegDyGkkBCSDOAGAHP5RkppFaU0n1Lak1LaE8BqAOMppa3SNiQ12W7c4CJWZHVWu6hwLn0E6DmKveaP1wvuZZM/+hh2gJXdXf0isGpWdMcaa9x1ahSD1bZ9ZgWiosUJxUJ31xlbswGZoiYuF54gI2YnmoUt6m/yfHItmA+dfxbOLPXJp65cdeMkOY0FXaxhot8uRh95XFqXEH+a4P9vPEs0qwsTPcPPyiRsMdpc/hQw4GrWpGbQtSxunZPVRdvspvBcdpMqWcd87gMnAlf+F+h1PpCjfFfn/x34WudZ9rpV1xVgLXIrCoQUdEqpF8CdABYC2A7gY0rpVkLIw4QQk5mi1sOZZIsvCz0UybpOSDUGRYF4U4y27mN317K4asB8Io3jd7kIP5RwytQ2F27JgRr7oK1OinoMInp8uklRfrPSV59MyVLPzdH40KG10MXCVNyqzunOknf0bh0xoYY/RfjHLIyVW+jExm5OXNwbjrN1vPpoVhf2mRg9cfncrW+hA0D7vsC1bwFXzGSNa7qNVLd1HAjknaK+zy1kN6mljzLLXQxsGHA1C2xodwqwe7H2szxqEOoYAyz50CmlCyilp1JKT6GUPqasm04pnWuw7wWtZZ0DcehDD4Ve0I0mkPjkTFuPhHHXqU1FQlrois+ltV0uYkd7o/KzAXHoBsW5Gk6YNKgwqeWit/C54IsuF7Gxg7hMyTT2dfP8iMr9TIiObmPvRQu9WhH0H59lpQfcegvdxYpfOVLV/4f648w65zWQ2vViy3l3G1dQ1DdvjwWEAH9YCoybydxd7QqBix5kPQ7S89iNbO8y5moRjarUHBbYMOZx9lkcWKVu45Exf7RQvCuKJHxAdGpynPnQQ6FvhWdkoftDwlpYvzqe8bqZxZapzDWE+lt5xIBoNbaGy8VdpzZLMRpjQBx6kvZGs+F/wL97GncM4sKd5GRiza1eM0G3C9atv7GD8nnwz4KPlcOFvuNAtjyyGfj8NuCls1nYpyjo3Ae85EFWekCcgPY2MFFPStEJeoW2/V6v0UCfS4Fd3zC/tYinQe0kFmu6ngGMuFV9f+7fWHKS2IbSLMqmxyj2f7ZZmDTl5bNzurPSA50GR37MFkh4QWculyZQK3WK4wErFjovAFRzGJiRDXz9D2DePWy9qxqYfy9LXU5keJSPM4u5FEIJOv//bW0L3V0DZCuRSkbzHQHlc3UulzUvs2XpusBj/e4au7aWuL7mO48gEd0VvIZ6zVEWu+11MVeI2GmL2FQLvdtINnFZvERNb6+vYC6X5AxmOVcf1PrvjaJckpzsGvy8Dce10Sg2G6txlNMD2PyZauX7vOzvikGyTVhwP3lKFpDf23iflAxg2O+Bje8BT/dlN8mqEha6mZoD3PYtcHtsLPWEF/TUZPYlj6tY9GDoLfTdi4F3f80egf9dCJTvUoWDZyeueZmFux1YBXz3KLDuVVaWN5HhLojkdJbsEVLQebPkVrbQG2vV0FNDC10XtmjTpf7zG3jZdrb0udl8wYxsloEKMDeN2L7NzIcuwoX7vYnArJHsnEkpWhcBbVKTr5LTgc5DgaNb1O0NJ9RsyeyuzIcuPgHxCVxbEhubt5FdI0m00E8E9t+12YDLHgPKtwM7leiuGGZPhkWXocDIycDkZcH3G3UX+xxqj7BY9coSIEex7mMQf86JwQxFZElPYbPmdW4vUpMToBiW3kLnBfNdVcza2fiuKhz67uqeejUSIR58kS0hbEHnFrrBpKIVts8DfngK+MMy6zXvvY1MnLOtCLry3dPHoXNx5sk+7jo1BX3bl+oxjjT1MwlwuQQRdE7JanaeVF3sNp+bSEphfvQ936rbGo6zsMzsAva++qB2LoOHH6a2YwJOCLuuw6kKeu1RJoJ6TlFqq/A4/kQR9KQUFhUTiqwuwJTdwJw/qy3+Bl0b3bFZIPEtdKXJRYM7QfzoNrtxLRf+SG5PMa+57K4XwtRaIUsymnD/rMOioHNhFN0A4US5fHYbS/wwa75gBBfYLEXwDCdFPcyC5VaZXedD15eFddeweGgRu4MlwPDIEL2Fzl0uojuEu1z816lkYqlPN+fXSnKqE9CcmiPsyaHjQOY7rjqonQTmgp6Wx25uooXudbHPp65MjVQSSU5jx/HImRiWlI0aKZmsMB9n6M2xG4tCwgt6erC+ovEKz0gbPY2V+XSkQ03PrlGjDfR4BEG30uUnnhE70liy0JXPrLmTotwlEqrVmAiv25HVGQAxvtE2eXTRJ6naKBP9DcRdFzj/YU9mNUV4CKHeQvdb3aKg6yx0VyX7LNOVhL3+V7GlaKGLlQuJHVj/Fpvs7DaCPYXUHNbOE2gEvUHrQ/fUq5EdOSYVEbML1H34/IB+3IlO12HA37YDDxxhnc9iTMILOnez1CeKhS6S3we4/Ek2485Z85L5/u461foLlVUY73Dr2m5V0A0s9HBcLtwlEo6g84lb3l7N6FivW9u9KjmdHcetaX0BsSavENuuYE9WaqAcVfcRyVRqfQez0Ju87OluwNXA7SuAITey9X5BTwW6K6Vke41m2ZMlawAQoPB8ZZ6Aalus1Rxi21NzmCB7uKArE7j8hmeWL5HdrW1b6JysLnFzo0p4QU9XJkXrGxNQ0Hl0QJ7JbLoeT4NqlXobgW/+H7B4enTGFm3432FzNN/lEo6gczeX1YxUQJhQzGBuhRMGjam9Ddr5jOR09jThdTGxb/KwRBSR43u17+0OdsNoqGSirXe5GImgUVnZpBTm+uk0UJ2r4bHgSSnsGn9aDVz/P6CzElbXdRj7HvJ5gnKhxGz1IXbjcKRqLfQk5b3fbaa7uXCyu7GbF6Ws/jhgPB8giRgJL+i5aexx98Dx2KTatgieLm0k6GOfDFznqVddDl4XsHoWsOK/0RtfNBHD/Zw5LAszWKEov8tFLM7lZmF7v5iEiB3/RXBjKCIZzpMNL+ubksGyCUWx43C/ModHMbnrVAu/00DtMRV6QU9mnwH1Kda9MtZeo4GrZxuXYTVqnixOOPoFvUK7rUM/5vvtr1TA5vXC+TzBsZ3qOWqPMl84D6nkf6sjlb0XJ7aNyC5gf4+rCvj+SRbWx8vkSqJCwgt67w4ZaJ+ZgvX7w5jsijVdFBcL943qJ5X6X8UsJz3uOtWSdVkotB9pNr6vJlC0FFHQU3MB0OATllzQqSD6Pg/w9hXsn1Hbt+eGAs8rnyMxyDQNhV+wMtj/Wc0h4MBqVj+c42nQPm77q2kKgs676HQaxJZlW7XXsTtUi7uhUnW5DP89MOR6oTBYiFwLUVj5jYUXeNNb+b0uAP6+Exig+NqNLHRAZ6E3CD70BjWENJigA2zCv2I3S96Jl8SiNkrCCzohBNmpDjR4EmhS9DdfABNfV39Ep17GKjLeupg9ng+4momAPhrG06A+QofjOogE3kbgyzuAt64Iva8VuMvFngyk57PX+ugPEaqz3omduTN4CGCNrsIfn4Tj9VeaI+jc5ZKSARQoxUPfuIwVYXphBEuP524IjkbQlRtCbk/gvl+ASx8zvo7NrvqhXVWqoPNKlHwC3Kx7D/+epAg5Dvx1fQXzrRvFRnPfPMCs9pTswFBZQrQWusPJ3osuFzNB79CPLdfOZktpnUedhBd0AEhLtqMukXzoqTnAoF+r7+0OVpGx20jgrg3MarLZgQdPAAOF/dy1qhVrlLVohZ3fqCVhw4GLk1lbvXBpEmqg8MiMYBOWer9ycga7KXAx41UROZW69/4GGeFY6NyHnslSuUXhPraLpcd7XToLXXC58BuCI535qQvPA9r3U88pwsVaFHSeGco/82xd2OFv57BSzfya4jm5yLoqrcd+cwNDLCfbeYhqofsnRdPYZ88nRc186PmnAh36A7sXsfd615Mk4rQZQT9YGcYPNZEQH5Vry1T/qlmsejAqS4APrge+uD38Y8NpyLHlM7VipBnipKgVQdenwyenM5eLWT11sUaJSLAmEt5G4IenVbcSF6zkdGaZTlrAnqxEfvlB+ySVrIibu1b9e9KVTEpCgKuUksi8nDKHVyt0Vao3Lx6ZM/Rm9tR23r3aY3pdwMq98olG0VJ2CK+tRpZwF0lON1Yy9ozfskYT/IbQWKX40JX3fH7CzEInBPi10NDDbD9JxGgTgr5673EUl9Xi5tdWx3ookUd8VBbjl8WoEL31agYPSWtOHRirDZkpZY07Xj43+H4alwsXdKsuF8KEU4xy0R/LxYYLPr9esDrVO74CvnsEWPkCe++uZVYyF8SCYezJ6v8Waiey969QX4sul2ql2JXYtarrMOD+UmDEbdpriy4XnxDSCTDr/tq3zDv48MQj0eViT1KF2KqFzl0kA65mlQbHK+3XxCeQpFQ1qqeqlN2IgvXO7HAaq21y62JrY5C0iDYh6JwVxa3sV24VBEEXrVDR5WK1mD73Hzen1oRf0EMcyy15T4gbgFh2Nq0dO69Vl0tKlpJi71aFXi/o/Fz6bkDBolz4/AQXYncdc2foP6/uZwGn32J8DtHlUn2I3RD4Dcs//sxAN4U4KcqzgM26JOnhrpkUnRuH31xSdPWDzDj378wyP+tP2vXiDSFJKABWeSDwbzOiYLi2BrkkarQpQQeApqYEqbpoFdEy1WQgioJuMRSP+4+bU5nSqsvFamq930J3MNdCWp65oFMKTYSHM4sdV3dMdcXoJ4m5hZ6Uym4e3C8dbFKUP/Xwz7mxNlAkOdzPnOTUFnISe8ZWHwIyOxt36dEn46RkAyDsRq230EPhb0zeU7veL+gmf4MeZzazzPXjFS30tDxB0PdbE3RJq9EmBP3289XEjRP1rVCBrzXh9Td4gwJAsZgEgbNa18UvZs0RdIsuF1HQq0qBJ08Bts0J3E90uQCs4p9Rn0YgMMKFW+hixqX+hsOfZrwu7ecTrFwAF/SGSuYb//l9c79v//GsANVv56hhiUCgy4X3ltWjF0Kbjf1fH96kjtEo1tyInop7q+Mg3TWUm45VQTdDtNA7D1b/xrpyIK9Xy84tiSiWBJ0QMoYQspMQUkwImWqw/XZCyGZCyEZCyI+EkP6RH6o5Uy7r6399or6Ndfk55y7gjz+oP1oASMvX7mO1rounJRa6IuihekKKgl5RzEIRF04L3E9fdjanW2BKvH9fg2JVNofqGhHHx6lVrH2PrrlxMEHnIY61ZcDbV7LXZjeZlEzgN5+r6fQc7krx1DML3UzQ9VURAXaT2L1InZS1aqFPeAG4syiwfjePWmmpoHOL3J7MSvDmn6pu6xrQC14SQ0IKOiHEDmAWgLEA+gO40UCw36eUDqKUDgXwJICZER9pEOw2gmvOYF/ehOpeZIXkNBY6liz4XNN19afDFXRQ1oj6pVHWxZ1bwKF6QoqCzpOfNJ1v3KwW+IrnmEDwUrY53Vk4pSjeteVM3AwtdGEirtNgNSKFw28Ovkat2HuDCDr3oYux2I1hdo2y2ZnrYtnjrLdnpomg8+5DvYSCTkNuYi6kHUoN8WCTjZpzOVhdID18MlZfgz9cOg5k38EbP2TzCbmFamRP38tbdm5JRLFioY8EUEwp3UspdQP4EMAEcQdKqZi2KJQObD0mDGVf3kZvGxN0jjiJFmChW/Wh8444AOb+hTU7sDqhykXRqPSviOjb57VPREHl5WQ9dWrpAwDodia7aRz+WV33TF/g2UGBIYsZHVTrNSWbJSa569jNZP9KVkJADJsUS9gGs9CNQh0nvGi+vxliBFKwyeF/7ANuErJOO/RjPvf9P7L3Vi10MzI7s2VLGy5kd2VPib2VGuc2G/DntcDk74HMji07tySiWBH0rgDEZ+FSZZ0GQsifCSF7wCz0uyIzPOuoddETpHNRuIiCnq4TdFGk5t2jlEVtBEp0bc+4eIsCaTWe3bKgCxb6mlfYUnyCEBsHi24HHgYoulH4OPUWemZn1XpNz2cWqLsWeO864M2xzNXja2RJLYA2AiaYoNccgSaK57bvgNObUeO6hxBjPuBq8/1Sc7Ux4oSoZSEAluHZErhbyyzxpyXk9zFubCGJKRGbFKWUzqKUngLgHwAMnKYAIWQyIaSIEFJUXh5GGVML+AW9rblcOKLLRbRsAcHypqxV3by7gQ9uBF6/WBXQXYtUv7IosFYzTrnLRV/aVc+3D7FlSrYgzkIFQdFaFv8OHmOt7xRvdM2szqpflwt6Yy1Qupat27uMLXntlHoLFvq+FWwSl1chBMx7Sobi6leAO1YCM6pY8k848DZmgHWXixn9lHmAM37bsvNIEgYrLegOAhC+ZShQ1pnxIQDDot6U0tkAZgPA8OHDI+qWcTrYvanN+dA5opWlr+nhdQNHt6oJMYDaaqz+OLPM3xfaY4miFq6FbqUWSpKTPaaXCa4HVxUTbdGCFxNleF9KfYcfIFDk83qrJWjb9WJx1mKUC0/04ZN3PKzPmW0s6GU7gLcUX3DnIarbx6x2SihEUQ4Xset8S10u+X3YTUVy0mDFQl8HoA8hpJAQkgzgBgBzxR0IIeKMzDgAuyM3RGs427qFHlTQXcBL57AwOz2NVYEThqLfPFQdcg4X4iaPeWYqj4c/b0pgdAc/Xmz4IFrojjTmYjCy0Pm6AdewEMGuw9SQvNyeqsuFc0z5+vFUdr+g5xjXUBfrvvQYFbi9NcmJoKBLTjpCWuiUUi8h5E4ACwHYAbxBKd1KCHkYQBGldC6AOwkhFwPwADgB4HfRHLQRvHPRfZ9uwrfbj+KV37SxcCoxVMypS0rRC3Z6ezVJx1UVKMCiC8NqsaoaYcLQ26h1AXF4tcT09gaCXhl4PVHQCWHhdfq/BVAnFnuOAq5VaoMMupb9befcBax+Ufs3Hd+r1IjRVXFMzVGfMHYtYk8FBcO0fvtOg4EJs2KXMMNvQoAaCSORWMTSN4ZSugDAAt266cLruwMOamVyUlV/48KtJoWZEpkO/ZhP1JkTaKGXrNG+14cOGtUK51jNMhWrLHpdTNDddcDRbawnJSAUo2qvrV8CqM0iRJeNfrIzOZ09PVCqDaf0T8gKMfBZnYGL/sle6+OsvQ0sUYk/1fCs0dR2QIPiquEuqBlVau/MycuAjv3Zv1jRYQALC9Q3dJZILNAmMkUBIMluw4s3nxF6x0SFEOD6d1kSiV7Qj+k8XKK16qoKPvFpJeSRUhYBwsuz8mNW/JdNvO5fxd7XBbHQuavFY2KhA8x1sukjYNZItecooDZSMIuwMYqzTstTqxAe282OzezMXC61ugn56kPsBiRmfMYKhxO4eyPwu7mh95VIdLQZQQeA/Iw22IDWCH0dkFqhemKAO6Y6+MSnFUFvrGZWL68Vwo85tJEtj25hS7+Fnq8m1PC0cbcg6MTOKhaefaf2Ojyl/NgubW0Wf1KTSZaqaKH7a4OnqzeMYzvZTcaRyiZF9aV2g6XoSyQJRJsS9BE9c5GWbEdOWgvDveId0UIndtW/PfYp4PKntPtGwkLn5XZzeyjHKGGPfHKVT1py10Z6PpCmiGmB4o5pFFwuDqUDvb4dmVg3pVKs0xIiBl6cSLz2bbZ0VWujaDI6sphvb6N2IphSFq4oBV3SBmhTgk4Iwc1ndkdlvQdlNWE0A040REFPzlAnDYdNCvS9uqqCW+hWfOhcqPm5uduE3yh4qOGJfcwqTslkCTJXPKs2hOCC7tX14BQRi0CJTx38xkFMLPR2QoGoPhcDlz0OTHyNXcffHLm/0guzXtuP9ecPWCKS3p8vkSQgbUrQAWDisAIQAlz38iq8teKXWA8nOhi1GrMns+p8epeLq1proYtlA5KczEKvPw7s/Nr8evx43oPS2wiUFqnp9fUVwE/vARveVjM+CWFNjjM6MMvaXQusfZVFlySZCLr4tCA24QjlcnFms844tymx92f/SU0QylBS03uczQSd+rS9Szf8jy2bU7BMIokz2pygn9YpC52ynNhXUY8Z87bFejjRwWYDzvozazbNBZ37jvX+9foKbeq7aMFzQX/jMuCDG4xjwAHVRZHBBb0BeO0i1XKuOQLM+ROzcvXVBwlhN6AjW4AF9wLVpeYWulj4S1NJkVvoQWqSDLxGbeQsMvbfwJl3AENuVKNexIidDCU88cr/mp9bIkkQ2pygA8DhKtXSO1BhXnyqrMaFnw5YbMgQb4z5F3DKhWqsNW9DJrpjUnNZ1UExcaa9WmqYdXNvYJOQAIv2aDJwPXCXDS/EpO8OxC11YgdG3RN4fEqmtuiW3nfOEcd+VLgZG4UtWqXvWGDsE0qnHS7oQlhrZQlLUtLXx5FIEpA2Kegi5z21NGDd15sP4+N1JbjiuR9x9YsrYzCqCMIn83ihK9H6ze8LlO9g/04dy94Pv5Vt+9XfmLCKdV0qdgMP5wLrXtNew1UJgKjJNqL1nNkZqFHiuCe+aiyMKRlan7hZsajL/sXG164XUCYKuuJyCVUYLBT+uHRhLJUHAsMnJZIEpc0LOgCs3691Jdzx3gbc99kmlNUwMaOJ7D/lgm5Ud0ScLOx9EXDnWpYE9MBR4KLpzJctZm5u+Ywti97UnsdVxc7PbxY8Eeemj1k6PsdMGPVx4mYul8yOwBUzWUx4jcGkaKjmGqHg1xXPXX9MloCVtBnapKDrXa0TX1qF3UdrUFxmkFYOwOVpwoy5W/H6jwk4iZqvuFCMarJkdVZf5xaqrx1O9iHxMD5O+U621Ldda6hkvnk+mXlc+ZzS87V9LM0EXd+kOFQXeme2tsRvS1wuIn6XyxH2efDJ5awC82MkkgSiTQr68vtGY86fR+HUjqqQXPKfH3DxzB8M969ze/HWyn145KsEnETl3dQLzw3cJka0GHVdd6RqMzcritlS3wHJVclENj0fAAEOrGbrcwu1afJmgq6PvAnVYUn/tGG1FnsoeKenqhI2Vj5B3JLqiBJJHNEmBb0gNw1DuuWgXXpgtbotBwMt2frGBK7Q2L4v63xz8UOB2/pcwpaTFqiTpiJJKdqMTB6LrS+Q5apiomx3AKCsLoszmyXudBAEXS/cnGydBRyqS5L+PP5+pi38uor1ZbK7smJfAGv2LJG0AdqkoHP+PXFwwLornv8xYF2dO0TTBoX31xzAzEU7sX7/ccxaWtzi8UWM1Fytn6nHr9iS18PuaVISNik1MGIFUJslc7jLRYSHMIrZmCkGNw1AjV/nXelDzVmIFrrNETkLXXxi6TCATcLesQrofmbLziuRxAltWtB75KVj0jk9Q+5Xb1HQ/98Xm/Hcd8WY+NIqPLVwZ8Bk6pyNB3G8LkiLs9bid3OBaRY6QiWlBNY1AbSZlACz4nkDinFK/2+9wAPmFnT/CcDptwBXvcg6+Jz5x+DjEgU9o6P1BtWhsNmAQdexG8OAq9kTRywrK0okEabNF1wuyDWJqBCorA9selDV4EF2avCaMPVuH9JT2Ed4qLIBd3+4EWf3ysMHk88K2PfLnw6CELWZdVSx2a1FhJhFm/gagTl/Ztmf04+z1H4u6Dx0UbTGb/mMdf0xI6c7qzEOAL+dE3pc4s0ioz1LRgJa3mMTYDeVsf/WPllIJG2ENm2hA0Cn7BARFQCO1Won6bYfrsaQhxZhzsZgnfaY6G8urcLMxbvQ6GX+58NVxg0j7vloI+7+cKP//abSSuw6ahx102oYRZvw1P2f3gVAmZjTJlXQeZjkKReqx/S+GDhHVzmxJYgWulhJMSkCHXzsDinmkjaLJUEnhIwhhOwkhBQTQqYabP8bIWQbIWQTIeRbQkiPyA+1eYwZ0AmzbjoDXXPMLfVjtaqbZNuhany1icVZL9/N/Mtvr9yH+ZsOBxxXWe/BxJdW4rlvd8Pr02ZYHq9zo+fU+Zj38yHDa45/YQUu/c8PuGTm92H/TRFD3xgCAHqco33Pa61zQS8Yzhogn3VH9MYlCrpY9yUSFrpE0oYJKeiEEDuAWQDGAugP4EZCiN7x+BOA4ZTSwQA+BfBkpAfaXJLsNowb3BlvTBqB353dAxkpgV6mmYt3+V9f/txyzFrKUtk/XV+Kyno3Hpy7FX9+f0PAcRsOnIBP8aNXu7R++B2HmR/6vTX7Nev1g1XUHQAAIABJREFUwr+7rBYxQxTOXqPZsvfF2n14xqZo1XYcELyuSkvhTwmAtkyA7LEpkQTFioU+EkAxpXQvpdQN4EMAE8QdKKVLKaU8Fm01gLjL1OjbKRMPTRiI2b8ZFrDN12QedTF9zlbTbdO+3OI/tqqBWflEEbo6NwuFXL33OB6ap55DvHlYgVKKd1fvR43LoLlxS+GCnpQK3PwJC39M06Xulyu+cW6htwYZHYBz7wVueF9roUfC5SKRtGGsCHpXAEK3AZQq68y4FUCQWqyx5Zze+RjWw3rtjrkmLhM9//dWkeZ9XaNqsb+5Yp//9fbDugiSEGw+WIVpX27BPz7bFNZxluCCnprLfMupuYHx6mXb2bI1BR1g/UJPG6ez0KXLRSIJRkSjXAghtwAYDuB8k+2TAUwGgO7dY9cEtymKtVu4I8JqbHso7DZ2xr3ldRE5nwaewCO6T/RJPfuWM1cHj25pbaSFLpFYxoqFfhCAmBtdoKzTQAi5GMADAMZTSg1zuymlsymlwymlw9u3j5FAAAjiYWkxjd4m/GfxLsNQSAAwunRTkAGlJLH/IrPztYgOp7GlWKwqpxsw4UXgvl9Ui7j3JeYhjtFG+tAlEstYsdDXAehDCCkEE/IbANwk7kAIOR3AKwDGUEoNMlXii/YZ0ROGg5UN+O+3u5HpNP5oKQ2cGPU2USTbjCcZ+a6VDVFIWMruxtLeR9yqXX/6zWyZlsdK4+b3Djy2tZBRLhKJZUJa6JRSL4A7ASwEsB3Ax5TSrYSQhwkh45XdngKQAeATQshGQsjcqI04Ajx97RDN+wFdslCYn477xvQ1OSJ8ahuNXS4U8Mesc7xGTSUUuHvI5YlCz0tCgN98znzVRvA6Lx1imE0pFvyyt/k8OImkRVj6hVBKFwBYoFs3XXh9ccBBcUxOmmqh2wgw/y61UuGT3+yMyDXM3PSUUrg82mJgHp+5yyVYBE7UyerMGj/3NKjk2Fp0DYxKksQPi7Yewfe7yvHY1YNiPRQJToJM0VCsnGpcae/KIV2ids0TOn94MNGO5gRuSK57B7jpE1aZMFZ0GcqWHaVgxCOT/7ce7605EOthSBRO+mdYs9IAM68bYprl2RKaKEXpCW35WL1PXbt/xIdgnc5DgM6hd4sqNjtw7+7QTTEkEsnJK+iL/3oeHHbzB5QkYZLytE6ZuPr0rnj86yAFqCyyubRK08QaYD71apcHWc7AYmAxdbnECxkdYj0CiSQhOGldLn06ZqJnfrrpdiLEZr8+aQTGD+2CU9qz/a1UcDSj2uVFVYPW5fLY/O0YPGORYRnfmLpcJBJJQnHSCroV/j1xEBbecx665qSic3YqPr+DNYqYeIZa2eC2XxWaHR5AThqzwI/oLPRvtrI4cKNIFn2MOqUUbm8UIl4kEknCIwVdx/M3no5HJgwAAFw/ojv6dlIrEmanObDloctw90V9/Ov+3+X9LJ97aDeWhfnWyn2G27lQV9a7ceEzy7DraI2/+Bfnia934NRpX8MTxO8ukUhOTk5aH7oZoaJb9NUabSYJQUZ0DlGbnYv00p1l2Ftehxe+K8Z1w7UNjN9dzao3HjjOJlZPaZ8BiUQiAaSFHlEyDUrzipzVK3iBK55wZFdaufkoDfCh8xvIRc98j4ueiWEtdYlEEndIQW8mp3dXi1jNuukMpCfbMefOUbi0f0dcc3pX/PeGoQHHdGuXhsIgE7Hc5WJXJmQPVzbgXwu2a/axh/FEIJFITi6ky6WZfPLHs/0x4uMGd8a4wSxge/Zvh/v3EVvOAazQVrA+pR5fEyil+OtH7LgNByoD9rG3sLHE3vJa9JJuGkmEoZRqIsMksUFa6M0kyW5DclJ4H1/7jBR/pIsRbl8T3l65D+4gE57h+Oz1LN52FBc+8z2+3hzYTk8iaQkyujY+kIIeRT7/0zn45p5zcWn/jvjP9UPQIcvpD3lc8rfz8f2UCzT7bz9cjRnztgU9Z0ssdN5cY+shtvx+VzmKY9kCT9JmkPkS8YF0uUSRM7qzSoGiG+bKIV1wSf+OcDrsOFGnLYkbrN0dJ5I+9N+9sRYAsO8Jk2qLEolFZEJzfCAt9BjgdNgBAOkhomL0XDLzexysbGj2daWHUxItpIUeH0hBjyHh+uB3G7hHistq0XPqfKz95bjl81DDvkmMjSWVWLO3IqxxmdHg9qHR6wu9oyThkXoeH0hBjzGnCZmozWFF8TEAwJcb1a6Am0urMOyRxTheF36Xo6tmrcD1s1e3aEycftO/wSUzfwjrmAZ3/NwA3N4mrN9/ItbDSAikhR4fSEGPMWat6sLFI9R3eXFZMSrq3Fi1R2tp8/nU1vzt8YxWK3y+oRT9pn+D4rKaKI7IOo/N34aJL62Mm/HEM1LQ4wNLgk4IGUMI2UkIKSaETDXYfh4hZAMhxEsI+XXkh9l2sbUwdvfBuWwi9YufVAudn/LDdQewaOsRo8M0lByvx+s//tKicUSCxduOAgB2HomPyJvNB6sAIKA6Zqz4uaQSk98pClo/P1bISdH4IKSgE0LsAGYBGAugP4AbCSH6JpMHAEwC8H6kB9jWiVTUilf4RfEEj+W7j2Hy/9YDALYcrDJtdTfpzbV45KttOFbbGJGxhKLR68Ntbxdh91Gt5cuNvHhJhuUfaTwkzHh8Tfjz+xuwaNvRFk2MczaVVka01j61YKE//+1uLNsZ9z3kExorFvpIAMWU0r2UUjeADwFMEHeglO6jlG4CEH+mQ5zTLTcNADDpnJ4tPhe33PRWf22jF1c8/yP+++1u/zrxB1jVwOqw60v1RoufDlRiyfajeOCLLZr1/LE9DvQTgPoZBXuKcnl8KKt2mW6PFH0e+BqlJ1ou5AC7uY9/YQWeXbIrIucDrLnxnlm8C5PeXBexa4ZDcVkN3luzPybXbk2sOHC7AigR3pcCODM6wzn5mDF+AM7pnYcJQ7vCbiM4u1ce0lOS8MaKXzCoazZmLrb+oztR70Fasj3gkby+Uds4g0LbCYlb5rF+ahaeMQK2bSypRNecVLTPTAnYNu655bhicBfcccEpER1Pk4UnhklvrsXqvcdbNZa/5HgDeuSZ1wQKxVHlBsQTzCLBdzvKkJPmwEX9OkbsnJHk8v/+CLevCTef2SPWQ4kqrZpYRAiZDGAyAHTv3r01Lx23pCbbMWEoa8L8zytUT9bZp7DKjK98vwd1FiM/TtS7MeKxwKgSj87yfmnZHn9tdhFvMy10SimOVLvQOdtaJ6dnFu1kx+luIdTv4tDu7/Y24apZKzCgSxbm33VuwPm2HqrG1kPVURD00Bb66r3Ww0UjxS2vr8HM64bgGqHRSqz5+yc/A4jfJLVg5TTaElZcLgcBiEW5C5R1YUMpnU0pHU4pHd6+ffvmnOKkgychAcC9l54adN+KWuMwRY9Bh6M/Kr51EdGyP1bbiK2HqiyN8ZOiUpz9+Hf46YC1EL91+9h+gY/pistFeff4gu34wztF2KX42iPhOw6H1proq6htRFW9duJ1U2llUL/0zyWBhdvCxYrfu63RWm7FWGFF0NcB6EMIKSSEJAO4AcDc6A5Lwhl9mtoguVMIC9gs7rzCYjy62AVpzLPLMe65Hy0dt0ZJajJKfAqG/qdFdZOQr/ywF4u3HUW1EmUSrFJlNOCCF+2QvGGPLsGQhxf53y/ZdhTjX1iBD9cxT2ekRShe5ihigb4DWFsjpKBTSr0A7gSwEMB2AB9TSrcSQh4mhIwHAELICEJIKYBrAbxCCAldlERiiX9dPcj/umNWoP9Y5M/vbzBc/9TCHZau9XOJapE3J+KF60RTE8Xe8vDE/a0Vv+DbHSwCQu+zjvbjcrXLYyiafJ7Bip5G0trdV1EHANh9lH2GRiIUiavFWtqO17lREkaeQiSIZGRPPGIpDp1SuoBSeiql9BRK6WPKuumU0rnK63WU0gJKaTqlNI9SOiCagz6ZSE6y4dPbz8bt558Sdu0XjlHzaSO4HzRc9L7wV5fvxYUWuimJIhisyiQPt9xfUR8w4asX0n9/swPDHlkc8tqcE3VuDJ6xCM99tztgG7fMrYiAr4lic2lVVJKQEkmEzMZqdMM799/f4dwnl0Z7SBraegKUzBRNAIb3bIepY09DSpi1XzhGPyarsd7hWJ7cVWJWV2bCCz/ika9U4TY7s8vThLIaNRRQFPHPf9JO34j68fG6Ery0bI9lFxMAVCrunC9/CpwW4n+6FRHwUYorX/gRF4dZ6kDEyGX27ur9KK+JTn5ANLStzu01XG+k81Yn+0VqG70tqg+USDfH5iAFPYHQC/qdo3v7Xw/smmV63M+lgZObSXZr//XcOn7ymx34flc5vt58GN/vKjfdf8vBKlMB/Lm0ylJG6l8+2ICRj33rfy+6XHYdqcHhqgZ/jRXxB3rfZ5sMz1ft8mDez4cMtyUpdzajpKtwLPSmCHiFztA9WRypbsC0L7f4yxxHChLFupur91TgkG7yusHtw8AHF0bk/AMfXIhfv7Sq2cdH4v8pnpH10BMIvU6KLphrTi/AloPBm2OIuA0iX4xo8PjwrwXb8dbKfXhx2R7/ek14mjKu1XsrcG8YbpufDlSiuKwGvTtoC5Tp9VMU240llbjy+R9xrNaNXx6/3JLYPjhnK7746SAK89MxsGu2Zhv/TI389PzUViYlvRFSCvGJyO1lr/ceqwvYL5gke31NsNtI2BmuVfUefFxUgtvOLQQhBJtKK+HyNGFkYTvL55j8v/VIttuw67Gx/nVnPLIYDR7Vqj5U2YAuOdZCXEX4kxovyQCwxC67jcBh0UA56SdFJfGDvtwuBcWveucDAH4/qic2z7g05DmGdMvB9cO7hdyPs2xnGd5auS9g/ewf9vijYvhPpDmhdFZcFGL0TdH+EzimhGeeqPdYEtLKerb/karAjE5+vP4G90lRib+wmBURCFfPG70+zFy0E/U6F4U43xHMtWA2Ikopej/wNa59eRX++eUWzQ3iteV7WXVOE52fNmcLHluwHauU8snjX1iB615ZhQ0HTuCdVfus/FkAAm+OopgDwJLtRy2fS+Swwf/faf/8Bte/Yt1ily4XSdzQIy8dz994Om46kyVlUQq89rvhWH7faBBCkOkMHdaXbCew261bbj8ZNKoGgH8t2IE+D3yNon2qv/xolFLgPSZRLgs2H8ZdH/xkuI2X4T1W2+i/ASzdWRZgbfMfuP4aUz7dFLBPMHYcCS/r8uOiUjz3XTGufF4bGlrTqMajL999LOR5Gtw+zY2Ki2nR/hP43+r9qBTi2x+dvx03v7bG9Fy8CFmj7uZ2zYsrMX3OVny49oDmBhFsfmXLQfMchuYaybWNxv55o2bqZshJUUlcceWQLpp4bKfDjm7t0gz3vfVXhQHr1u07gbJq65NsRta5yK9fXuWfhKx2Gf/g3N4mjH/BPKb9rx9tDHoNsxrp077cgqU7jf35/aZ/g8/Wl2L4o0v8j+jvrTmAl3/Yo9mPZ8cGc0H5mii+3X40QMzeXa3WBhFryHt9TagIEfbJz7WnXOtOqTX5DPW8s2o/3l65D797Yy3Oelydb9B/VkbyxW9q+m18opxSauhmmvr5Zs2E9+lBoomueN78/7u5ourytLxWfnOzoVuKr4lGZPyhkIKegHD7OlQEilhKgPOnC04xtXibS6gojLIaFzYZTMxyvjCIMBGpb2bTC6MwzG26+iXc+g72Q/9oXQlufbsInxSVYtbSYny07gD2lNdi2pdbDPc/45HFGPboEuyvCPR9c77ebFzW2MwKNWLGvK1Yqzwh8b9DHzli5JIye+LgJQ6O1bpxot44Ukh0p1TWN6+scHM11Wr4bdBrN/PiLo8PQx9ehAWbDzfr+L9+tBGn/fObZh0bDlLQExBe+2XMwM6m+9w3pq/h+ov6dYzYBB5n++Hg7gavSdleq4hVIluKOBKXx4dyCwlU3Jd+uMqFpxbuxD8+22zoz+XwJ5UDx+tBKcX9n2/C+v3aUM5VJm3+aixa6IDWdVHb6IWvieLP72mTy4yid/iNSG8QcEPhvk83YdijSwyvaY9Amqn+usEMk22Hqv1JanxOoSVDaK4PvbLeg8p6D/5pchMPxVwlysrl8UW1/IAU9ASkb6dM7HtiHHp3yDDd508XsJDGS/p3xLRx/dCrPavOl5GS5P+Rv3zLsOgPFtZLD7QGXDxqG70YNGMhfi+Uc+V+cL3AcOv9P0K52T0Wyhw0UWZVfrC2BDfONvddi4Qj6CJDHlqEW99eh426ielXvt+DDQdOaP6mMuWJavnuY1gq1Ce3FBWj7HLTq9baFL76w96AdXr9DvZ0dPlzy3HhM99j1Z4Kv4XusNmU84QvjFYmuBdsPhxQl4gfd9zkycUqp/3zGzz8lfVotHCRgt7GePP3IzS11V/97XDcdm4vNCo/hrRku9/lkpvWOrVRJr60slWuYwX+e75h9qoA63XMs8uxcOuRAIEx6hBkZmGLNFHqtyqthsuF43LRs8xgPuGdVftxzYsrTUVTvKFZ0XP+ma3cY62R+GMLtges23usVjNnYeUJ7sZXV/s/S3uQ3IGlO8qwdGcZHvhis6E1bsU6/tN7G3D1iytR41JdSrzAXSTmVKNZl13GobcxRvftgNF9OwSs571LWb109q10OuzompOK805tj5vP7I6JL630RzgMLsjGP8acFjQqIhHhE3JbDhq7iX4uqQz40RsJhxW/PqXU/3n6mihueW0NXB4fioI0nv5xd3mzSzwEw8q8iZXs4cYwJvbMLOgP1pYgJUmtIspcgOr7Rq8PdkICkt/4pGKDx4cZc7diymWBbsXfv6XeoJJsBA9NGKjZHk4c+qAZi7Dkb+ehd4fMkPWEXlu+F2MHdcauozU4v0972JQPs6K2Ef9brRXwaHbAkoJ+kvDGpBFYtrMceRkp/h+3w27DiqkX+vf5fspo/HKsDje+uhqTzumJUUqMOwDcfVEfuH1NeGnZnoBzA8Cz1w/FPSGiVeKB8prGoNmqLxr8fUZle62EFB6rcWtuiD8Whz7my43GGa1mJNttloqXebyhhcxKf1t9SGNz9/1g7QH/a18TxbyfD/kTv/pO+waDC7Ix985faY4RJ0XfWrkP91zcJ+j13161H+ed2l4zeRuuD3330Vom6CZ/ywNfbEbnbCeeXrQLj85nTyOPXT3Q30hj+tytmL9JO5EazRaL0uVyktAlJ9Ufv37PxX1ACNAjTxvu2CnbibNPycO+J8YFNE/46yWnYsqlfbF+2sWG59eXHkiyESy99wLT8aQl2023GfHBH84Ka38zNhyo1NSTiSavLt+L4jBLCuvpYNChSeTcPvlBt3OsiL4Vw/FotctybZn31xww3SaK/ewf9uIvH/yEK57/0R92aRQVpQ/7E2vf9Jw6H2+uCLxR3/p2kSbaySge4PdvrsWjIb4TZp/fe2sO4OlF2q5iJccb8HNJJR79apvhnEhLG8MHQwr6SciYgZ3xy+Pjwn60t9kI8jJUgekjTMr27pCJ925TOxN6mygK8wPbpP3hXBYbP7BLNv5+iXnDjrsv0lpf+RnJYY01Hgi3PrwRn95+TlBRt/p/GMzlsu9YHXYcqcYCk1BKkUfnb8eIx4wjYPRYnfwTn4r+T3CZ6G+8enEU9wWAh4JU7OQYuVyW7izHa8pTm95NdLTahSXbjmqaxOibkehpcHsxYdYKvPbjL2gwKFYWzXL0UtAlQZl75yjMvXOU4bbFfzsfC+46Fz9MGQ0AGhcNR5/cdMcFvfHmpBF4+TfD8JeL+pha8frHaVG49j0xLmB7OOUM4hWjfqnd89JQkBtY9+TN348AAByxmJ07fY55uN0FTy/DmGeXWxxldBEnm/WuMf3fuq8i/FrqepfLPqFOztKdZdh5VFv+eMa8bbjtnSJN+YJJb7FiaUaT5QBz9XB4dy4RaaFLYsbgghwMLgjsP8rp3yUL3fMCM1V/cxbzIYr+wk9uPxvt0pMx+rQOaJce3OImhOCbe871u4lydBE5d1/UB+seuBg3K9uTLJQzuH/saZr3/GkhXjD7C7rmBn6+A7owF9dFpwVOgBuxZHtZ6J3inMNVLW9BKGapHq124YKnl/nfv7R0j+mN7dklai4EL4dR39zMz1j70AkhYwghOwkhxYSQqQbbUwghHynb1xBCekZ6oJL4Yfl9o/G/W0cabuvVPh23nNUdj1zFogvuvLAPBhdk4y8X9sbwHrkB+/fMS8Pt55+CB/9/e+caXFV1BeBv5Z3wCAkgCQQIERQJbyIPCeUhEB5a1KIDrcogSnVQ1MGqTCsUdURHW7VOdWirBZ1WHdGpiFbaBmltdYBQUQOCBAgCCqTyRh4hWf1xdsK9N+8HxHuyvpk7OXuffe/d66ybdc5ee++1rq64q7VnSmsendKb/EU5JMRE8emC8fz3oXGAZ/Dbt4rlwYk9mTk8ncl9gjdZzR3TnXfnBk+qTQppU1mEvlBXT21pjPR4oREIy5aVjulZMf/uRa3i+HTheG4bkdHg721M+nduw2WpVYdybgh7DjXcoB/+rpi9h0+y/+gpHggJt7yusOqE36Hr+0tKle9O18+g13evQW2o0aCLSCTwW2Ai0AuYLiKh/32zgEOq2h14GniisTtqfH/onJzAiB6VJ/lePW8Uj15zLm1eYnw0K+7MZt74SytdriUizih3Y/tjk4iPDp4sjYgQWjp3S2JCdIUn+1Zx0Sy8OpPMjl5Y3JGXeP3K7JRIZsdEPnE3AIBOIQZzz6GTQf7pyX1TuXfcJdyQ5U0IB7qLfpZzKZenV7whlRG6yWv2D4IN7dtzhvPvB0ZX+f7npg8I6t+TU/vyt3tHAnDtgDQWX9cnKP49eNc2ImAItPz2Ydwy/PyOOtqGXP/QUU5cdATXDwqeUG8sdtXDxRLKbS/nMfzx1Qx5LLfSdfu1JXPh+1z7/H/q/f7qgpc1hNo8oQ8GClR1h6qeAV4DpoS0mQIsc8fLgSvlfC62NHxJZISw4aGxbFqUU+f3JiZEU/j4ZJbOvJyVd2WTk5kCQFKLGN684wr+fOsQIiKE56YPoJ2b2J3YO4U7Rl0MwNCM5HKXzIAunuFOjI8uN9Q3DunKC25n7bPT+pPRrgVPTu1b7lKa2DuFN24fRt4vxvLh/aOZM6o743p1IHfeSHY8Nol+nduQlpTAzsWTyo3gtMs9v//cMd25ul9HcnqnlMtzfVbnIJ/69MFdanwaz0pPZkHASKdnSis2LhjHK7MGs9T53APJnTeyys8a3C25wqjjolax5M4bSc+Uc/Hry27AYy/zXD9ZXZM50YDNUVUROAH/4yFdKtwwLzSnikurDf9QGYHusYaufqoKqWn7rIhMBSao6q2ufBMwRFXvDGiT79rsceXtrk2VC2+zsrI0Ly+vEUQwjLqjquUjhjNnS4NizZ8tKWXpR4XcOLQrRcdOs+bLovI5gVBKS5X3N+1jQmZK0NNydRQdO81Vz33I72/Ooo9LuFHWl7zCg4jAoK6VJ5W4741PyezYmpkBT+LvfvYNO4qOc5dzF9304lrWFx5kyyMTg977+Z4jbNl3lLYtY3j+g+28/tNhrNl6gPjoSO5+fSO9UlszK7sbaUnxZLT3DGj6g+8CsOyWwVzSoSWpifEcOHaK0U+u4cSZEpbcNKj85rlt/zEy2rdk3c6DTHehARZf14f5b30OQEa7Fuz43wnW3DeKUlV2HzoZlI1pct/UCmu2y1h1zw/IeeZf/GhgGr+6oR8AO4qO89r63ZwuLmHZx7toHRfFnNHdmXFFOove2cys7G68/HEh8TGRLPlnxRAEE3un8Nd8b2VP/85tePSa3jz8zmYuah1LVIQE7QnI6prEoK5JvLruq6CoogO7tAkK3xv4mQDRkVK+Ma3w8cnl13PLIxOIi67b0t0yRGSDqmZVeu5CGnQRmQ3MBujSpcugXbvO3xZYw2jOlJZqrW8w1VFw4DixURGVhmg+fbYkaMdnIKeKS9i67xh90xI5crKYVnHRCF5wtMiAfp08U8LJ4hJaxkYRExVB/t4jbP76KL06tmbv4ZNc3L4lURFCersWrC88SK/U1nVebquqLPuokLxdh4iNiiS9bQKx0RHcNiKj2l2bX+4/RsGB46QlxdOnUyIiwvHTZ3lq1VZSE+OY0r8TKYlxHDxxhrU7viX/6yPMys5AVUmIiWLr/mO0bxVbHlxsRI/2bNx9mOOnzpJdy/0DldFQgz4M+KWq5rjyfABVXRzQZpVr87GIRAH7gPZazYfbE7phGEbdqc6g18aHvh7oISLdRCQGmAasCGmzApjhjqcCq6sz5oZhGEbjU+PYRVXPisidwCq8CDovqeomEXkYyFPVFcCLwCsiUgAcxDP6hmEYxgWkVs4oVX0PeC+kbkHA8Sng+sbtmmEYhlEXbKeoYRiGTzCDbhiG4RPMoBuGYfgEM+iGYRg+wQy6YRiGT6hxY9F5+2KRIqC+W0XbATXn8/IXJnPzwGRuHjRE5q6qWml0vCYz6A1BRPKq2inlV0zm5oHJ3Dw4XzKby8UwDMMnmEE3DMPwCeFq0H/X1B1oAkzm5oHJ3Dw4LzKHpQ/dMAzDqEi4PqEbhmEYIYSdQa8pYXW4IiKdReQDEdksIptE5G5XnywifxeRbe5vkqsXEfmNuw6ficjAppWgfohIpIh8IiIrXbmbSzRe4BKPx7h6XyQiF5E2IrJcRLaIyBciMqwZ6Phe95vOF5FXRSTOj3oWkZdE5IBL+FNWV2fdisgM136biMyo7LuqIqwMutQuYXW4chaYp6q9gKHAHCfbg0CuqvYAcl0ZvGvQw71mAy9c+C43CncDXwSUnwCedgnHD+ElIAf/JCJ/FnhfVXsC/fBk962ORaQTMBfIUtXeeCG4p+FPPS8FJoTU1Um3IpIMLASG4OVzXlh2E6gVqho2L2AYsCqgPB+Y39T9Ok+yvg2MA7YCqa4uFdjqjpcA0wPal7cLlxeQ5n7kY4CVgOBttogK1TdePP7zwcq6AAACbklEQVRh7jjKtZOmlqGO8iYCO0P77XMddwJ2A8lObyuBHL/qGUgH8uurW2A6sCSgPqhdTa+wekLn3I+jjD2uzle4YeYAYC3QQVXLMufuAzq4Yz9ci2eA+4FSV24LHFbVsiy8gTKVy+vOH3Htw4luQBHwR+dm+oOItMDHOlbVvcBTwFfAN3h624C/9RxIXXXbIJ2Hm0H3PSLSEngTuEdVjwaeU++W7YtlSSJyFXBAVTc0dV8uIFHAQOAFVR0AnODcEBzwl44BnLtgCt7NrCPQgopuiWbBhdBtuBn0vUDngHKaq/MFIhKNZ8z/pKpvuer9IpLqzqcCB1x9uF+L4cAPRaQQeA3P7fIs0MYlGodgmcrldecTgW8vZIcbgT3AHlVd68rL8Qy8X3UMMBbYqapFqloMvIWnez/rOZC66rZBOg83g16bhNVhiYgIXm7WL1T11wGnAhNwz8DzrZfV3+xmy4cCRwKGdt97VHW+qqapajqeHler6k+AD/ASjUNFecM6Ebmq7gN2i8ilrupKYDM+1bHjK2CoiCS433iZzL7Vcwh11e0qYLyIJLnRzXhXVzuaehKhHpMOk4Avge3Az5u6P40oVzbecOwzYKN7TcLzH+YC24B/AMmuveCt+NkOfI63iqDJ5ain7KOAle44A1gHFABvALGuPs6VC9z5jKbudz1l7Q/kOT3/BUjyu46BRcAWIB94BYj1o56BV/HmCYrxRmOz6qNb4BYnfwEwsy59sJ2ihmEYPiHcXC6GYRhGFZhBNwzD8Alm0A3DMHyCGXTDMAyfYAbdMAzDJ5hBNwzD8Alm0A3DMHyCGXTDMAyf8H/cEfOLCka0FgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqLxqYspiELw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "76579885-cbde-4f0c-d214-f566da601597"
      },
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "plot_decision_regions(X_test, y_test, model)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsm8M6SXiEL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSLroQ1AiEMO",
        "colab_type": "text"
      },
      "source": [
        "# Regularyzacja\n",
        "\n",
        "# Zad.\n",
        "Do modelu dodaj \n",
        "* \n",
        "```python\n",
        "model.add(Dense( ... , activity_regularizer=l1(0.00001)))\n",
        "```\n",
        "* \n",
        "```python\n",
        "model.add(Dense( ... , activity_regularizer=l1(0.0001)))\n",
        "```\n",
        "\n",
        "* \n",
        "```python\n",
        "model.add(Dense( ... , activity_regularizer=l2(0.00001)))\n",
        "```\n",
        "* \n",
        "```python\n",
        "model.add(Dense( ... , activity_regularizer=l2(0.0001)))\n",
        "```\n",
        "\n",
        "w każdej warstwie.\n",
        "\n",
        "Zwizualizuj wyniki dla obu modeli."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcMIRxTniEMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3d8878b-1f26-4899-f7dc-f3cbe51c0d3f"
      },
      "source": [
        "from keras.callbacks import History\n",
        "from keras.regularizers import l1\n",
        "\n",
        "\n",
        "history_Adam_2 = History()\n",
        "model = Sequential()\n",
        "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],), activity_regularizer=l1(0.00001)))\n",
        "model.add(Dense(500,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
        "model.add(Dense(200,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_2])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 1000)              3000      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 200)               100200    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 603,901\n",
            "Trainable params: 603,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 53 samples, validate on 47 samples\n",
            "Epoch 1/1000\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.8883 - accuracy: 0.4340 - val_loss: 0.8701 - val_accuracy: 0.4468\n",
            "Epoch 2/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.7997 - accuracy: 0.5472 - val_loss: 0.8232 - val_accuracy: 0.4468\n",
            "Epoch 3/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.7651 - accuracy: 0.5472 - val_loss: 0.7483 - val_accuracy: 0.7447\n",
            "Epoch 4/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.7583 - accuracy: 0.6415 - val_loss: 0.7238 - val_accuracy: 0.7021\n",
            "Epoch 5/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.7145 - accuracy: 0.8302 - val_loss: 0.7114 - val_accuracy: 0.7872\n",
            "Epoch 6/1000\n",
            "53/53 [==============================] - 0s 812us/step - loss: 0.6866 - accuracy: 0.7547 - val_loss: 0.7163 - val_accuracy: 0.7234\n",
            "Epoch 7/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.6622 - accuracy: 0.6981 - val_loss: 0.6776 - val_accuracy: 0.7234\n",
            "Epoch 8/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.6210 - accuracy: 0.8302 - val_loss: 0.6333 - val_accuracy: 0.7447\n",
            "Epoch 9/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.5759 - accuracy: 0.8302 - val_loss: 0.6092 - val_accuracy: 0.7447\n",
            "Epoch 10/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.5459 - accuracy: 0.8491 - val_loss: 0.5995 - val_accuracy: 0.7660\n",
            "Epoch 11/1000\n",
            "53/53 [==============================] - 0s 641us/step - loss: 0.5113 - accuracy: 0.8491 - val_loss: 0.5814 - val_accuracy: 0.7447\n",
            "Epoch 12/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.4775 - accuracy: 0.8491 - val_loss: 0.5679 - val_accuracy: 0.7447\n",
            "Epoch 13/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.4524 - accuracy: 0.8491 - val_loss: 0.5686 - val_accuracy: 0.7447\n",
            "Epoch 14/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.4415 - accuracy: 0.8491 - val_loss: 0.5783 - val_accuracy: 0.7447\n",
            "Epoch 15/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.4295 - accuracy: 0.8491 - val_loss: 0.6000 - val_accuracy: 0.7447\n",
            "Epoch 16/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.4159 - accuracy: 0.8679 - val_loss: 0.6230 - val_accuracy: 0.7660\n",
            "Epoch 17/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.4191 - accuracy: 0.8679 - val_loss: 0.6481 - val_accuracy: 0.7660\n",
            "Epoch 18/1000\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.4034 - accuracy: 0.8679 - val_loss: 0.6422 - val_accuracy: 0.7872\n",
            "Epoch 19/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.3939 - accuracy: 0.8679 - val_loss: 0.6252 - val_accuracy: 0.7872\n",
            "Epoch 20/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.3836 - accuracy: 0.8868 - val_loss: 0.6000 - val_accuracy: 0.7872\n",
            "Epoch 21/1000\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.3759 - accuracy: 0.8868 - val_loss: 0.5802 - val_accuracy: 0.8085\n",
            "Epoch 22/1000\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.3683 - accuracy: 0.8868 - val_loss: 0.5672 - val_accuracy: 0.8298\n",
            "Epoch 23/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.3614 - accuracy: 0.8868 - val_loss: 0.5603 - val_accuracy: 0.8298\n",
            "Epoch 24/1000\n",
            "53/53 [==============================] - 0s 736us/step - loss: 0.3529 - accuracy: 0.8868 - val_loss: 0.5583 - val_accuracy: 0.8298\n",
            "Epoch 25/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.3467 - accuracy: 0.8868 - val_loss: 0.5635 - val_accuracy: 0.8085\n",
            "Epoch 26/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.3448 - accuracy: 0.9057 - val_loss: 0.5680 - val_accuracy: 0.8085\n",
            "Epoch 27/1000\n",
            "53/53 [==============================] - 0s 779us/step - loss: 0.3412 - accuracy: 0.9057 - val_loss: 0.5596 - val_accuracy: 0.8085\n",
            "Epoch 28/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.3351 - accuracy: 0.9057 - val_loss: 0.5391 - val_accuracy: 0.8085\n",
            "Epoch 29/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.3336 - accuracy: 0.9057 - val_loss: 0.5266 - val_accuracy: 0.8085\n",
            "Epoch 30/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.3359 - accuracy: 0.9057 - val_loss: 0.5249 - val_accuracy: 0.8085\n",
            "Epoch 31/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.3267 - accuracy: 0.9057 - val_loss: 0.5455 - val_accuracy: 0.8085\n",
            "Epoch 32/1000\n",
            "53/53 [==============================] - 0s 927us/step - loss: 0.3219 - accuracy: 0.9057 - val_loss: 0.5737 - val_accuracy: 0.8085\n",
            "Epoch 33/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.3292 - accuracy: 0.9057 - val_loss: 0.5949 - val_accuracy: 0.8085\n",
            "Epoch 34/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.3226 - accuracy: 0.9057 - val_loss: 0.5753 - val_accuracy: 0.8085\n",
            "Epoch 35/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.3148 - accuracy: 0.9057 - val_loss: 0.5521 - val_accuracy: 0.8298\n",
            "Epoch 36/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.3150 - accuracy: 0.9057 - val_loss: 0.5368 - val_accuracy: 0.8085\n",
            "Epoch 37/1000\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.3117 - accuracy: 0.9057 - val_loss: 0.5389 - val_accuracy: 0.8085\n",
            "Epoch 38/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.3096 - accuracy: 0.9057 - val_loss: 0.5511 - val_accuracy: 0.8298\n",
            "Epoch 39/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.3085 - accuracy: 0.9057 - val_loss: 0.5610 - val_accuracy: 0.8298\n",
            "Epoch 40/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.3013 - accuracy: 0.8868 - val_loss: 0.5540 - val_accuracy: 0.8298\n",
            "Epoch 41/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.2997 - accuracy: 0.8868 - val_loss: 0.5494 - val_accuracy: 0.8298\n",
            "Epoch 42/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.2961 - accuracy: 0.9057 - val_loss: 0.5360 - val_accuracy: 0.8298\n",
            "Epoch 43/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.2940 - accuracy: 0.9057 - val_loss: 0.5267 - val_accuracy: 0.8298\n",
            "Epoch 44/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.2917 - accuracy: 0.9057 - val_loss: 0.5238 - val_accuracy: 0.8298\n",
            "Epoch 45/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.2890 - accuracy: 0.9057 - val_loss: 0.5252 - val_accuracy: 0.8298\n",
            "Epoch 46/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.2867 - accuracy: 0.9245 - val_loss: 0.5295 - val_accuracy: 0.8298\n",
            "Epoch 47/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.2841 - accuracy: 0.9245 - val_loss: 0.5388 - val_accuracy: 0.8298\n",
            "Epoch 48/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.2875 - accuracy: 0.9057 - val_loss: 0.5461 - val_accuracy: 0.8085\n",
            "Epoch 49/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.2815 - accuracy: 0.9057 - val_loss: 0.5267 - val_accuracy: 0.8298\n",
            "Epoch 50/1000\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.2807 - accuracy: 0.9245 - val_loss: 0.5140 - val_accuracy: 0.8298\n",
            "Epoch 51/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.2751 - accuracy: 0.9245 - val_loss: 0.5189 - val_accuracy: 0.8298\n",
            "Epoch 52/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.2721 - accuracy: 0.9245 - val_loss: 0.5282 - val_accuracy: 0.8298\n",
            "Epoch 53/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.2713 - accuracy: 0.9434 - val_loss: 0.5415 - val_accuracy: 0.8298\n",
            "Epoch 54/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.2688 - accuracy: 0.9434 - val_loss: 0.5387 - val_accuracy: 0.8298\n",
            "Epoch 55/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.2659 - accuracy: 0.9434 - val_loss: 0.5375 - val_accuracy: 0.8298\n",
            "Epoch 56/1000\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.2638 - accuracy: 0.9434 - val_loss: 0.5392 - val_accuracy: 0.8511\n",
            "Epoch 57/1000\n",
            "53/53 [==============================] - 0s 805us/step - loss: 0.2619 - accuracy: 0.9434 - val_loss: 0.5366 - val_accuracy: 0.8511\n",
            "Epoch 58/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.2589 - accuracy: 0.9434 - val_loss: 0.5234 - val_accuracy: 0.8298\n",
            "Epoch 59/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.2570 - accuracy: 0.9434 - val_loss: 0.5085 - val_accuracy: 0.8298\n",
            "Epoch 60/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.2533 - accuracy: 0.9434 - val_loss: 0.5025 - val_accuracy: 0.8298\n",
            "Epoch 61/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.2494 - accuracy: 0.9434 - val_loss: 0.5006 - val_accuracy: 0.8298\n",
            "Epoch 62/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.2473 - accuracy: 0.9623 - val_loss: 0.4987 - val_accuracy: 0.8298\n",
            "Epoch 63/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.2446 - accuracy: 0.9623 - val_loss: 0.4901 - val_accuracy: 0.8298\n",
            "Epoch 64/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.2430 - accuracy: 0.9623 - val_loss: 0.4774 - val_accuracy: 0.8298\n",
            "Epoch 65/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.2408 - accuracy: 0.9623 - val_loss: 0.4772 - val_accuracy: 0.8298\n",
            "Epoch 66/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.2362 - accuracy: 0.9623 - val_loss: 0.4646 - val_accuracy: 0.8511\n",
            "Epoch 67/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.2360 - accuracy: 0.9245 - val_loss: 0.4432 - val_accuracy: 0.8511\n",
            "Epoch 68/1000\n",
            "53/53 [==============================] - 0s 738us/step - loss: 0.2340 - accuracy: 0.9245 - val_loss: 0.4391 - val_accuracy: 0.8511\n",
            "Epoch 69/1000\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.2272 - accuracy: 0.9245 - val_loss: 0.4524 - val_accuracy: 0.8511\n",
            "Epoch 70/1000\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.2234 - accuracy: 0.9623 - val_loss: 0.4669 - val_accuracy: 0.8511\n",
            "Epoch 71/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.2233 - accuracy: 0.9811 - val_loss: 0.4706 - val_accuracy: 0.8511\n",
            "Epoch 72/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.2242 - accuracy: 0.9811 - val_loss: 0.4701 - val_accuracy: 0.8511\n",
            "Epoch 73/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.2256 - accuracy: 0.9811 - val_loss: 0.4396 - val_accuracy: 0.8723\n",
            "Epoch 74/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.2127 - accuracy: 0.9811 - val_loss: 0.4255 - val_accuracy: 0.8723\n",
            "Epoch 75/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.2119 - accuracy: 0.9623 - val_loss: 0.4105 - val_accuracy: 0.8511\n",
            "Epoch 76/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.2077 - accuracy: 0.9623 - val_loss: 0.4062 - val_accuracy: 0.8511\n",
            "Epoch 77/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.2045 - accuracy: 0.9623 - val_loss: 0.4070 - val_accuracy: 0.8723\n",
            "Epoch 78/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.2031 - accuracy: 0.9811 - val_loss: 0.4151 - val_accuracy: 0.8936\n",
            "Epoch 79/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.2015 - accuracy: 0.9811 - val_loss: 0.4121 - val_accuracy: 0.8723\n",
            "Epoch 80/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.1968 - accuracy: 0.9811 - val_loss: 0.4141 - val_accuracy: 0.8723\n",
            "Epoch 81/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.1953 - accuracy: 0.9811 - val_loss: 0.4022 - val_accuracy: 0.8723\n",
            "Epoch 82/1000\n",
            "53/53 [==============================] - 0s 786us/step - loss: 0.1903 - accuracy: 0.9811 - val_loss: 0.3947 - val_accuracy: 0.8723\n",
            "Epoch 83/1000\n",
            "53/53 [==============================] - 0s 889us/step - loss: 0.1894 - accuracy: 0.9811 - val_loss: 0.3842 - val_accuracy: 0.8723\n",
            "Epoch 84/1000\n",
            "53/53 [==============================] - 0s 613us/step - loss: 0.1850 - accuracy: 0.9811 - val_loss: 0.3807 - val_accuracy: 0.8723\n",
            "Epoch 85/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.1825 - accuracy: 0.9811 - val_loss: 0.3754 - val_accuracy: 0.8723\n",
            "Epoch 86/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.1806 - accuracy: 0.9811 - val_loss: 0.3633 - val_accuracy: 0.8723\n",
            "Epoch 87/1000\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.1773 - accuracy: 0.9811 - val_loss: 0.3560 - val_accuracy: 0.8936\n",
            "Epoch 88/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.1761 - accuracy: 0.9811 - val_loss: 0.3494 - val_accuracy: 0.8936\n",
            "Epoch 89/1000\n",
            "53/53 [==============================] - 0s 732us/step - loss: 0.1717 - accuracy: 0.9811 - val_loss: 0.3506 - val_accuracy: 0.8936\n",
            "Epoch 90/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.1713 - accuracy: 0.9811 - val_loss: 0.3538 - val_accuracy: 0.8936\n",
            "Epoch 91/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.1680 - accuracy: 0.9811 - val_loss: 0.3451 - val_accuracy: 0.8936\n",
            "Epoch 92/1000\n",
            "53/53 [==============================] - 0s 811us/step - loss: 0.1646 - accuracy: 0.9811 - val_loss: 0.3314 - val_accuracy: 0.8723\n",
            "Epoch 93/1000\n",
            "53/53 [==============================] - 0s 808us/step - loss: 0.1617 - accuracy: 0.9811 - val_loss: 0.3160 - val_accuracy: 0.8723\n",
            "Epoch 94/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.1604 - accuracy: 0.9811 - val_loss: 0.3012 - val_accuracy: 0.8936\n",
            "Epoch 95/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.1594 - accuracy: 0.9811 - val_loss: 0.2947 - val_accuracy: 0.8936\n",
            "Epoch 96/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.1571 - accuracy: 0.9811 - val_loss: 0.2902 - val_accuracy: 0.9149\n",
            "Epoch 97/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.1556 - accuracy: 0.9811 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
            "Epoch 98/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.1529 - accuracy: 0.9811 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
            "Epoch 99/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.1496 - accuracy: 0.9811 - val_loss: 0.2911 - val_accuracy: 0.9149\n",
            "Epoch 100/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.1490 - accuracy: 0.9811 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
            "Epoch 101/1000\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.1460 - accuracy: 0.9623 - val_loss: 0.2812 - val_accuracy: 0.9149\n",
            "Epoch 102/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.1440 - accuracy: 0.9811 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
            "Epoch 103/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.1417 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9149\n",
            "Epoch 104/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.1414 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.8936\n",
            "Epoch 105/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.1399 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
            "Epoch 106/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.1371 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9149\n",
            "Epoch 107/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.1352 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9149\n",
            "Epoch 108/1000\n",
            "53/53 [==============================] - 0s 762us/step - loss: 0.1353 - accuracy: 0.9811 - val_loss: 0.2769 - val_accuracy: 0.9149\n",
            "Epoch 109/1000\n",
            "53/53 [==============================] - 0s 806us/step - loss: 0.1333 - accuracy: 0.9811 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
            "Epoch 110/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.1316 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9149\n",
            "Epoch 111/1000\n",
            "53/53 [==============================] - 0s 744us/step - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
            "Epoch 112/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.8936\n",
            "Epoch 113/1000\n",
            "53/53 [==============================] - 0s 588us/step - loss: 0.1272 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
            "Epoch 114/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.1257 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9149\n",
            "Epoch 115/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
            "Epoch 116/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.1234 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9149\n",
            "Epoch 117/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9149\n",
            "Epoch 118/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.1210 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9149\n",
            "Epoch 119/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.8936\n",
            "Epoch 120/1000\n",
            "53/53 [==============================] - 0s 624us/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.8936\n",
            "Epoch 121/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
            "Epoch 122/1000\n",
            "53/53 [==============================] - 0s 630us/step - loss: 0.1172 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9149\n",
            "Epoch 123/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9149\n",
            "Epoch 124/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
            "Epoch 125/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9149\n",
            "Epoch 126/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
            "Epoch 127/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.8936\n",
            "Epoch 128/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
            "Epoch 129/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9362\n",
            "Epoch 130/1000\n",
            "53/53 [==============================] - 0s 640us/step - loss: 0.1097 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
            "Epoch 131/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9362\n",
            "Epoch 132/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9362\n",
            "Epoch 133/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9149\n",
            "Epoch 134/1000\n",
            "53/53 [==============================] - 0s 809us/step - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
            "Epoch 135/1000\n",
            "53/53 [==============================] - 0s 832us/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
            "Epoch 136/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.1057 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9149\n",
            "Epoch 137/1000\n",
            "53/53 [==============================] - 0s 608us/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.8936\n",
            "Epoch 138/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.8936\n",
            "Epoch 139/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.8936\n",
            "Epoch 140/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.8936\n",
            "Epoch 141/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
            "Epoch 142/1000\n",
            "53/53 [==============================] - 0s 607us/step - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
            "Epoch 143/1000\n",
            "53/53 [==============================] - 0s 595us/step - loss: 0.0997 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9149\n",
            "Epoch 144/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9149\n",
            "Epoch 145/1000\n",
            "53/53 [==============================] - 0s 815us/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9362\n",
            "Epoch 146/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9362\n",
            "Epoch 147/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
            "Epoch 148/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.8936\n",
            "Epoch 149/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
            "Epoch 150/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9149\n",
            "Epoch 151/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
            "Epoch 152/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.8936\n",
            "Epoch 153/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.8936\n",
            "Epoch 154/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.8936\n",
            "Epoch 155/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.8936\n",
            "Epoch 156/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.8936\n",
            "Epoch 157/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.8936\n",
            "Epoch 158/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9149\n",
            "Epoch 159/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
            "Epoch 160/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.8936\n",
            "Epoch 161/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.8936\n",
            "Epoch 162/1000\n",
            "53/53 [==============================] - 0s 893us/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9149\n",
            "Epoch 163/1000\n",
            "53/53 [==============================] - 0s 791us/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
            "Epoch 164/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.8936\n",
            "Epoch 165/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.8936\n",
            "Epoch 166/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
            "Epoch 167/1000\n",
            "53/53 [==============================] - 0s 613us/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9149\n",
            "Epoch 168/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.8936\n",
            "Epoch 169/1000\n",
            "53/53 [==============================] - 0s 594us/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9149\n",
            "Epoch 170/1000\n",
            "53/53 [==============================] - 0s 836us/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
            "Epoch 171/1000\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
            "Epoch 172/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.8936\n",
            "Epoch 173/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9149\n",
            "Epoch 174/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
            "Epoch 175/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.8936\n",
            "Epoch 176/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.8936\n",
            "Epoch 177/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9149\n",
            "Epoch 178/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
            "Epoch 179/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.8936\n",
            "Epoch 180/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.8936\n",
            "Epoch 181/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.8936\n",
            "Epoch 182/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
            "Epoch 183/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.8936\n",
            "Epoch 184/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.8936\n",
            "Epoch 185/1000\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.8936\n",
            "Epoch 186/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9149\n",
            "Epoch 187/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
            "Epoch 188/1000\n",
            "53/53 [==============================] - 0s 833us/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.8936\n",
            "Epoch 189/1000\n",
            "53/53 [==============================] - 0s 761us/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.8936\n",
            "Epoch 190/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.8936\n",
            "Epoch 191/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.8936\n",
            "Epoch 192/1000\n",
            "53/53 [==============================] - 0s 662us/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9149\n",
            "Epoch 193/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9149\n",
            "Epoch 194/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
            "Epoch 195/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.8936\n",
            "Epoch 196/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.8936\n",
            "Epoch 197/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9149\n",
            "Epoch 198/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9149\n",
            "Epoch 199/1000\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
            "Epoch 200/1000\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9149\n",
            "Epoch 201/1000\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9149\n",
            "Epoch 202/1000\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9149\n",
            "Epoch 203/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9149\n",
            "Epoch 204/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
            "Epoch 205/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9149\n",
            "Epoch 206/1000\n",
            "53/53 [==============================] - 0s 601us/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
            "Epoch 207/1000\n",
            "53/53 [==============================] - 0s 610us/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
            "Epoch 208/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.8936\n",
            "Epoch 209/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.8936\n",
            "Epoch 210/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.8936\n",
            "Epoch 211/1000\n",
            "53/53 [==============================] - 0s 599us/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.8936\n",
            "Epoch 212/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.8936\n",
            "Epoch 213/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9149\n",
            "Epoch 214/1000\n",
            "53/53 [==============================] - 0s 888us/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
            "Epoch 215/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
            "Epoch 216/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
            "Epoch 217/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
            "Epoch 218/1000\n",
            "53/53 [==============================] - 0s 644us/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9149\n",
            "Epoch 219/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9149\n",
            "Epoch 220/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9149\n",
            "Epoch 221/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
            "Epoch 222/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
            "Epoch 223/1000\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9149\n",
            "Epoch 224/1000\n",
            "53/53 [==============================] - 0s 602us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.8936\n",
            "Epoch 225/1000\n",
            "53/53 [==============================] - 0s 627us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.8936\n",
            "Epoch 226/1000\n",
            "53/53 [==============================] - 0s 786us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
            "Epoch 227/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
            "Epoch 228/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9149\n",
            "Epoch 229/1000\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
            "Epoch 230/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
            "Epoch 231/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9149\n",
            "Epoch 232/1000\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.8936\n",
            "Epoch 233/1000\n",
            "53/53 [==============================] - 0s 621us/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.8936\n",
            "Epoch 234/1000\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
            "Epoch 235/1000\n",
            "53/53 [==============================] - 0s 621us/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9149\n",
            "Epoch 236/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9149\n",
            "Epoch 237/1000\n",
            "53/53 [==============================] - 0s 630us/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9149\n",
            "Epoch 238/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9149\n",
            "Epoch 239/1000\n",
            "53/53 [==============================] - 0s 825us/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9149\n",
            "Epoch 240/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.8936\n",
            "Epoch 241/1000\n",
            "53/53 [==============================] - 0s 869us/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.8936\n",
            "Epoch 242/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.8936\n",
            "Epoch 243/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.8936\n",
            "Epoch 244/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.8936\n",
            "Epoch 245/1000\n",
            "53/53 [==============================] - 0s 809us/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9149\n",
            "Epoch 246/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
            "Epoch 247/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9149\n",
            "Epoch 248/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9149\n",
            "Epoch 249/1000\n",
            "53/53 [==============================] - 0s 621us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
            "Epoch 250/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
            "Epoch 251/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
            "Epoch 252/1000\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
            "Epoch 253/1000\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
            "Epoch 254/1000\n",
            "53/53 [==============================] - 0s 608us/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.8936\n",
            "Epoch 255/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.8936\n",
            "Epoch 256/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9149\n",
            "Epoch 257/1000\n",
            "53/53 [==============================] - 0s 603us/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9149\n",
            "Epoch 258/1000\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9149\n",
            "Epoch 259/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.8936\n",
            "Epoch 260/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.8936\n",
            "Epoch 261/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.8936\n",
            "Epoch 262/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.8936\n",
            "Epoch 263/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8936\n",
            "Epoch 264/1000\n",
            "53/53 [==============================] - 0s 789us/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9149\n",
            "Epoch 265/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9149\n",
            "Epoch 266/1000\n",
            "53/53 [==============================] - 0s 786us/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9149\n",
            "Epoch 267/1000\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.8936\n",
            "Epoch 268/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.8936\n",
            "Epoch 269/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.8936\n",
            "Epoch 270/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.8936\n",
            "Epoch 271/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.8936\n",
            "Epoch 272/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.8936\n",
            "Epoch 273/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.8936\n",
            "Epoch 274/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8936\n",
            "Epoch 275/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.8936\n",
            "Epoch 276/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.8936\n",
            "Epoch 277/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.8936\n",
            "Epoch 278/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.8936\n",
            "Epoch 279/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.8936\n",
            "Epoch 280/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9149\n",
            "Epoch 281/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9149\n",
            "Epoch 282/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9149\n",
            "Epoch 283/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.8936\n",
            "Epoch 284/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.8936\n",
            "Epoch 285/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.8936\n",
            "Epoch 286/1000\n",
            "53/53 [==============================] - 0s 744us/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.8936\n",
            "Epoch 287/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.8936\n",
            "Epoch 288/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8936\n",
            "Epoch 289/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.8936\n",
            "Epoch 290/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9149\n",
            "Epoch 291/1000\n",
            "53/53 [==============================] - 0s 735us/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9149\n",
            "Epoch 292/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.8936\n",
            "Epoch 293/1000\n",
            "53/53 [==============================] - 0s 908us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.8936\n",
            "Epoch 294/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.8936\n",
            "Epoch 295/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.8936\n",
            "Epoch 296/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.8936\n",
            "Epoch 297/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.8936\n",
            "Epoch 298/1000\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.8936\n",
            "Epoch 299/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.8936\n",
            "Epoch 300/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.8936\n",
            "Epoch 301/1000\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.8936\n",
            "Epoch 302/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.8936\n",
            "Epoch 303/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.8936\n",
            "Epoch 304/1000\n",
            "53/53 [==============================] - 0s 735us/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.8936\n",
            "Epoch 305/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.8936\n",
            "Epoch 306/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.8936\n",
            "Epoch 307/1000\n",
            "53/53 [==============================] - 0s 821us/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.8936\n",
            "Epoch 308/1000\n",
            "53/53 [==============================] - 0s 860us/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.8936\n",
            "Epoch 309/1000\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.8936\n",
            "Epoch 310/1000\n",
            "53/53 [==============================] - 0s 791us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.8936\n",
            "Epoch 311/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.8936\n",
            "Epoch 312/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.8936\n",
            "Epoch 313/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.8936\n",
            "Epoch 314/1000\n",
            "53/53 [==============================] - 0s 615us/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.8936\n",
            "Epoch 315/1000\n",
            "53/53 [==============================] - 0s 857us/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.8936\n",
            "Epoch 316/1000\n",
            "53/53 [==============================] - 0s 919us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.8936\n",
            "Epoch 317/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.8936\n",
            "Epoch 318/1000\n",
            "53/53 [==============================] - 0s 838us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.8936\n",
            "Epoch 319/1000\n",
            "53/53 [==============================] - 0s 762us/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.8936\n",
            "Epoch 320/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.8936\n",
            "Epoch 321/1000\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.8936\n",
            "Epoch 322/1000\n",
            "53/53 [==============================] - 0s 792us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.8936\n",
            "Epoch 323/1000\n",
            "53/53 [==============================] - 0s 862us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.8936\n",
            "Epoch 324/1000\n",
            "53/53 [==============================] - 0s 772us/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.8936\n",
            "Epoch 325/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.8936\n",
            "Epoch 326/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.8936\n",
            "Epoch 327/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.8936\n",
            "Epoch 328/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
            "Epoch 329/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
            "Epoch 330/1000\n",
            "53/53 [==============================] - 0s 753us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8936\n",
            "Epoch 331/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.8936\n",
            "Epoch 332/1000\n",
            "53/53 [==============================] - 0s 614us/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.8936\n",
            "Epoch 333/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8936\n",
            "Epoch 334/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
            "Epoch 335/1000\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.8936\n",
            "Epoch 336/1000\n",
            "53/53 [==============================] - 0s 772us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8936\n",
            "Epoch 337/1000\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8936\n",
            "Epoch 338/1000\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.8936\n",
            "Epoch 339/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
            "Epoch 340/1000\n",
            "53/53 [==============================] - 0s 801us/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.8936\n",
            "Epoch 341/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.8936\n",
            "Epoch 342/1000\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
            "Epoch 343/1000\n",
            "53/53 [==============================] - 0s 597us/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
            "Epoch 344/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.8936\n",
            "Epoch 345/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.8936\n",
            "Epoch 346/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8936\n",
            "Epoch 347/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
            "Epoch 348/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.8936\n",
            "Epoch 349/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.8936\n",
            "Epoch 350/1000\n",
            "53/53 [==============================] - 0s 868us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.8936\n",
            "Epoch 351/1000\n",
            "53/53 [==============================] - 0s 892us/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.8936\n",
            "Epoch 352/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.8936\n",
            "Epoch 353/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8936\n",
            "Epoch 354/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.8936\n",
            "Epoch 355/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
            "Epoch 356/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
            "Epoch 357/1000\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8936\n",
            "Epoch 358/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.8936\n",
            "Epoch 359/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8936\n",
            "Epoch 360/1000\n",
            "53/53 [==============================] - 0s 732us/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
            "Epoch 361/1000\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
            "Epoch 362/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8936\n",
            "Epoch 363/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.8936\n",
            "Epoch 364/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8936\n",
            "Epoch 365/1000\n",
            "53/53 [==============================] - 0s 736us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8936\n",
            "Epoch 366/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
            "Epoch 367/1000\n",
            "53/53 [==============================] - 0s 843us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
            "Epoch 368/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8936\n",
            "Epoch 369/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
            "Epoch 370/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
            "Epoch 371/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
            "Epoch 372/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
            "Epoch 373/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8936\n",
            "Epoch 374/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.8936\n",
            "Epoch 375/1000\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
            "Epoch 376/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
            "Epoch 377/1000\n",
            "53/53 [==============================] - 0s 779us/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8936\n",
            "Epoch 378/1000\n",
            "53/53 [==============================] - 0s 641us/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.8936\n",
            "Epoch 379/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.8936\n",
            "Epoch 380/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.8936\n",
            "Epoch 381/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
            "Epoch 382/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.8936\n",
            "Epoch 383/1000\n",
            "53/53 [==============================] - 0s 755us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.8936\n",
            "Epoch 384/1000\n",
            "53/53 [==============================] - 0s 873us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.8936\n",
            "Epoch 385/1000\n",
            "53/53 [==============================] - 0s 781us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.8936\n",
            "Epoch 386/1000\n",
            "53/53 [==============================] - 0s 837us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
            "Epoch 387/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
            "Epoch 388/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
            "Epoch 389/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
            "Epoch 390/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.8936\n",
            "Epoch 391/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8936\n",
            "Epoch 392/1000\n",
            "53/53 [==============================] - 0s 976us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
            "Epoch 393/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8936\n",
            "Epoch 394/1000\n",
            "53/53 [==============================] - 0s 887us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.8936\n",
            "Epoch 395/1000\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.8936\n",
            "Epoch 396/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.8936\n",
            "Epoch 397/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.8936\n",
            "Epoch 398/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
            "Epoch 399/1000\n",
            "53/53 [==============================] - 0s 730us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8936\n",
            "Epoch 400/1000\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
            "Epoch 401/1000\n",
            "53/53 [==============================] - 0s 732us/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
            "Epoch 402/1000\n",
            "53/53 [==============================] - 0s 727us/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
            "Epoch 403/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
            "Epoch 404/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.8936\n",
            "Epoch 405/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
            "Epoch 406/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
            "Epoch 407/1000\n",
            "53/53 [==============================] - 0s 617us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.8936\n",
            "Epoch 408/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
            "Epoch 409/1000\n",
            "53/53 [==============================] - 0s 598us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8936\n",
            "Epoch 410/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
            "Epoch 411/1000\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
            "Epoch 412/1000\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
            "Epoch 413/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8936\n",
            "Epoch 414/1000\n",
            "53/53 [==============================] - 0s 597us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
            "Epoch 415/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
            "Epoch 416/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
            "Epoch 417/1000\n",
            "53/53 [==============================] - 0s 847us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
            "Epoch 418/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.8936\n",
            "Epoch 419/1000\n",
            "53/53 [==============================] - 0s 739us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.8936\n",
            "Epoch 420/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
            "Epoch 421/1000\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
            "Epoch 422/1000\n",
            "53/53 [==============================] - 0s 769us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.8936\n",
            "Epoch 423/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8936\n",
            "Epoch 424/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.8936\n",
            "Epoch 425/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.8936\n",
            "Epoch 426/1000\n",
            "53/53 [==============================] - 0s 791us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.8936\n",
            "Epoch 427/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8936\n",
            "Epoch 428/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.8936\n",
            "Epoch 429/1000\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.8936\n",
            "Epoch 430/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.8936\n",
            "Epoch 431/1000\n",
            "53/53 [==============================] - 0s 777us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.8936\n",
            "Epoch 432/1000\n",
            "53/53 [==============================] - 0s 820us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8936\n",
            "Epoch 433/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.8936\n",
            "Epoch 434/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.8936\n",
            "Epoch 435/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.8936\n",
            "Epoch 436/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.8936\n",
            "Epoch 437/1000\n",
            "53/53 [==============================] - 0s 650us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.8936\n",
            "Epoch 438/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.8936\n",
            "Epoch 439/1000\n",
            "53/53 [==============================] - 0s 897us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.8936\n",
            "Epoch 440/1000\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.8936\n",
            "Epoch 441/1000\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.8936\n",
            "Epoch 442/1000\n",
            "53/53 [==============================] - 0s 786us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.8936\n",
            "Epoch 443/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.8936\n",
            "Epoch 444/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.8936\n",
            "Epoch 445/1000\n",
            "53/53 [==============================] - 0s 585us/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.8936\n",
            "Epoch 446/1000\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9149\n",
            "Epoch 447/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9149\n",
            "Epoch 448/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.8936\n",
            "Epoch 449/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.8936\n",
            "Epoch 450/1000\n",
            "53/53 [==============================] - 0s 736us/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.8936\n",
            "Epoch 451/1000\n",
            "53/53 [==============================] - 0s 734us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.8936\n",
            "Epoch 452/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.8936\n",
            "Epoch 453/1000\n",
            "53/53 [==============================] - 0s 864us/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8936\n",
            "Epoch 454/1000\n",
            "53/53 [==============================] - 0s 752us/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9149\n",
            "Epoch 455/1000\n",
            "53/53 [==============================] - 0s 832us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9149\n",
            "Epoch 456/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9149\n",
            "Epoch 457/1000\n",
            "53/53 [==============================] - 0s 757us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9149\n",
            "Epoch 458/1000\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9149\n",
            "Epoch 459/1000\n",
            "53/53 [==============================] - 0s 784us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9149\n",
            "Epoch 460/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9149\n",
            "Epoch 461/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
            "Epoch 462/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.8936\n",
            "Epoch 463/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.8936\n",
            "Epoch 464/1000\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.8936\n",
            "Epoch 465/1000\n",
            "53/53 [==============================] - 0s 707us/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.8936\n",
            "Epoch 466/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9149\n",
            "Epoch 467/1000\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9149\n",
            "Epoch 468/1000\n",
            "53/53 [==============================] - 0s 810us/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9149\n",
            "Epoch 469/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9149\n",
            "Epoch 470/1000\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9149\n",
            "Epoch 471/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
            "Epoch 472/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9149\n",
            "Epoch 473/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9149\n",
            "Epoch 474/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9149\n",
            "Epoch 475/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.8936\n",
            "Epoch 476/1000\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.8936\n",
            "Epoch 477/1000\n",
            "53/53 [==============================] - 0s 846us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.8936\n",
            "Epoch 478/1000\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9149\n",
            "Epoch 479/1000\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9149\n",
            "Epoch 480/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
            "Epoch 481/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9149\n",
            "Epoch 482/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
            "Epoch 483/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9149\n",
            "Epoch 484/1000\n",
            "53/53 [==============================] - 0s 910us/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9149\n",
            "Epoch 485/1000\n",
            "53/53 [==============================] - 0s 752us/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9149\n",
            "Epoch 486/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
            "Epoch 487/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
            "Epoch 488/1000\n",
            "53/53 [==============================] - 0s 600us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
            "Epoch 489/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
            "Epoch 490/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9149\n",
            "Epoch 491/1000\n",
            "53/53 [==============================] - 0s 851us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
            "Epoch 492/1000\n",
            "53/53 [==============================] - 0s 866us/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9149\n",
            "Epoch 493/1000\n",
            "53/53 [==============================] - 0s 616us/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9149\n",
            "Epoch 494/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
            "Epoch 495/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9149\n",
            "Epoch 496/1000\n",
            "53/53 [==============================] - 0s 733us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9149\n",
            "Epoch 497/1000\n",
            "53/53 [==============================] - 0s 732us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9149\n",
            "Epoch 498/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9149\n",
            "Epoch 499/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
            "Epoch 500/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
            "Epoch 501/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9149\n",
            "Epoch 502/1000\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
            "Epoch 503/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
            "Epoch 504/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9149\n",
            "Epoch 505/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
            "Epoch 506/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9149\n",
            "Epoch 507/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9149\n",
            "Epoch 508/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
            "Epoch 509/1000\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9149\n",
            "Epoch 510/1000\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9149\n",
            "Epoch 511/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
            "Epoch 512/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
            "Epoch 513/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9149\n",
            "Epoch 514/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9149\n",
            "Epoch 515/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
            "Epoch 516/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
            "Epoch 517/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9149\n",
            "Epoch 518/1000\n",
            "53/53 [==============================] - 0s 790us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9149\n",
            "Epoch 519/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9149\n",
            "Epoch 520/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9149\n",
            "Epoch 521/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9149\n",
            "Epoch 522/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9149\n",
            "Epoch 523/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
            "Epoch 524/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9149\n",
            "Epoch 525/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9149\n",
            "Epoch 526/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9149\n",
            "Epoch 527/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9149\n",
            "Epoch 528/1000\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
            "Epoch 529/1000\n",
            "53/53 [==============================] - 0s 763us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
            "Epoch 530/1000\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
            "Epoch 531/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
            "Epoch 532/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
            "Epoch 533/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9149\n",
            "Epoch 534/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
            "Epoch 535/1000\n",
            "53/53 [==============================] - 0s 751us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9149\n",
            "Epoch 536/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9149\n",
            "Epoch 537/1000\n",
            "53/53 [==============================] - 0s 750us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
            "Epoch 538/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9149\n",
            "Epoch 539/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9149\n",
            "Epoch 540/1000\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9149\n",
            "Epoch 541/1000\n",
            "53/53 [==============================] - 0s 578us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
            "Epoch 542/1000\n",
            "53/53 [==============================] - 0s 793us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
            "Epoch 543/1000\n",
            "53/53 [==============================] - 0s 824us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
            "Epoch 544/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9149\n",
            "Epoch 545/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9149\n",
            "Epoch 546/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
            "Epoch 547/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9149\n",
            "Epoch 548/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9149\n",
            "Epoch 549/1000\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
            "Epoch 550/1000\n",
            "53/53 [==============================] - 0s 633us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
            "Epoch 551/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
            "Epoch 552/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
            "Epoch 553/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9149\n",
            "Epoch 554/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
            "Epoch 555/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
            "Epoch 556/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
            "Epoch 557/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9149\n",
            "Epoch 558/1000\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
            "Epoch 559/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
            "Epoch 560/1000\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9149\n",
            "Epoch 561/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9149\n",
            "Epoch 562/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9149\n",
            "Epoch 563/1000\n",
            "53/53 [==============================] - 0s 748us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
            "Epoch 564/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9149\n",
            "Epoch 565/1000\n",
            "53/53 [==============================] - 0s 848us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9149\n",
            "Epoch 566/1000\n",
            "53/53 [==============================] - 0s 778us/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9149\n",
            "Epoch 567/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9149\n",
            "Epoch 568/1000\n",
            "53/53 [==============================] - 0s 564us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9149\n",
            "Epoch 569/1000\n",
            "53/53 [==============================] - 0s 785us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
            "Epoch 570/1000\n",
            "53/53 [==============================] - 0s 594us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9149\n",
            "Epoch 571/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9149\n",
            "Epoch 572/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9149\n",
            "Epoch 573/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9149\n",
            "Epoch 574/1000\n",
            "53/53 [==============================] - 0s 725us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9149\n",
            "Epoch 575/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
            "Epoch 576/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9149\n",
            "Epoch 577/1000\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9149\n",
            "Epoch 578/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9149\n",
            "Epoch 579/1000\n",
            "53/53 [==============================] - 0s 610us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9149\n",
            "Epoch 580/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
            "Epoch 581/1000\n",
            "53/53 [==============================] - 0s 816us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9149\n",
            "Epoch 582/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
            "Epoch 583/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9149\n",
            "Epoch 584/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9149\n",
            "Epoch 585/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9149\n",
            "Epoch 586/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9149\n",
            "Epoch 587/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9149\n",
            "Epoch 588/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
            "Epoch 589/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9149\n",
            "Epoch 590/1000\n",
            "53/53 [==============================] - 0s 625us/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9149\n",
            "Epoch 591/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9149\n",
            "Epoch 592/1000\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
            "Epoch 593/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9149\n",
            "Epoch 594/1000\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9149\n",
            "Epoch 595/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9149\n",
            "Epoch 596/1000\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9149\n",
            "Epoch 597/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9149\n",
            "Epoch 598/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9149\n",
            "Epoch 599/1000\n",
            "53/53 [==============================] - 0s 797us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9149\n",
            "Epoch 600/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9149\n",
            "Epoch 601/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9149\n",
            "Epoch 602/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9149\n",
            "Epoch 603/1000\n",
            "53/53 [==============================] - 0s 617us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9149\n",
            "Epoch 604/1000\n",
            "53/53 [==============================] - 0s 650us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9149\n",
            "Epoch 605/1000\n",
            "53/53 [==============================] - 0s 599us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
            "Epoch 606/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9149\n",
            "Epoch 607/1000\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
            "Epoch 608/1000\n",
            "53/53 [==============================] - 0s 604us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
            "Epoch 609/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
            "Epoch 610/1000\n",
            "53/53 [==============================] - 0s 573us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
            "Epoch 611/1000\n",
            "53/53 [==============================] - 0s 591us/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
            "Epoch 612/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9149\n",
            "Epoch 613/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
            "Epoch 614/1000\n",
            "53/53 [==============================] - 0s 627us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
            "Epoch 615/1000\n",
            "53/53 [==============================] - 0s 603us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9149\n",
            "Epoch 616/1000\n",
            "53/53 [==============================] - 0s 626us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9149\n",
            "Epoch 617/1000\n",
            "53/53 [==============================] - 0s 618us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
            "Epoch 618/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9149\n",
            "Epoch 619/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
            "Epoch 620/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9149\n",
            "Epoch 621/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9149\n",
            "Epoch 622/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
            "Epoch 623/1000\n",
            "53/53 [==============================] - 0s 834us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
            "Epoch 624/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
            "Epoch 625/1000\n",
            "53/53 [==============================] - 0s 598us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
            "Epoch 626/1000\n",
            "53/53 [==============================] - 0s 650us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9149\n",
            "Epoch 627/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9149\n",
            "Epoch 628/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
            "Epoch 629/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9149\n",
            "Epoch 630/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
            "Epoch 631/1000\n",
            "53/53 [==============================] - 0s 635us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9149\n",
            "Epoch 632/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9149\n",
            "Epoch 633/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9149\n",
            "Epoch 634/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9149\n",
            "Epoch 635/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9149\n",
            "Epoch 636/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9149\n",
            "Epoch 637/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
            "Epoch 638/1000\n",
            "53/53 [==============================] - 0s 906us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9149\n",
            "Epoch 639/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
            "Epoch 640/1000\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
            "Epoch 641/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
            "Epoch 642/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
            "Epoch 643/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9149\n",
            "Epoch 644/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9149\n",
            "Epoch 645/1000\n",
            "53/53 [==============================] - 0s 731us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
            "Epoch 646/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
            "Epoch 647/1000\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
            "Epoch 648/1000\n",
            "53/53 [==============================] - 0s 633us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9149\n",
            "Epoch 649/1000\n",
            "53/53 [==============================] - 0s 819us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9149\n",
            "Epoch 650/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9149\n",
            "Epoch 651/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9149\n",
            "Epoch 652/1000\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9149\n",
            "Epoch 653/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9149\n",
            "Epoch 654/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
            "Epoch 655/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
            "Epoch 656/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9149\n",
            "Epoch 657/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
            "Epoch 658/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
            "Epoch 659/1000\n",
            "53/53 [==============================] - 0s 615us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
            "Epoch 660/1000\n",
            "53/53 [==============================] - 0s 766us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
            "Epoch 661/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
            "Epoch 662/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9149\n",
            "Epoch 663/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
            "Epoch 664/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9149\n",
            "Epoch 665/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
            "Epoch 666/1000\n",
            "53/53 [==============================] - 0s 627us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
            "Epoch 667/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
            "Epoch 668/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9149\n",
            "Epoch 669/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9149\n",
            "Epoch 670/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
            "Epoch 671/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
            "Epoch 672/1000\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9149\n",
            "Epoch 673/1000\n",
            "53/53 [==============================] - 0s 619us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9149\n",
            "Epoch 674/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9149\n",
            "Epoch 675/1000\n",
            "53/53 [==============================] - 0s 717us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9149\n",
            "Epoch 676/1000\n",
            "53/53 [==============================] - 0s 774us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n",
            "Epoch 677/1000\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9149\n",
            "Epoch 678/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9149\n",
            "Epoch 679/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n",
            "Epoch 680/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
            "Epoch 681/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9149\n",
            "Epoch 682/1000\n",
            "53/53 [==============================] - 0s 689us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9149\n",
            "Epoch 683/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
            "Epoch 684/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
            "Epoch 685/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9149\n",
            "Epoch 686/1000\n",
            "53/53 [==============================] - 0s 709us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
            "Epoch 687/1000\n",
            "53/53 [==============================] - 0s 702us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
            "Epoch 688/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9149\n",
            "Epoch 689/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
            "Epoch 690/1000\n",
            "53/53 [==============================] - 0s 726us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
            "Epoch 691/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
            "Epoch 692/1000\n",
            "53/53 [==============================] - 0s 735us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9149\n",
            "Epoch 693/1000\n",
            "53/53 [==============================] - 0s 695us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
            "Epoch 694/1000\n",
            "53/53 [==============================] - 0s 802us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9149\n",
            "Epoch 695/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
            "Epoch 696/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9149\n",
            "Epoch 697/1000\n",
            "53/53 [==============================] - 0s 765us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
            "Epoch 698/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
            "Epoch 699/1000\n",
            "53/53 [==============================] - 0s 758us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
            "Epoch 700/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9149\n",
            "Epoch 701/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
            "Epoch 702/1000\n",
            "53/53 [==============================] - 0s 835us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9149\n",
            "Epoch 703/1000\n",
            "53/53 [==============================] - 0s 754us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
            "Epoch 704/1000\n",
            "53/53 [==============================] - 0s 768us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9149\n",
            "Epoch 705/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
            "Epoch 706/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
            "Epoch 707/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9149\n",
            "Epoch 708/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
            "Epoch 709/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
            "Epoch 710/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9149\n",
            "Epoch 711/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9149\n",
            "Epoch 712/1000\n",
            "53/53 [==============================] - 0s 740us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
            "Epoch 713/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
            "Epoch 714/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
            "Epoch 715/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9149\n",
            "Epoch 716/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
            "Epoch 717/1000\n",
            "53/53 [==============================] - 0s 679us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
            "Epoch 718/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
            "Epoch 719/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
            "Epoch 720/1000\n",
            "53/53 [==============================] - 0s 841us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9149\n",
            "Epoch 721/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9149\n",
            "Epoch 722/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
            "Epoch 723/1000\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
            "Epoch 724/1000\n",
            "53/53 [==============================] - 0s 640us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
            "Epoch 725/1000\n",
            "53/53 [==============================] - 0s 631us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9149\n",
            "Epoch 726/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
            "Epoch 727/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
            "Epoch 728/1000\n",
            "53/53 [==============================] - 0s 852us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
            "Epoch 729/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9149\n",
            "Epoch 730/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9149\n",
            "Epoch 731/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
            "Epoch 732/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
            "Epoch 733/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
            "Epoch 734/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
            "Epoch 735/1000\n",
            "53/53 [==============================] - 0s 756us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
            "Epoch 736/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9149\n",
            "Epoch 737/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
            "Epoch 738/1000\n",
            "53/53 [==============================] - 0s 700us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9149\n",
            "Epoch 739/1000\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
            "Epoch 740/1000\n",
            "53/53 [==============================] - 0s 634us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
            "Epoch 741/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
            "Epoch 742/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9149\n",
            "Epoch 743/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9149\n",
            "Epoch 744/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9149\n",
            "Epoch 745/1000\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9149\n",
            "Epoch 746/1000\n",
            "53/53 [==============================] - 0s 744us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
            "Epoch 747/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9149\n",
            "Epoch 748/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9149\n",
            "Epoch 749/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
            "Epoch 750/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9149\n",
            "Epoch 751/1000\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
            "Epoch 752/1000\n",
            "53/53 [==============================] - 0s 605us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9149\n",
            "Epoch 753/1000\n",
            "53/53 [==============================] - 0s 827us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
            "Epoch 754/1000\n",
            "53/53 [==============================] - 0s 764us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
            "Epoch 755/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9149\n",
            "Epoch 756/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
            "Epoch 757/1000\n",
            "53/53 [==============================] - 0s 641us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9149\n",
            "Epoch 758/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9149\n",
            "Epoch 759/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
            "Epoch 760/1000\n",
            "53/53 [==============================] - 0s 653us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
            "Epoch 761/1000\n",
            "53/53 [==============================] - 0s 831us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
            "Epoch 762/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
            "Epoch 763/1000\n",
            "53/53 [==============================] - 0s 577us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
            "Epoch 764/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
            "Epoch 765/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9149\n",
            "Epoch 766/1000\n",
            "53/53 [==============================] - 0s 641us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
            "Epoch 767/1000\n",
            "53/53 [==============================] - 0s 624us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
            "Epoch 768/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
            "Epoch 769/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
            "Epoch 770/1000\n",
            "53/53 [==============================] - 0s 629us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
            "Epoch 771/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9149\n",
            "Epoch 772/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
            "Epoch 773/1000\n",
            "53/53 [==============================] - 0s 611us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
            "Epoch 774/1000\n",
            "53/53 [==============================] - 0s 664us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
            "Epoch 775/1000\n",
            "53/53 [==============================] - 0s 715us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
            "Epoch 776/1000\n",
            "53/53 [==============================] - 0s 625us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9149\n",
            "Epoch 777/1000\n",
            "53/53 [==============================] - 0s 602us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9149\n",
            "Epoch 778/1000\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9149\n",
            "Epoch 779/1000\n",
            "53/53 [==============================] - 0s 614us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
            "Epoch 780/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
            "Epoch 781/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
            "Epoch 782/1000\n",
            "53/53 [==============================] - 0s 876us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
            "Epoch 783/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
            "Epoch 784/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9149\n",
            "Epoch 785/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
            "Epoch 786/1000\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
            "Epoch 787/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
            "Epoch 788/1000\n",
            "53/53 [==============================] - 0s 674us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9149\n",
            "Epoch 789/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
            "Epoch 790/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
            "Epoch 791/1000\n",
            "53/53 [==============================] - 0s 719us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
            "Epoch 792/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
            "Epoch 793/1000\n",
            "53/53 [==============================] - 0s 711us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
            "Epoch 794/1000\n",
            "53/53 [==============================] - 0s 662us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
            "Epoch 795/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
            "Epoch 796/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
            "Epoch 797/1000\n",
            "53/53 [==============================] - 0s 722us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
            "Epoch 798/1000\n",
            "53/53 [==============================] - 0s 832us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
            "Epoch 799/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9149\n",
            "Epoch 800/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
            "Epoch 801/1000\n",
            "53/53 [==============================] - 0s 729us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
            "Epoch 802/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
            "Epoch 803/1000\n",
            "53/53 [==============================] - 0s 649us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
            "Epoch 804/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9149\n",
            "Epoch 805/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
            "Epoch 806/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
            "Epoch 807/1000\n",
            "53/53 [==============================] - 0s 666us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
            "Epoch 808/1000\n",
            "53/53 [==============================] - 0s 817us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9149\n",
            "Epoch 809/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
            "Epoch 810/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9149\n",
            "Epoch 811/1000\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
            "Epoch 812/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9149\n",
            "Epoch 813/1000\n",
            "53/53 [==============================] - 0s 728us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
            "Epoch 814/1000\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9149\n",
            "Epoch 815/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9149\n",
            "Epoch 816/1000\n",
            "53/53 [==============================] - 0s 697us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9149\n",
            "Epoch 817/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9149\n",
            "Epoch 818/1000\n",
            "53/53 [==============================] - 0s 780us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9149\n",
            "Epoch 819/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9149\n",
            "Epoch 820/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9149\n",
            "Epoch 821/1000\n",
            "53/53 [==============================] - 0s 716us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9149\n",
            "Epoch 822/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
            "Epoch 823/1000\n",
            "53/53 [==============================] - 0s 635us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
            "Epoch 824/1000\n",
            "53/53 [==============================] - 0s 699us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
            "Epoch 825/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
            "Epoch 826/1000\n",
            "53/53 [==============================] - 0s 800us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
            "Epoch 827/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
            "Epoch 828/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9149\n",
            "Epoch 829/1000\n",
            "53/53 [==============================] - 0s 651us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9362\n",
            "Epoch 830/1000\n",
            "53/53 [==============================] - 0s 720us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9149\n",
            "Epoch 831/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9149\n",
            "Epoch 832/1000\n",
            "53/53 [==============================] - 0s 724us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9149\n",
            "Epoch 833/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9149\n",
            "Epoch 834/1000\n",
            "53/53 [==============================] - 0s 913us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
            "Epoch 835/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
            "Epoch 836/1000\n",
            "53/53 [==============================] - 0s 601us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
            "Epoch 837/1000\n",
            "53/53 [==============================] - 0s 647us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
            "Epoch 838/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9362\n",
            "Epoch 839/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9362\n",
            "Epoch 840/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9362\n",
            "Epoch 841/1000\n",
            "53/53 [==============================] - 0s 771us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9362\n",
            "Epoch 842/1000\n",
            "53/53 [==============================] - 0s 760us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
            "Epoch 843/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9149\n",
            "Epoch 844/1000\n",
            "53/53 [==============================] - 0s 694us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
            "Epoch 845/1000\n",
            "53/53 [==============================] - 0s 706us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9149\n",
            "Epoch 846/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
            "Epoch 847/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9149\n",
            "Epoch 848/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
            "Epoch 849/1000\n",
            "53/53 [==============================] - 0s 705us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9149\n",
            "Epoch 850/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9149\n",
            "Epoch 851/1000\n",
            "53/53 [==============================] - 0s 710us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
            "Epoch 852/1000\n",
            "53/53 [==============================] - 0s 762us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9149\n",
            "Epoch 853/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9149\n",
            "Epoch 854/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9149\n",
            "Epoch 855/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9149\n",
            "Epoch 856/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9149\n",
            "Epoch 857/1000\n",
            "53/53 [==============================] - 0s 654us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9149\n",
            "Epoch 858/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9149\n",
            "Epoch 859/1000\n",
            "53/53 [==============================] - 0s 718us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9149\n",
            "Epoch 860/1000\n",
            "53/53 [==============================] - 0s 950us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9149\n",
            "Epoch 861/1000\n",
            "53/53 [==============================] - 0s 788us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9149\n",
            "Epoch 862/1000\n",
            "53/53 [==============================] - 0s 667us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9149\n",
            "Epoch 863/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9149\n",
            "Epoch 864/1000\n",
            "53/53 [==============================] - 0s 692us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9149\n",
            "Epoch 865/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9149\n",
            "Epoch 866/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
            "Epoch 867/1000\n",
            "53/53 [==============================] - 0s 747us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
            "Epoch 868/1000\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
            "Epoch 869/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
            "Epoch 870/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
            "Epoch 871/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9149\n",
            "Epoch 872/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
            "Epoch 873/1000\n",
            "53/53 [==============================] - 0s 660us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9149\n",
            "Epoch 874/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9149\n",
            "Epoch 875/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
            "Epoch 876/1000\n",
            "53/53 [==============================] - 0s 617us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9149\n",
            "Epoch 877/1000\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9149\n",
            "Epoch 878/1000\n",
            "53/53 [==============================] - 0s 794us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
            "Epoch 879/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
            "Epoch 880/1000\n",
            "53/53 [==============================] - 0s 708us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
            "Epoch 881/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
            "Epoch 882/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
            "Epoch 883/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9149\n",
            "Epoch 884/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9149\n",
            "Epoch 885/1000\n",
            "53/53 [==============================] - 0s 661us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9149\n",
            "Epoch 886/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
            "Epoch 887/1000\n",
            "53/53 [==============================] - 0s 823us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9149\n",
            "Epoch 888/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
            "Epoch 889/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9149\n",
            "Epoch 890/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9149\n",
            "Epoch 891/1000\n",
            "53/53 [==============================] - 0s 696us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
            "Epoch 892/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9362\n",
            "Epoch 893/1000\n",
            "53/53 [==============================] - 0s 612us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9362\n",
            "Epoch 894/1000\n",
            "53/53 [==============================] - 0s 619us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9362\n",
            "Epoch 895/1000\n",
            "53/53 [==============================] - 0s 741us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
            "Epoch 896/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9149\n",
            "Epoch 897/1000\n",
            "53/53 [==============================] - 0s 623us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9149\n",
            "Epoch 898/1000\n",
            "53/53 [==============================] - 0s 614us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9149\n",
            "Epoch 899/1000\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
            "Epoch 900/1000\n",
            "53/53 [==============================] - 0s 592us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9149\n",
            "Epoch 901/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9149\n",
            "Epoch 902/1000\n",
            "53/53 [==============================] - 0s 617us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9149\n",
            "Epoch 903/1000\n",
            "53/53 [==============================] - 0s 620us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9149\n",
            "Epoch 904/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9362\n",
            "Epoch 905/1000\n",
            "53/53 [==============================] - 0s 631us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9362\n",
            "Epoch 906/1000\n",
            "53/53 [==============================] - 0s 595us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9362\n",
            "Epoch 907/1000\n",
            "53/53 [==============================] - 0s 637us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9362\n",
            "Epoch 908/1000\n",
            "53/53 [==============================] - 0s 646us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9362\n",
            "Epoch 909/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
            "Epoch 910/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9149\n",
            "Epoch 911/1000\n",
            "53/53 [==============================] - 0s 642us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
            "Epoch 912/1000\n",
            "53/53 [==============================] - 0s 613us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9149\n",
            "Epoch 913/1000\n",
            "53/53 [==============================] - 0s 865us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9362\n",
            "Epoch 914/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
            "Epoch 915/1000\n",
            "53/53 [==============================] - 0s 867us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9362\n",
            "Epoch 916/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9362\n",
            "Epoch 917/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9362\n",
            "Epoch 918/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9149\n",
            "Epoch 919/1000\n",
            "53/53 [==============================] - 0s 842us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9149\n",
            "Epoch 920/1000\n",
            "53/53 [==============================] - 0s 704us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9149\n",
            "Epoch 921/1000\n",
            "53/53 [==============================] - 0s 773us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
            "Epoch 922/1000\n",
            "53/53 [==============================] - 0s 628us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9149\n",
            "Epoch 923/1000\n",
            "53/53 [==============================] - 0s 636us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9149\n",
            "Epoch 924/1000\n",
            "53/53 [==============================] - 0s 652us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9149\n",
            "Epoch 925/1000\n",
            "53/53 [==============================] - 0s 742us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9149\n",
            "Epoch 926/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9149\n",
            "Epoch 927/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9149\n",
            "Epoch 928/1000\n",
            "53/53 [==============================] - 0s 830us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9149\n",
            "Epoch 929/1000\n",
            "53/53 [==============================] - 0s 714us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9149\n",
            "Epoch 930/1000\n",
            "53/53 [==============================] - 0s 713us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9149\n",
            "Epoch 931/1000\n",
            "53/53 [==============================] - 0s 659us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9149\n",
            "Epoch 932/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
            "Epoch 933/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9362\n",
            "Epoch 934/1000\n",
            "53/53 [==============================] - 0s 672us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9362\n",
            "Epoch 935/1000\n",
            "53/53 [==============================] - 0s 688us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9362\n",
            "Epoch 936/1000\n",
            "53/53 [==============================] - 0s 668us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
            "Epoch 937/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9362\n",
            "Epoch 938/1000\n",
            "53/53 [==============================] - 0s 638us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9362\n",
            "Epoch 939/1000\n",
            "53/53 [==============================] - 0s 613us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9149\n",
            "Epoch 940/1000\n",
            "53/53 [==============================] - 0s 617us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9149\n",
            "Epoch 941/1000\n",
            "53/53 [==============================] - 0s 813us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9149\n",
            "Epoch 942/1000\n",
            "53/53 [==============================] - 0s 648us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9149\n",
            "Epoch 943/1000\n",
            "53/53 [==============================] - 0s 622us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9149\n",
            "Epoch 944/1000\n",
            "53/53 [==============================] - 0s 645us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9362\n",
            "Epoch 945/1000\n",
            "53/53 [==============================] - 0s 670us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9362\n",
            "Epoch 946/1000\n",
            "53/53 [==============================] - 0s 746us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9362\n",
            "Epoch 947/1000\n",
            "53/53 [==============================] - 0s 845us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9362\n",
            "Epoch 948/1000\n",
            "53/53 [==============================] - 0s 693us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9362\n",
            "Epoch 949/1000\n",
            "53/53 [==============================] - 0s 745us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9362\n",
            "Epoch 950/1000\n",
            "53/53 [==============================] - 0s 681us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9362\n",
            "Epoch 951/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9149\n",
            "Epoch 952/1000\n",
            "53/53 [==============================] - 0s 673us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9149\n",
            "Epoch 953/1000\n",
            "53/53 [==============================] - 0s 701us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9149\n",
            "Epoch 954/1000\n",
            "53/53 [==============================] - 0s 795us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9149\n",
            "Epoch 955/1000\n",
            "53/53 [==============================] - 0s 675us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9149\n",
            "Epoch 956/1000\n",
            "53/53 [==============================] - 0s 691us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9362\n",
            "Epoch 957/1000\n",
            "53/53 [==============================] - 0s 678us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9362\n",
            "Epoch 958/1000\n",
            "53/53 [==============================] - 0s 665us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9362\n",
            "Epoch 959/1000\n",
            "53/53 [==============================] - 0s 690us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9362\n",
            "Epoch 960/1000\n",
            "53/53 [==============================] - 0s 721us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9362\n",
            "Epoch 961/1000\n",
            "53/53 [==============================] - 0s 655us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9149\n",
            "Epoch 962/1000\n",
            "53/53 [==============================] - 0s 759us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9149\n",
            "Epoch 963/1000\n",
            "53/53 [==============================] - 0s 669us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9149\n",
            "Epoch 964/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9149\n",
            "Epoch 965/1000\n",
            "53/53 [==============================] - 0s 656us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9149\n",
            "Epoch 966/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9362\n",
            "Epoch 967/1000\n",
            "53/53 [==============================] - 0s 767us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9362\n",
            "Epoch 968/1000\n",
            "53/53 [==============================] - 0s 749us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9362\n",
            "Epoch 969/1000\n",
            "53/53 [==============================] - 0s 723us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9149\n",
            "Epoch 970/1000\n",
            "53/53 [==============================] - 0s 737us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
            "Epoch 971/1000\n",
            "53/53 [==============================] - 0s 658us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9149\n",
            "Epoch 972/1000\n",
            "53/53 [==============================] - 0s 615us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
            "Epoch 973/1000\n",
            "53/53 [==============================] - 0s 698us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
            "Epoch 974/1000\n",
            "53/53 [==============================] - 0s 671us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
            "Epoch 975/1000\n",
            "53/53 [==============================] - 0s 685us/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
            "Epoch 976/1000\n",
            "53/53 [==============================] - 0s 604us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9149\n",
            "Epoch 977/1000\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
            "Epoch 978/1000\n",
            "53/53 [==============================] - 0s 639us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
            "Epoch 979/1000\n",
            "53/53 [==============================] - 0s 822us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9149\n",
            "Epoch 980/1000\n",
            "53/53 [==============================] - 0s 735us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9149\n",
            "Epoch 981/1000\n",
            "53/53 [==============================] - 0s 632us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9362\n",
            "Epoch 982/1000\n",
            "53/53 [==============================] - 0s 683us/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9362\n",
            "Epoch 983/1000\n",
            "53/53 [==============================] - 0s 657us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9362\n",
            "Epoch 984/1000\n",
            "53/53 [==============================] - 0s 682us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9362\n",
            "Epoch 985/1000\n",
            "53/53 [==============================] - 0s 677us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9362\n",
            "Epoch 986/1000\n",
            "53/53 [==============================] - 0s 641us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9362\n",
            "Epoch 987/1000\n",
            "53/53 [==============================] - 0s 643us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9362\n",
            "Epoch 988/1000\n",
            "53/53 [==============================] - 0s 829us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9362\n",
            "Epoch 989/1000\n",
            "53/53 [==============================] - 0s 743us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9362\n",
            "Epoch 990/1000\n",
            "53/53 [==============================] - 0s 684us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
            "Epoch 991/1000\n",
            "53/53 [==============================] - 0s 663us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9149\n",
            "Epoch 992/1000\n",
            "53/53 [==============================] - 0s 712us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9362\n",
            "Epoch 993/1000\n",
            "53/53 [==============================] - 0s 676us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9362\n",
            "Epoch 994/1000\n",
            "53/53 [==============================] - 0s 818us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9362\n",
            "Epoch 995/1000\n",
            "53/53 [==============================] - 0s 687us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9362\n",
            "Epoch 996/1000\n",
            "53/53 [==============================] - 0s 680us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9362\n",
            "Epoch 997/1000\n",
            "53/53 [==============================] - 0s 703us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9362\n",
            "Epoch 998/1000\n",
            "53/53 [==============================] - 0s 936us/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
            "Epoch 999/1000\n",
            "53/53 [==============================] - 0s 899us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9362\n",
            "Epoch 1000/1000\n",
            "53/53 [==============================] - 0s 686us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd2998789e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GEBl5_HiEMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7f617d6d-e65e-4b62-8995-480d9420b2e0"
      },
      "source": [
        "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
        "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
        "\n",
        "# plt.plot(history_Adam_1.history['loss'], label = \"tarina dropout\")\n",
        "# plt.plot(history_Adam_1.history['val_loss'], label = \"test dropout\")\n",
        "\n",
        "plt.plot(history_Adam_2.history['loss'], label = \"tarina l1\")\n",
        "plt.plot(history_Adam_2.history['val_loss'], label = \"test l1\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ifw5Cm4iEMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "f79debaa-4b73-4607-ddd4-8b47065d458f"
      },
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "plot_decision_regions(X_test, y_test, model)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}